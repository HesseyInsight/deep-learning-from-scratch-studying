{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6-2 예제: 와인 분류하기2\n",
    "\n",
    "지난 Chap5 5.5 와인분류 모형에서 신경망을 이용해 와인을 분류하는 모형을 만들었다.<br/>\n",
    "이번에는 중간층의 수를 늘려 다층퍼셉트론을 만들어 분류 모형을 만들어보자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 학습 데이터를 준비하고 전처리 하는 과정은 지난 와인 분류기 노트북과 동일하다.<br/>\n",
    "다시한번 내용을 살펴보면서 모델을 구현해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #1.학습 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import Library - 라이브러리 불러오기\n",
    "* Load Data      - 데이터 불러오기\n",
    "* EDA            - 탐색적 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python Library\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Import Scikit-learn Library\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Import Pandas Library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Variable(data): 텐서를 래핑하고, 계산 과정을 기록하는 역할을 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "# wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0    14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1    13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2    13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3    14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4    13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "\n",
       "   flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0        3.06                  0.28             2.29             5.64  1.04   \n",
       "1        2.76                  0.26             1.28             4.38  1.05   \n",
       "2        3.24                  0.30             2.81             5.68  1.03   \n",
       "3        3.49                  0.24             2.18             7.80  0.86   \n",
       "4        2.69                  0.39             1.82             4.32  1.04   \n",
       "\n",
       "   od280/od315_of_diluted_wines  proline  \n",
       "0                          3.92   1065.0  \n",
       "1                          3.40   1050.0  \n",
       "2                          3.17   1185.0  \n",
       "3                          3.45   1480.0  \n",
       "4                          2.93    735.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(wine.data, columns=wine.feature_names, )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA(Exploratory Data Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "         1.065e+03],\n",
       "        [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "         1.050e+03],\n",
       "        [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "         1.185e+03],\n",
       "        ...,\n",
       "        [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "         8.350e+02],\n",
       "        [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "         8.400e+02],\n",
       "        [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "         5.600e+02]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2]),\n",
       " 'target_names': array(['class_0', 'class_1', 'class_2'], dtype='<U7'),\n",
       " 'DESCR': '.. _wine_dataset:\\n\\nWine recognition dataset\\n------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 178 (50 in each of three classes)\\n    :Number of Attributes: 13 numeric, predictive attributes and the class\\n    :Attribute Information:\\n \\t\\t- Alcohol\\n \\t\\t- Malic acid\\n \\t\\t- Ash\\n\\t\\t- Alcalinity of ash  \\n \\t\\t- Magnesium\\n\\t\\t- Total phenols\\n \\t\\t- Flavanoids\\n \\t\\t- Nonflavanoid phenols\\n \\t\\t- Proanthocyanins\\n\\t\\t- Color intensity\\n \\t\\t- Hue\\n \\t\\t- OD280/OD315 of diluted wines\\n \\t\\t- Proline\\n\\n    - class:\\n            - class_0\\n            - class_1\\n            - class_2\\n\\t\\t\\n    :Summary Statistics:\\n    \\n    ============================= ==== ===== ======= =====\\n                                   Min   Max   Mean     SD\\n    ============================= ==== ===== ======= =====\\n    Alcohol:                      11.0  14.8    13.0   0.8\\n    Malic Acid:                   0.74  5.80    2.34  1.12\\n    Ash:                          1.36  3.23    2.36  0.27\\n    Alcalinity of Ash:            10.6  30.0    19.5   3.3\\n    Magnesium:                    70.0 162.0    99.7  14.3\\n    Total Phenols:                0.98  3.88    2.29  0.63\\n    Flavanoids:                   0.34  5.08    2.03  1.00\\n    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\\n    Proanthocyanins:              0.41  3.58    1.59  0.57\\n    Colour Intensity:              1.3  13.0     5.1   2.3\\n    Hue:                          0.48  1.71    0.96  0.23\\n    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\\n    Proline:                       278  1680     746   315\\n    ============================= ==== ===== ======= =====\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThis is a copy of UCI ML Wine recognition datasets.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\\n\\nThe data is the results of a chemical analysis of wines grown in the same\\nregion in Italy by three different cultivators. There are thirteen different\\nmeasurements taken for different constituents found in the three types of\\nwine.\\n\\nOriginal Owners: \\n\\nForina, M. et al, PARVUS - \\nAn Extendible Package for Data Exploration, Classification and Correlation. \\nInstitute of Pharmaceutical and Food Analysis and Technologies,\\nVia Brigata Salerno, 16147 Genoa, Italy.\\n\\nCitation:\\n\\nLichman, M. (2013). UCI Machine Learning Repository\\n[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\\nSchool of Information and Computer Science. \\n\\n.. topic:: References\\n\\n  (1) S. Aeberhard, D. Coomans and O. de Vel, \\n  Comparison of Classifiers in High Dimensional Settings, \\n  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Technometrics). \\n\\n  The data was used with many others for comparing various \\n  classifiers. The classes are separable, though only RDA \\n  has achieved 100% correct classification. \\n  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \\n  (All results using the leave-one-out technique) \\n\\n  (2) S. Aeberhard, D. Coomans and O. de Vel, \\n  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \\n  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \\n  Mathematics and Statistics, James Cook University of North Queensland. \\n  (Also submitted to Journal of Chemometrics).\\n',\n",
       " 'feature_names': ['alcohol',\n",
       "  'malic_acid',\n",
       "  'ash',\n",
       "  'alcalinity_of_ash',\n",
       "  'magnesium',\n",
       "  'total_phenols',\n",
       "  'flavanoids',\n",
       "  'nonflavanoid_phenols',\n",
       "  'proanthocyanins',\n",
       "  'color_intensity',\n",
       "  'hue',\n",
       "  'od280/od315_of_diluted_wines',\n",
       "  'proline']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.423e+01, 1.710e+00, 2.430e+00, ..., 1.040e+00, 3.920e+00,\n",
       "        1.065e+03],\n",
       "       [1.320e+01, 1.780e+00, 2.140e+00, ..., 1.050e+00, 3.400e+00,\n",
       "        1.050e+03],\n",
       "       [1.316e+01, 2.360e+00, 2.670e+00, ..., 1.030e+00, 3.170e+00,\n",
       "        1.185e+03],\n",
       "       ...,\n",
       "       [1.327e+01, 4.280e+00, 2.260e+00, ..., 5.900e-01, 1.560e+00,\n",
       "        8.350e+02],\n",
       "       [1.317e+01, 2.590e+00, 2.370e+00, ..., 6.000e-01, 1.620e+00,\n",
       "        8.400e+02],\n",
       "       [1.413e+01, 4.100e+00, 2.740e+00, ..., 6.100e-01, 1.600e+00,\n",
       "        5.600e+02]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alcohol',\n",
       " 'malic_acid',\n",
       " 'ash',\n",
       " 'alcalinity_of_ash',\n",
       " 'magnesium',\n",
       " 'total_phenols',\n",
       " 'flavanoids',\n",
       " 'nonflavanoid_phenols',\n",
       " 'proanthocyanins',\n",
       " 'color_intensity',\n",
       " 'hue',\n",
       " 'od280/od315_of_diluted_wines',\n",
       " 'proline']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-6061671f0abf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "wine.feature_names.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wine.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.unique(wine.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. target 값이 0, 1, 2 3개의 값으로 이루어져 있다.이 때 target값이 2가되는 시작 인덱스의 값은 얼마인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NumPy to DataFrame\n",
    "* Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numpy to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
       "\n",
       "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     od280/od315_of_diluted_wines  proline  \n",
       "0                            3.92   1065.0  \n",
       "1                            3.40   1050.0  \n",
       "2                            3.17   1185.0  \n",
       "3                            3.45   1480.0  \n",
       "4                            2.93    735.0  \n",
       "..                            ...      ...  \n",
       "173                          1.74    740.0  \n",
       "174                          1.56    750.0  \n",
       "175                          1.56    835.0  \n",
       "176                          1.62    840.0  \n",
       "177                          1.60    560.0  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data = wine.data, columns=wine.feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "178행 13열의 데이터프레임 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 설명변수 목적변수 분할\n",
    "* Train_Test_Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 설명변수, 목적변수 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설명변수와 목적변수를 변수에 대입\n",
    "\n",
    "wine_data = wine.data[0:130]  # wine data에서 130행까지의 데이터만 사용한다.\n",
    "wine_target = wine.target[0:130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(wine_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_Test_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape:  (104, 13)\n",
      "train_Y.shape:  (104,)\n",
      "test_X.shape:  (26, 13)\n",
      "test_Y.shape:  (26,)\n"
     ]
    }
   ],
   "source": [
    "# Train_Test_Split 함수 임포트하기\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(wine_data, wine_target, test_size=0.2)\n",
    "print('train_X.shape: ', train_X.shape)\n",
    "print('train_Y.shape: ', train_Y.shape)\n",
    "print('test_X.shape: ', test_X.shape)\n",
    "print('test_Y.shape: ', test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #3. Make Tensor(텐서 생성)\n",
    "\n",
    "**Reivew** <br/>\n",
    "완성된 train, test 데이터를 PyTorch의 tensor 데이터로 변환한다.<br/>\n",
    "numpy.ndarray 데이터를 torch.tensor형으로 변환해 파이토치가 다룰 수 있는 형태로 정리해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 훈련 데이터와 테스트 데이터 텐서 변환\n",
    "* 설명변수와 목적변수 병합\n",
    "* Mini-Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 데이터와 테스트 데이터 텐서 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X.shape:  torch.Size([104, 13])\n",
      "train_Y.shape:  torch.Size([104])\n",
      "test_X.shape:  torch.Size([26, 13])\n",
      "test_Y.shape:  torch.Size([26])\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터 텐서 변환\n",
    "train_X = torch.from_numpy(train_X).float()\n",
    "train_Y = torch.from_numpy(train_Y).long()\n",
    "\n",
    "# 테스트 데이터 텐서 변환\n",
    "test_X = torch.from_numpy(test_X).float()\n",
    "test_Y = torch.from_numpy(test_Y).long()\n",
    "\n",
    "# 텐서로 변환한 데이터의 형상을 확인해보자\n",
    "print('train_X.shape: ', train_X.shape)\n",
    "print('train_Y.shape: ', train_Y.shape)\n",
    "print('test_X.shape: ', test_X.shape)\n",
    "print('test_Y.shape: ', test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 설명변수와 목적변수 병합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "설명변수와 목적변수의 텐서를 병합해준다. 이 때 훈련데이터만 병합한다. 왜 그럴까?<br/>\n",
    "테스트 데이터는 트레이닝 과정에 사용되지 않기 때문이다. 즉, 잘 훈련된 모델의 성능을 평가할 때만 사용하기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 설명변수와 목적변수의 텐서를 병합\n",
    "# #1. 라이브러리 임포트 과정에서 불러왔던 TensorDataset()함수를 사용한다.\n",
    "\n",
    "train = TensorDataset(train_X, train_Y)  # from torch.unils.data import DataLoader, TensorDataset\n",
    "# print('train.shape: ', train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.1820e+01, 1.4700e+00, 1.9900e+00, 2.0800e+01, 8.6000e+01, 1.9800e+00,\n",
       "         1.6000e+00, 3.0000e-01, 1.5300e+00, 1.9500e+00, 9.5000e-01, 3.3300e+00,\n",
       "         4.9500e+02]), tensor(1))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-Batch\n",
    "\n",
    "batch size가 16인 미니배치로 분할을 하자<br/>\n",
    "from torch.unils.data import DataLoader에서 불러온 DataLoader()함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미니배치로 분할\n",
    "train_loader = DataLoader(train, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1c541597c48>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #4. 신경망 구성\n",
    "학습에 사용할 다층퍼셉트론을 구성하는 단계이다.<br/>\n",
    "이번에는 중간층이 5층인 신경망을 구성한다.<br/>\n",
    "\n",
    "* 입력층의 노드 수는 13개\n",
    "* 중간층의 노드 수는 96개\n",
    "* 출력층의 노드 수는 2개\n",
    "<br/>\n",
    "\n",
    "\n",
    "위와 같은 신경망을 구현해보자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 신경망 구성\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(13, 96)\n",
    "        self.fc2 = nn.Linear(96, 96)\n",
    "        self.fc3 = nn.Linear(96, 96)\n",
    "        self.fc4 = nn.Linear(96, 96)\n",
    "        self.fc5 = nn.Linear(96, 96)\n",
    "        self.fc6 = nn.Linear(96, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = F.relu(self.fc5(x))\n",
    "        x = self.fc6(x)\n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "# 인스턴스 생성\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #5. 모형 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞서 생성한 텐서를 신경망에 입력해 모형을 학습해본다.\n",
    "학습된 모형의 정확도도 측정해보도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stevelee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 tensor(2.1583)\n",
      "100 tensor(1.5621)\n",
      "150 tensor(2.0515)\n",
      "200 tensor(1.3868)\n",
      "250 tensor(1.2280)\n",
      "300 tensor(1.5892)\n"
     ]
    }
   ],
   "source": [
    "# 오차함수 객체 \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 최적화를 담당할 객체\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 학습 시작\n",
    "for epoch in range(300):\n",
    "    total_loss = 0\n",
    "    #분할해둔 데이터를 꺼내온다.\n",
    "    for train_x, train_y in train_loader:\n",
    "        # 게산 그래프 구성\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        # 경사 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 순전파 계산\n",
    "        output = model(train_x)  # 와우... 정말 간단하네...\n",
    "        # 오차 계산\n",
    "        loss = criterion(output, train_y)\n",
    "        # 역전파 계산 \n",
    "        loss.backward()\n",
    "        # 가중치 업데이트\n",
    "        optimizer.step()\n",
    "        # 누적 오차 계산\n",
    "        total_loss += loss.data\n",
    "        \n",
    "    # 50회마다 누적 오차 출력\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(epoch+1, total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# #6. Accuracy test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stevelee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8076923076923077"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계산 그리프 구성\n",
    "test_x, test_y = Variable(test_X), Variable(test_Y)\n",
    "\n",
    "# 출력이 0 또는 1이 되도록 변환\n",
    "result = torch.max(model(test_x).data, 1)[1]\n",
    "\n",
    "# 모형의 정확도 측정\n",
    "accuracy = sum(test_y.data.numpy() == result.numpy()) / len(test_y.data.numpy())\n",
    "\n",
    "# 모형의 정확도 출력\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "조금 더 학습해볼까요?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 학습 정리\n",
    "    * 1. 오차함수 객체 생성\n",
    "    * 2. 최적화 객체 생성\n",
    "    * 3. 학습 시작\n",
    "        * 분할해온 데이터를 꺼내온다 \n",
    "            * 3-1) 계산 그래프 구성\n",
    "            * 3-2) 경사 소기화\n",
    "            * 3-3) 순전파 계산\n",
    "            * 3-4) 오차 계산\n",
    "            * 3-5) 역전파 계산\n",
    "            * 3-6) 가중치 업데이트\n",
    "            * 3-7) 누적오차 계산\n",
    "         * 50회마다 누적 오차 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000에폭만큼 학습해보자 loss가 얼마나 줄어들까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stevelee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 tensor(1.2742)\n",
      "100 tensor(1.1651)\n",
      "150 tensor(1.1647)\n",
      "200 tensor(1.8895)\n",
      "250 tensor(1.2294)\n",
      "300 tensor(1.7649)\n",
      "350 tensor(1.0492)\n",
      "400 tensor(1.0913)\n",
      "450 tensor(1.3442)\n",
      "500 tensor(1.1261)\n",
      "550 tensor(1.0991)\n",
      "600 tensor(1.1885)\n",
      "650 tensor(1.2699)\n",
      "700 tensor(0.9641)\n",
      "750 tensor(1.0615)\n",
      "800 tensor(1.2582)\n",
      "850 tensor(1.2832)\n",
      "900 tensor(1.3237)\n",
      "950 tensor(0.9586)\n",
      "1000 tensor(1.0653)\n"
     ]
    }
   ],
   "source": [
    "# 1. 오차 함수 객체 생성\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 2. 최적화 객체 생성\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 3. 학습 시작\n",
    "for epoch in range(1000):\n",
    "    total_loss = 0\n",
    "    # 분할해온 데이터를 꺼내온다.(train_loader)에서\n",
    "    for train_x, train_y in train_loader:\n",
    "        # 3-1) 계산 그래프 구성\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        # 3-2) 경사 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 3-3) 순전파 계산\n",
    "        output = model(train_x)\n",
    "        # 3-4) 오차 계산\n",
    "        loss = criterion(output, train_y) \n",
    "        # 3-5) 역전파 계산\n",
    "        loss.backward()\n",
    "        # 3-6) 가중치 업데이트 \n",
    "        optimizer.step()\n",
    "        # 3-7) 누적 오차 계산\n",
    "        total_loss += loss.data\n",
    "        \n",
    "    # 50회마다 누적 오차를 출력한다.\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(epoch+1, total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다시 한번 Accuracy를 찍어보자<br/>\n",
    "epoch수를 1000으로 늘렸을 때 정확도는 얼마나 향상될까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stevelee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계산 그래프 구성\n",
    "test_x, test_y = Variable(test_X), Variable(test_Y)\n",
    "# 출력이 0 또는 1이 되도록 변환\n",
    "result = torch.max(model(test_x).data, 1)[1]\n",
    "\n",
    "# 모형의 정확도 측정\n",
    "accuracy = sum(test_y.data.numpy() == result.numpy()) / len(test_y.data.numpy())\n",
    "\n",
    "# 모형의 정확도 출력\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "epoch수를 700 늘렸더니 정확도가 무려 12% 향상되었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이번에는 Learning rate를 줄여보자\n",
    "**lr를 0.001로 줄여보자**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stevelee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 tensor(0.9182)\n",
      "100 tensor(0.9829)\n",
      "150 tensor(0.8226)\n",
      "200 tensor(0.8716)\n",
      "250 tensor(0.8822)\n",
      "300 tensor(0.7771)\n",
      "350 tensor(0.7578)\n",
      "400 tensor(0.8039)\n",
      "450 tensor(0.7381)\n",
      "500 tensor(0.8006)\n",
      "550 tensor(0.9186)\n",
      "600 tensor(0.7777)\n",
      "650 tensor(0.6735)\n",
      "700 tensor(0.7891)\n",
      "750 tensor(0.7694)\n",
      "800 tensor(0.7160)\n",
      "850 tensor(0.7281)\n",
      "900 tensor(0.6280)\n",
      "950 tensor(0.6527)\n",
      "1000 tensor(0.6457)\n"
     ]
    }
   ],
   "source": [
    "# 1. 오차 함수 객체 생성\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 2. 최적화 객체 생성\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# 3. 학습 시작\n",
    "for epoch in range(1000):\n",
    "    total_loss = 0\n",
    "    # 분할해온 데이터를 꺼내온다.(train_loader)에서\n",
    "    for train_x, train_y in train_loader:\n",
    "        # 3-1) 계산 그래프 구성\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        # 3-2) 경사 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 3-3) 순전파 계산\n",
    "        output = model(train_x)\n",
    "        # 3-4) 오차 계산\n",
    "        loss = criterion(output, train_y) \n",
    "        # 3-5) 역전파 계산\n",
    "        loss.backward()\n",
    "        # 3-6) 가중치 업데이트 \n",
    "        optimizer.step()\n",
    "        # 3-7) 누적 오차 계산\n",
    "        total_loss += loss.data\n",
    "        \n",
    "    # 50회마다 누적 오차를 출력한다.\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        print(epoch+1, total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss가 1.6254에서 0.6346으로 줄었다..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stevelee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9615384615384616"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계산그래프 구성\n",
    "test_x, test_y = Variable(test_x), Variable(test_y)\n",
    "# 출력이 0또는 1이 되도록 변환\n",
    "result = torch.max(model(test_x).data, 1)[1]\n",
    "# 모형의 정확도 측성\n",
    "accuracy = sum(test_y.data.numpy() == result.numpy()) / len(test_y.data.numpy())\n",
    "\n",
    "# 모형의 정확도 출력\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "92%에서 96%로 더 상승"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이상태로 epoch수를 늘려보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stevelee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 tensor(1.4901e-08)\n",
      "200 tensor(1.4901e-08)\n",
      "300 tensor(1.4901e-08)\n",
      "400 tensor(1.4901e-08)\n",
      "500 tensor(1.4901e-08)\n",
      "600 tensor(1.4901e-08)\n",
      "700 tensor(1.4901e-08)\n",
      "800 tensor(1.4901e-08)\n",
      "900 tensor(1.4901e-08)\n",
      "1000 tensor(1.4901e-08)\n",
      "1100 tensor(2.2352e-08)\n",
      "1200 tensor(2.2352e-08)\n",
      "1300 tensor(1.4901e-08)\n",
      "1400 tensor(1.4901e-08)\n",
      "1500 tensor(2.2352e-08)\n",
      "1600 tensor(1.4901e-08)\n",
      "1700 tensor(2.2352e-08)\n",
      "1800 tensor(1.4901e-08)\n",
      "1900 tensor(1.4901e-08)\n",
      "2000 tensor(1.4901e-08)\n"
     ]
    }
   ],
   "source": [
    "# 1. 오차 함수 객체 생성\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 2. 최적화 객체 생성\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# 3. 학습 시작\n",
    "for epoch in range(2000):\n",
    "    total_loss = 0\n",
    "    # 분할해온 데이터를 꺼내온다.(train_loader)에서\n",
    "    for train_x, train_y in train_loader:\n",
    "        # 3-1) 계산 그래프 구성\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        # 3-2) 경사 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 3-3) 순전파 계산\n",
    "        output = model(train_x)\n",
    "        # 3-4) 오차 계산\n",
    "        loss = criterion(output, train_y) \n",
    "        # 3-5) 역전파 계산\n",
    "        loss.backward()\n",
    "        # 3-6) 가중치 업데이트 \n",
    "        optimizer.step()\n",
    "        # 3-7) 누적 오차 계산\n",
    "        total_loss += loss.data\n",
    "        \n",
    "    # 50회마다 누적 오차를 출력한다.\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(epoch+1, total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stevelee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계산 그리프 구성\n",
    "test_x, test_y = Variable(test_X), Variable(test_Y)\n",
    "\n",
    "# 출력이 0 또는 1이 되도록 변환\n",
    "result = torch.max(model(test_x).data, 1)[1]\n",
    "\n",
    "# 모형의 정확도 측정\n",
    "accuracy = sum(test_y.data.numpy() == result.numpy()) / len(test_y.data.numpy())\n",
    "\n",
    "# 모형의 정확도 출력\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optimizer는 Adam이 좋다던데...\n",
    "### Adam로 최적해 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stevelee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 tensor(0.7274)\n",
      "200 tensor(0.3738)\n",
      "300 tensor(0.5605)\n",
      "400 tensor(0.5831)\n",
      "500 tensor(0.1633)\n",
      "600 tensor(0.0017)\n",
      "700 tensor(2.6754e-05)\n",
      "800 tensor(6.5639e-06)\n",
      "900 tensor(2.3693e-06)\n",
      "1000 tensor(1.1027e-06)\n",
      "1100 tensor(6.3330e-07)\n",
      "1200 tensor(4.4703e-07)\n",
      "1300 tensor(2.2352e-07)\n",
      "1400 tensor(1.4901e-07)\n",
      "1500 tensor(1.1176e-07)\n",
      "1600 tensor(5.9605e-08)\n",
      "1700 tensor(3.7253e-08)\n",
      "1800 tensor(2.2352e-08)\n",
      "1900 tensor(2.2352e-08)\n",
      "2000 tensor(1.4901e-08)\n"
     ]
    }
   ],
   "source": [
    "# 1. 오차 함수 객체 생성\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 2. 최적화 객체 생성\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 3. 학습 시작\n",
    "for epoch in range(2000):\n",
    "    total_loss = 0\n",
    "    # 분할해온 데이터를 꺼내온다.(train_loader)에서\n",
    "    for train_x, train_y in train_loader:\n",
    "        # 3-1) 계산 그래프 구성\n",
    "        train_x, train_y = Variable(train_x), Variable(train_y)\n",
    "        # 3-2) 경사 초기화\n",
    "        optimizer.zero_grad()\n",
    "        # 3-3) 순전파 계산\n",
    "        output = model(train_x)\n",
    "        # 3-4) 오차 계산\n",
    "        loss = criterion(output, train_y) \n",
    "        # 3-5) 역전파 계산\n",
    "        loss.backward()\n",
    "        # 3-6) 가중치 업데이트 \n",
    "        optimizer.step()\n",
    "        # 3-7) 누적 오차 계산\n",
    "        total_loss += loss.data\n",
    "        \n",
    "    # 50회마다 누적 오차를 출력한다.\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(epoch+1, total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "역시...빠르고... 최적화도 급이 다르구나...<br/>\n",
    "20.02.17.mon am 12:37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Accuracy Test\n",
    "test data로 accuracy를 계산해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stevelee\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계산 그리프 구성\n",
    "test_x, test_y = Variable(test_X), Variable(test_Y)\n",
    "\n",
    "# 출력이 0 또는 1이 되도록 변환\n",
    "result = torch.max(model(test_x).data, 1)[1]\n",
    "\n",
    "# 모형의 정확도 측정\n",
    "accuracy = sum(test_y.data.numpy() == result.numpy()) / len(test_y.data.numpy())\n",
    "\n",
    "# 모형의 정확도 출력\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam Optimimzer를 사용해서 Accuracy를 테스트해본 결과. 의외로 Test 정확도는 낮게 나왔다.<br/>\n",
    "왜때문일까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
