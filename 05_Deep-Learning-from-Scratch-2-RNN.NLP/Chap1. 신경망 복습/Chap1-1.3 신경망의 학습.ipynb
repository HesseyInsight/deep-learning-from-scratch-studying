{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 신경망의 학습\n",
    "신경망으로 좋은 추론을 하기 위해서는 학습을 먼저 수행하고, 학습된 매개변수를 이용해 추론을 수행하는 흐름이 일반적이다.\n",
    "\n",
    "한편 신경망의 학습은 최적의 매개변수값을 찾는 작업이다.\n",
    "\n",
    "이번절에서는 신경망의 학습에 대해 살펴본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.1 손실 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 학습에는 학습이 얼마나 잘 이루어지고 있는지를 나타내기 위한 '척도'가 필요하다.<br>\n",
    "일반적으로 학습 단계의 특정 시점에서 신경망의 성능을 나타내는 척도로 **손실(Loss)**를 사용한다.<br>\n",
    "학습시 주어진 정답 데이터와 신경망이 예측한 결과를 비교해 예측이 얼마나 나쁜가를 산출한 단일 스칼라값(loss)를 구할 수 있다.\n",
    "\n",
    "\n",
    "* 학습의 척도로 Loss를 사용한다.\n",
    "* Loss는 정답 데이터와 신경망 예측 결과를 비교한 단일 스칼라값으로 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망의 손실은 **손실 함수(loss function)**을 사용해서 구한다.\n",
    "\n",
    "다중 클래스 분류(multi-class classification) 신경망에서는 손실함수로 흔히 **교차 엔트로피 오차(Cross Entropy Error)**를 이용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**손실함수를 적용한 신경망 계층 구성**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](TwoLayerNetwork-with-LossFunction.PNG \"TwoLayerNet-with-LossFunction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-X: 입력데이터<br>\n",
    "-t: 정답레이블<br>\n",
    "-L: 손실<br>\n",
    "-Softmax계층의 출력: 확률<br>\n",
    "-Cross Entropy Error 계층: Softmax 계층 출력 확률과 정답 레이블이 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Softmax 함수**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](Softmax-function.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Softmax함수 출력의 각 원소는 0.0이상 1.0이하의 실수이다. <br>\n",
    "* 원소들을 모두 더하면 1.0이 된다.\n",
    "* 이 때문에 Softmax의 출력을 '확률'로 해석할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.34985881 18.17414537 54.59815003]\n",
      "74.1221542101633\n",
      "[0.01821127 0.24519181 0.73659691]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([0.3, 2.9, 4.0])\n",
    "exp_a = np.exp(a)\n",
    "print(exp_a)\n",
    "\n",
    "sum_exp_a = np.sum(exp_a)\n",
    "print(sum_exp_a)\n",
    "\n",
    "y = exp_a / sum_exp_a\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CEE(Cross Entropy Error)**<br>\n",
    "![alt text](Cross-Entropy.PNG \"Cross-Entropy function\")\n",
    "* tk는 k번째 클래스에 해당하는 정답 레이블이다.<br>\n",
    "* log는 네이피어 상수(혹은 오일러의수)e를 밑으로 하는 로그이다.<br>\n",
    "* 정답 레이블은 t=[0, 0, 1]과 같이 원-핫 벡터로 표현한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minibatch를 적용한 CrossEntropyError**<br>\n",
    "![alt text](Minibatch-CrossEntropy.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tnk는 n번째 데이터에서 k차원째의 값을 의미한다.<br>\n",
    "* ynk는 신경망의 출력이고, tnk는 정답 레이블이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Softmax-with-Loss Layer**<br>\n",
    "![alt text](Softmax-with-Loss-Layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 책에서는 소프트맥스 함수와 교차 엔트로피 오차를 계산하는 계층을 Softmax with Loss 계층 하나로 구현한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.2 미분과 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 연쇄 법칙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.4 계산 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.5 기울기 도출과 역전파 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.6 가중치 갱신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
