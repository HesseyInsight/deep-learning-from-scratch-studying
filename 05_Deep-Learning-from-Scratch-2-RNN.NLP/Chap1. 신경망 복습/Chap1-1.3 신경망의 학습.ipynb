{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 신경망의 학습\n",
    "신경망으로 좋은 추론을 하기 위해서는 학습을 먼저 수행하고, 학습된 매개변수를 이용해 추론을 수행하는 흐름이 일반적이다.\n",
    "\n",
    "한편 신경망의 학습은 최적의 매개변수값을 찾는 작업이다.\n",
    "\n",
    "이번절에서는 신경망의 학습에 대해 살펴본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.1 손실 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 학습에는 학습이 얼마나 잘 이루어지고 있는지를 나타내기 위한 '척도'가 필요하다.<br>\n",
    "일반적으로 학습 단계의 특정 시점에서 신경망의 성능을 나타내는 척도로 **손실(Loss)**를 사용한다.<br>\n",
    "학습시 주어진 정답 데이터와 신경망이 예측한 결과를 비교해 예측이 얼마나 나쁜가를 산출한 단일 스칼라값(loss)를 구할 수 있다.\n",
    "\n",
    "\n",
    "* 학습의 척도로 Loss를 사용한다.\n",
    "* Loss는 정답 데이터와 신경망 예측 결과를 비교한 단일 스칼라값으로 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망의 손실은 **손실 함수(loss function)**을 사용해서 구한다.\n",
    "\n",
    "다중 클래스 분류(multi-class classification) 신경망에서는 손실함수로 흔히 **교차 엔트로피 오차(Cross Entropy Error)**를 이용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**손실함수를 적용한 신경망 계층 구성**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./img/TwoLayerNetwork-with-LossFunction.PNG \"TwoLayerNet-with-LossFunction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-X: 입력데이터<br>\n",
    "-t: 정답레이블<br>\n",
    "-L: 손실<br>\n",
    "-Softmax계층의 출력: 확률<br>\n",
    "-Cross Entropy Error 계층: Softmax 계층 출력 확률과 정답 레이블이 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Softmax 함수**<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./img/Softmax-function.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Softmax함수 출력의 각 원소는 0.0이상 1.0이하의 실수이다. <br>\n",
    "* 원소들을 모두 더하면 1.0이 된다.\n",
    "* 이 때문에 Softmax의 출력을 '확률'로 해석할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.34985881 18.17414537 54.59815003]\n",
      "74.1221542101633\n",
      "[0.01821127 0.24519181 0.73659691]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([0.3, 2.9, 4.0])\n",
    "exp_a = np.exp(a)\n",
    "print(exp_a)\n",
    "\n",
    "sum_exp_a = np.sum(exp_a)\n",
    "print(sum_exp_a)\n",
    "\n",
    "y = exp_a / sum_exp_a\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Softmax 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax 함수 정의\n",
    "\n",
    "def softmax(s):\n",
    "    c = np.max(s)\n",
    "    exp_s = np.exp(s-c)\n",
    "    sum_exp_s = np.sum(exp_s)\n",
    "    y = exp_s / sum_exp_s\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01821127 0.24519181 0.73659691]\n"
     ]
    }
   ],
   "source": [
    "s = np.array([0.3, 2.9, 4.0])\n",
    "\n",
    "print(softmax(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Softmax 함수의 특징\n",
    "    * 함수의 출력은 0에서 1.0사이이다.\n",
    "    * 함수 출력의 총 합은 1이다.\n",
    "    * Softmax함수를 적용해도 각 원소의 대소 관계는 변하지 않는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CEE(Cross Entropy Error)**<br>\n",
    "![alt text](./img/Cross-Entropy.PNG \"Cross-Entropy function\")\n",
    "* tk는 k번째 클래스에 해당하는 정답 레이블이다.<br>\n",
    "* log는 네이피어 상수(혹은 오일러의수)e를 밑으로 하는 로그이다.<br>\n",
    "* 정답 레이블은 t=[0, 0, 1]과 같이 원-핫 벡터로 표현한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Minibatch를 적용한 CrossEntropyError**<br>\n",
    "![alt text](./img/Minibatch-CrossEntropy.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* tnk는 n번째 데이터에서 k차원째의 값을 의미한다.<br>\n",
    "* ynk는 신경망의 출력이고, tnk는 정답 레이블이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Softmax-with-Loss Layer**<br>\n",
    "![alt text](./img/Softmax-with-Loss-Layer.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본 책에서는 소프트맥스 함수와 교차 엔트로피 오차를 계산하는 계층을 Softmax with Loss 계층 하나로 구현한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.2 미분과 기울기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망 학습의 목표는 손실을 최소화하는 매개변수를 찾는 것이다.\n",
    "\n",
    "이 때 중요한 것이 바로 **'미분'**과 **'기울기'**이다.\n",
    "\n",
    "이번 절에서는 미분과 기울기에 대해 간략히 설명한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gradient(기울기)란 무엇인가\n",
    "-x에 관한 y의 미분은 dy/dx라고 쓴다<br>\n",
    "-이것이 의미하는 것은 x를 조금 변화시켰을 때(조금의 변화를 극한까지 줄일 때) y값이 얼마나 변하는가이다.\n",
    "\n",
    "* 두 가지의 Gradient\n",
    "    * 벡터의 각 원소에 대한 미분을 정리\n",
    "    * 행렬에서의 기울기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 벡터의 기울기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L은 스칼라, x는 벡터인 함수 L = f(x) 가 있다.\n",
    "\n",
    "이 때 xi(x의 i번 째 원소)에 대한 미분과 x의 다른 원소의 미분을 다음과 같이 정리할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./img/gradient-vector.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이처럼 벡터의 각 원소에 대한 미분을 정리한 것이 기울기이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 행렬의 기울기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./img/gradient-matrix.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 행렬의 기울기는 원래의 행렬과 형상이 같다.\n",
    "  \n",
    "이 성질을 이용하면 매개변수 갱신과 연쇄 법칙을 쉽게 구현할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 연쇄 법칙"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 시 신경망은 학습데이터를 통해 손실(Loss)을 출력한다. 이 때 우리가 알고 싶은 것은 바로 **매개변수에 대한 손실의 기울기**이다.\n",
    "\n",
    "Gradient of parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 연쇄 법칙(Chain-Rule)\n",
    "\n",
    "오차역전파법을 이해하는 열쇠는 **연쇄법칙(Chain-Rule)**이다. 연쇄법칙이란 합성함수에 대한 미분의 법칙이다.\n",
    "\n",
    "* 연쇄법칙이 중요한 이유\n",
    "\n",
    "아무리 복잡하고, 많은 함수를 사용하더라도 개별 미분들을 이용해 전체 미분값을 구할 수 있기 때문이다.<br>\n",
    "즉, 각 함수의 국소적 미분을 구할 수 있다면 그 값들을 곱해서 전체 미분을 구할 수 있다.\n",
    "\n",
    "* Chain-Rule을 활용한 역전파 미분값 구하기\n",
    "\n",
    "Chain-Rule에 따르면 역전파로 흐르는 미분값은 상류로부터 흘러온 미분과 각 연산 노드의 국소적인 미분을 곱해 계산할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.4 계산 그래프"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 분기노드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./img/분기노드.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분기노드는 위의 그림과 같이 분기하는 노드이다.\n",
    "\n",
    "분기노드의 역전파는 (상류노드에서 흘러들어온) 분기노드의 합이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2개의 분기 노드를 일반화 하면 N개의 분기가 된다. 이를 Repeat Node라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](./img/Repeat-Node.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "분기노드 코드 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "D, N = 8, 7\n",
    "x = np.random.randn(1, D)  # 입력\n",
    "# y = np.random.randn(8, 7)\n",
    "y = np.repeat(x, N, axis=0)  # 순전파\n",
    "\n",
    "# 역전파\n",
    "dy = np.random.randn(N,D)\n",
    "dx = np.sum(dy, axis=0, keepdims=True)  # Keppdims= Ture\n",
    "                                        # If this is set to True, the axes which are reduced are left\n",
    "                                        # in the result as dimensions with size one. With this option,\n",
    "                                        # the result will broadcast correctly against the input array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.5 기울기 도출과 역전파 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.6 가중치 갱신"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
