{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 신경망의 추론\n",
    "신경망에서 수행하는 작업은 두 단계로 나눌 수 있다. 이번 절에서는 '추론'에 집중해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 완전연결계층에 의한 변환\n",
    "# 미니배치를 적용한 예시\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "W1 = np.random.randn(2, 4)  # 가중치\n",
    "b1 = np.random.randn(4)     # 편향\n",
    "x = np.random.randn(10, 2)  # 입력\n",
    "\n",
    "# 입력노드가 2개일 때, 4개의 출력노드를 갖는 신경망\n",
    "# (10, 2) -> (10, 2) x (2, 4) + (4) = (10, 4)\n",
    "\n",
    "h = np.matmul(x, W1) + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2)\n",
      "[[ 0.96693241 -0.02815344]\n",
      " [ 1.34707481 -0.46435713]\n",
      " [ 0.60334194  0.92355497]\n",
      " [-1.22126792 -0.1603039 ]\n",
      " [-0.04535196  0.67409964]\n",
      " [-0.86934708  0.45223215]\n",
      " [-0.49676093  0.00206163]\n",
      " [ 0.56662034 -1.52395026]\n",
      " [-0.04539973 -0.09461   ]\n",
      " [ 0.96083142 -0.17576389]]\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 4)\n"
     ]
    }
   ],
   "source": [
    "print(h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.40998083 -0.49736758 -1.10430266 -0.09364953]\n",
      " [-2.66759939 -0.4793049  -0.3929734  -0.72038846]\n",
      " [-2.36911973 -0.48202799 -3.22141159  1.11786253]\n",
      " [ 0.08932306 -0.76262406  1.9057381   0.48741976]\n",
      " [-1.54733631 -0.57349504 -1.76384308  1.04932676]\n",
      " [-0.54000855 -0.68388286 -0.16774919  1.07105614]\n",
      " [-0.78380111 -0.66756058  0.59029107  0.43085266]\n",
      " [-1.38684507 -0.63569432  3.40213664 -1.67252596]\n",
      " [-1.25167653 -0.6204084   0.30253843  0.16908045]\n",
      " [-2.34639071 -0.50709207 -0.70011763 -0.26063872]]\n"
     ]
    }
   ],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데 완전연결계층에 의한 변환은 '선형 변환'이다.\n",
    "\n",
    "여기에 **'비선형 효과'**를 부여하는 것이 바로 **활성화함수(Activation Function)**이다.\n",
    "\n",
    "비선형 활성화 함수를 이용함으로써 신경망의 표현력을 높일 수 있다. 이번 예제에서는 시그모이드 함수(Sigmoid Function)을 활성화 함수로 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image of Sigmoid](https://www.researchgate.net/profile/Knut_Kvaal/publication/239269767/figure/fig2/AS:643520205430784@1530438581076/An-illustration-of-the-signal-processing-in-a-sigmoid-function.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "시그모이드 함수는 임의의 실수를 입력받아 0에서 1사이의 실수를 출력한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 시그모이드 함수 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid function\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.08241477, 0.3781595 , 0.24893457, 0.47660471],\n",
       "       [0.06491253, 0.38241628, 0.40300172, 0.32730745],\n",
       "       [0.08555798, 0.38177336, 0.03836787, 0.75359202],\n",
       "       [0.52231593, 0.31807683, 0.87053959, 0.61949841],\n",
       "       [0.17547132, 0.36043075, 0.14630967, 0.7406456 ],\n",
       "       [0.36818559, 0.33539524, 0.45816077, 0.74479771],\n",
       "       [0.31350124, 0.33904328, 0.64343193, 0.60607726],\n",
       "       [0.1999119 , 0.34622049, 0.96777124, 0.15808769],\n",
       "       [0.22241006, 0.34968857, 0.57506294, 0.5421697 ],\n",
       "       [0.08735309, 0.37587546, 0.33178615, 0.4352067 ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = sigmoid(h)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 10개의 데이터를 갖는 2개의 입력노드가있다. 은닉층을 거쳐서 3개의 출력 노드를 갖는 완전신경망을 구현해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.34042506 1.87095788 0.22820835]\n",
      " [0.88737931 1.73249498 0.93608287]\n",
      " [0.55365595 1.93142429 0.36457133]\n",
      " [0.91834243 2.18458366 0.42180521]\n",
      " [0.20868081 1.79041129 0.20930506]\n",
      " [0.75253542 2.15869045 0.26759512]\n",
      " [0.8545556  2.12747722 0.42444608]\n",
      " [0.30314686 1.90181023 0.1313175 ]\n",
      " [0.67146552 1.72012054 0.68864551]\n",
      " [1.03704736 1.83830579 0.96587446]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# define sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Fully-connected layer\n",
    "x = np.random.randn(10, 2) # np.random.randn(): return the sample(or samples) from standard normal distribution\n",
    "W1 = np.random.randn(2, 4)\n",
    "b1 = np.random.randn(4)\n",
    "W2 = np.random.randn(4, 3)\n",
    "b2 = np.random.randn(3)\n",
    "\n",
    "h1 = np.dot(x, W1) + b1\n",
    "a1 = sigmoid(h1)\n",
    "h2 = np.dot(a1, W2) + b2\n",
    "print(h2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# define sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Fully-connected Layer\n",
    "x = np.random.randn(10, 2)\n",
    "W1 = np.random.randn(2, 4)\n",
    "b1 = np.random.randn(4)\n",
    "W2 = np.random.randn(4, 3)\n",
    "b2 = np.random.randn(3)\n",
    "\n",
    "h1 = np.matmul(x, W1) + 1\n",
    "a1 = sigmoid(h1)\n",
    "h2 = np.matmul(a1, )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
