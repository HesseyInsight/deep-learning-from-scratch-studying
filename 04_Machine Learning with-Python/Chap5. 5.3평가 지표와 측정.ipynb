{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chap5. 모델 평가와 성능 향상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지금까지는 지도 학습과 비지도 학습 이론을 다루면서 다양한 머신러닝 알고리즘을 살펴봤다.\n",
    "\n",
    "이제 모델 평가와 매개변수 선택에 대해 더 자세히 배워보도록 한다.\n",
    "\n",
    "(3장에서 보았듯이) 비지도 학습 모델을 평가하고 선택하는 일은 매우 정성적인 작업이므로 여기서는 지도학습인 회귀와 분류에 집중하도록 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "지도학습 모델을 평가하기 위해 sklearn에서 제공하는 train_test_split 함수를 사용하여 데이터셋을 훈련 세트와 테스트 세트로 나눴다. 그리고 모델을 만들기 위해 훈련 세트에 fit 메서드를 적용했고, 모델을 평가하기 위해 테스트 세트에 score 메서드를 사용했다.분류에서 score 메서드는 정확히 분류된 샘플의 비율을 계한하는 역할을 한다. \n",
    "\n",
    "다음의 예제를 통해 과정을 살펴보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 세트 점수:  0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 인위적인 데이터 셋을 만든다.\n",
    "X, y = make_blobs(random_state=0)\n",
    "# 데이터와 타깃 레이블을 훈련 세트와 테스트 세트로 나눈다.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "# 모델 객체를 만들고 훈련 세트로 학습시킨다.\n",
    "logreg = LogisticRegression().fit(X_train, y_train)\n",
    "# 모델을 테스트 세트로 평가한다.\n",
    "print(\"테스트 세트 점수: {: .2f}\".format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터를 훈련 세트와 테스트 세트로 나누는 이유는 지금까지 본 적없는 새로운 데이터에 모델이 얼마나 잘 일반화되는지 측정하기 위해서이다. 모델이 훈련 세트에 잘 맞는 것보다, 학습 과정에 없던 데이터에 대해 예측을 얼마나 잘 하느냐가 중요하다.\n",
    "\n",
    "이번 장에서는 두 가지 관점에서 이 평가 방법을 확장해 보겠다. \n",
    "\n",
    "먼저 안정적인 일반화 성능 측정 방법인 교차 검증을 소개하고, score 메서드가 제공하는 정확도와 R**2 값 이외에 분류와 회귀 성능을 측정하는 다른 방법을 알아보겠다.\n",
    "\n",
    "또 가장 좋은 일반화 성능을 얻기 위해서 지도 학습 모델의 매개변수를 조정하는 데 유용한 그리드 서치에 관해서도 알아본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
