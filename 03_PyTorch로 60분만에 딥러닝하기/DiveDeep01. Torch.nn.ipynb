{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiveDeep into PyTorch\n",
    "Tutorial을 따라하면서 발견한 궁금증을 해소하과 해결하지 못한 문제들을 해결하는 시간\n",
    "\n",
    "PyTorch Doc을 통해 하나하나 독파해 나가자!\n",
    "\n",
    "Torch Documentation: https://pytorch.org/docs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🤔 Q1. How to calculate the output size after Conv2d in PyTorch? -20.02.20.Thur pm4:20-<br>\n",
    "Link: http://bitly.kr/bbjdFjRp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ Complete! - 20.02.20.Thur pm5:23\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🤔 Q2. Linear layer inpt neurons number calculation after conv2d -20.02.20.Thur pm 4:20-<br>\n",
    "Link: http://bitly.kr/bH5wNhWr\n",
    "\n",
    "\n",
    "🙊 설명이 대박이다. <br/>\n",
    "다시 Torch NN 예제로 돌아가자! -20.02.20.Thur pm 6:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Convolutional Layer](#ConvLayer)\n",
    "    * [Conv2d](#Conv2d)\n",
    "    \n",
    "* [Linear](#Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# markdown Reference:\n",
    "# https://www.kaggle.com/general/24692"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Torch.nn\n",
    "Ref: https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Module\n",
    "CLASS<code>torch.nn.Module</code><br>\n",
    "\n",
    "Base class for all neural network modules.\n",
    "\n",
    "Your models should also subclass this class.\n",
    "\n",
    "Modules can also contain other Modules, allowwing to nest them in a tree structure. you can assign the submodules as regular attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5)\n",
    "        self.conv2 = nn.Conv2d(20, 20, 5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        return F.relu(self.conv2(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class<code>torch.nn.Linear(in_features, out_features, bias=True)</code>를 공부하던 중... nn.Lienar()모듈에 대한 이해가 잘 되지 않아 다시 nn 모듈로 돌아왔다. -20.02.21.Fri pm 3:25-\n",
    "\n",
    "👨‍🔧 다시 처음부터 차근차근히"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "예제로 배우는 파이토치<br>\n",
    "reference: https://tutorials.pytorch.kr/beginner/pytorch_with_examples.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>nn</code>패키지는 신경망 계층(layer)들과 거의 동일한 **Module**의 집합을 정의한다. \n",
    "\n",
    "Module은 입력 Tensor를 받고 출력 Tensor를 계산하는 한편, 학습 가능한 매개변수를 갖는 Tensor 같은 내부 상대(internal state)를 갖는다. <code>nn</code>패키지는 또한 신경망을 학습시킬 때 주로 사용하는 유용한 손실 함수들도 정의하고 있다.\n",
    "\n",
    "<code>nn</code>패키지를 사용하여 2계층 신경망을 구성해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 698.82275390625\n",
      "199 648.9466552734375\n",
      "299 605.8740844726562\n",
      "399 568.2747192382812\n",
      "499 534.7984619140625\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "\n",
    "# N은 배치 크기이며, D_in은 입력의 차원이다.(Dimension Input?)\n",
    "# H는 은닉층의 차원이며, D_out은 출력 차원이다.\n",
    "N, D_in, H, D_out = 64, 1000, 100, 10  # 각각 차례대로 배치 크기, D_in, H, D_out\n",
    "\n",
    "# 입력과 출력을 저장하기 위해 무작위 값을 갖는 Tensor를 생성한다.\n",
    "x = torch.randn(N, D_in)\n",
    "y = torch.randn(N, D_out)\n",
    "\n",
    "# nn 패키지를 사용하여 모델을 순차적 계층(sequence of layers)로 정의한다.\n",
    "# nn.Sequential은 다르 Module들을 포함하는 Module로, 그 Module들을 순차적으로 적용하여 출력을 생성한다.\n",
    "# 각각의 Linear Module은 선형 함수를 사용하여 입력으로부터 출력을 계산하고,\n",
    "# 내부 Tensor에 가중치와 편향을 저장한다.\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(D_in, H),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(H, D_out),\n",
    ")\n",
    "\n",
    "# 또한 nn 패키지에는 널리 사용하는 손실 함수들에 대한 정의도 포함하고 있다.\n",
    "# 여기서는 평균 제곱 오차(MSE: Mean Squared Error)를 손실 함수로 사용한다.\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "learning_rate = 1e-4\n",
    "for t in range(500):\n",
    "    # 순전파 단계: 모델에 x를 전달하여 예상되는 y 값을 계산한다.\n",
    "    # Module 객체는 __call__ 연산자를 덮어써(Override) 함수처럼 호출할 수 있게 한다.\n",
    "    # 이렇게 함으로써 입력 데이터의 Tensor를 Module에 전달하여 출력 데이터 Tensor를 생성한다.\n",
    "    y_pred = model(x)\n",
    "    \n",
    "    # 손실을 계산하고 출력한다. 예측한 y와 정답인 y를 갖는 Tensor들을 전달하고, \n",
    "    # 손실 함수는 손실 값을 갖는 Tensor를 반환한다.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if t % 100 == 99:\n",
    "        print(t, loss.item())\n",
    "        \n",
    "        # 역전파 단계를 실행하기 전에 변화도를 0으로 만든다.\n",
    "        model.zero_grad()\n",
    "        \n",
    "        # 역전파 단계: 모델의 학습 가능한 모든 매개변수에 대해 손실의 변화도를 계산한다.\n",
    "        # 내부적으로 각 Module의 매개변수는 requires_grad=True 일 때, Tensor 내에 저장되므로,\n",
    "        # 이 호출은 모든 모델의 모든 학습 가능한 매개변수의 변화도를 계산하게 된다.\n",
    "        loss.backward()\n",
    "        \n",
    "        # 경사하강법(gradient descent)를 사용하여 가중치를 갱신한다.\n",
    "        # 각 매개변수는 Tensor이므로 이전에 했던 것과 같이 변화도에 접근할 수 있다.\n",
    "        with torch.no_grad():\n",
    "            for param in model.parameters():\n",
    "                param -= learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 id=\"Conv2d\">Conv2d</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class <code>torch.nn.Conv2d()</code>\n",
    "\n",
    "torch.nn.Conv2d(in_channels, out_channels, kernel_size, stiride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<button type=\"button\">Definition</button><br> Applies a 2D convolution over an input signal composed of several input planes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여러 평면으로 이루어진 입력 신호에 2D convolution을 적용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* in_channels (python:int) – Number of channels in the input image\n",
    "\n",
    "* out_channels (python:int) – Number of channels produced by the convolution\n",
    "\n",
    "* kernel_size (python:int or tuple) – Size of the convolving kernel\n",
    "\n",
    "* stride (python:int or tuple, optional) – Stride of the convolution. Default: 1\n",
    "\n",
    "* padding (python:int or tuple, optional) – Zero-padding added to both sides of the input. Default: 0\n",
    "\n",
    "* padding_mode (string, optional) – zeros\n",
    "\n",
    "* dilation (python:int or tuple, optional) – Spacing between kernel elements. Default: 1\n",
    "\n",
    "* groups (python:int, optional) – Number of blocked connections from input channels to output channels. Default: 1\n",
    "\n",
    "* bias (bool, optional) – If True, adds a learnable bias to the output. Default: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# With square kernels and equal stride\n",
    "m = nn.Conv2d(16, 33, 3, stride=2)  # in_channels=16, out_channels=33, kernel_size(filter_size)=3,\n",
    "                                    # stride=2\n",
    "# non-square kernels and unequal stride and with padding\n",
    "m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\n",
    "\n",
    "# non-square kernels and unequal stride and with padding and dilation\n",
    "# m = nn.Conv2d(16, 33, (3, 5), stride=(2,1), padding=(4, 2), dilation=(3, 1))\n",
    "input = torch.randn(20, 16, 50, 100)\n",
    "output = m(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 33, 28, 100])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# Q1. How to calculate the output size after Conv2d in PyTorch\n",
    "# https://discuss.pytorch.org/t/how-to-calculate-the-output-size-after-conv2d-in-pytorch/20405\n",
    "\n",
    "inputs = torch.rand(1, 1, 10, 10)\n",
    "mod = nn.Conv2d(1, 32, 3, 2, 1)\n",
    "out = mod(inputs)\n",
    "print(out.shape)  # 어떤 값이 출력될까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4 id=\"Lienar\">Linear</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class<code>torch.nn.Linear(in_features, out_features, bias=True)</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applies a linear transformation to the incoming data: y = xAT + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters<br>\n",
    "* in_features - size of each input sample\n",
    "* out_features - size of each output sample\n",
    "* bias - If set to False, the layer will not learn an additive bias. Default: <code>True</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input.shape:  torch.Size([128, 20])\n",
      "torch.Size([128, 30])\n"
     ]
    }
   ],
   "source": [
    "m = nn.Linear(20, 30)  # in_features = 20, out_features = 30\n",
    "input = torch.randn(128, 20)\n",
    "print('input.shape: ', input.shape)\n",
    "output = m(input)\n",
    "print(output.size()) # ???!?!?!  -20.02.21.Fri pm 12:40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이게 왜 이해가 안가지... 뭐지..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3035, -0.2441, -0.2721,  ...,  0.9307, -0.1898,  0.0967],\n",
      "        [-2.2034, -1.1245,  0.0411,  ...,  0.5764, -0.6538, -0.2309],\n",
      "        [-1.6404,  0.8272,  0.1735,  ...,  1.3595,  0.5311,  1.5078],\n",
      "        ...,\n",
      "        [-0.6212,  1.2815,  0.7916,  ...,  0.7449, -0.7889,  1.0028],\n",
      "        [ 0.3250,  0.0128, -0.5722,  ...,  1.5311,  0.2628, -1.1692],\n",
      "        [-1.0568,  0.1525,  0.4658,  ..., -0.6502, -0.3048, -1.1291]])\n"
     ]
    }
   ],
   "source": [
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(1.3035)</td>\n",
       "      <td>tensor(-0.2441)</td>\n",
       "      <td>tensor(-0.2721)</td>\n",
       "      <td>tensor(1.8012)</td>\n",
       "      <td>tensor(1.9294)</td>\n",
       "      <td>tensor(2.4222)</td>\n",
       "      <td>tensor(1.5510)</td>\n",
       "      <td>tensor(-0.7361)</td>\n",
       "      <td>tensor(0.6903)</td>\n",
       "      <td>tensor(1.0940)</td>\n",
       "      <td>tensor(0.6094)</td>\n",
       "      <td>tensor(-1.0502)</td>\n",
       "      <td>tensor(0.9670)</td>\n",
       "      <td>tensor(1.1579)</td>\n",
       "      <td>tensor(0.7707)</td>\n",
       "      <td>tensor(0.5152)</td>\n",
       "      <td>tensor(0.2413)</td>\n",
       "      <td>tensor(0.9307)</td>\n",
       "      <td>tensor(-0.1898)</td>\n",
       "      <td>tensor(0.0967)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(-2.2034)</td>\n",
       "      <td>tensor(-1.1245)</td>\n",
       "      <td>tensor(0.0411)</td>\n",
       "      <td>tensor(0.7757)</td>\n",
       "      <td>tensor(-0.8950)</td>\n",
       "      <td>tensor(-1.4705)</td>\n",
       "      <td>tensor(-2.1596)</td>\n",
       "      <td>tensor(-0.3662)</td>\n",
       "      <td>tensor(-1.1190)</td>\n",
       "      <td>tensor(1.0754)</td>\n",
       "      <td>tensor(-0.3060)</td>\n",
       "      <td>tensor(0.3282)</td>\n",
       "      <td>tensor(-0.7042)</td>\n",
       "      <td>tensor(-1.1023)</td>\n",
       "      <td>tensor(-0.5411)</td>\n",
       "      <td>tensor(0.8595)</td>\n",
       "      <td>tensor(-1.4358)</td>\n",
       "      <td>tensor(0.5764)</td>\n",
       "      <td>tensor(-0.6538)</td>\n",
       "      <td>tensor(-0.2309)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(-1.6404)</td>\n",
       "      <td>tensor(0.8272)</td>\n",
       "      <td>tensor(0.1735)</td>\n",
       "      <td>tensor(0.4321)</td>\n",
       "      <td>tensor(-0.0466)</td>\n",
       "      <td>tensor(1.1273)</td>\n",
       "      <td>tensor(-0.6599)</td>\n",
       "      <td>tensor(-1.0778)</td>\n",
       "      <td>tensor(0.8083)</td>\n",
       "      <td>tensor(1.3652)</td>\n",
       "      <td>tensor(2.2923)</td>\n",
       "      <td>tensor(2.6808)</td>\n",
       "      <td>tensor(0.5248)</td>\n",
       "      <td>tensor(-0.4709)</td>\n",
       "      <td>tensor(-0.7522)</td>\n",
       "      <td>tensor(-1.1187)</td>\n",
       "      <td>tensor(-1.0345)</td>\n",
       "      <td>tensor(1.3595)</td>\n",
       "      <td>tensor(0.5311)</td>\n",
       "      <td>tensor(1.5078)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(-1.6998)</td>\n",
       "      <td>tensor(1.4340)</td>\n",
       "      <td>tensor(-0.2018)</td>\n",
       "      <td>tensor(0.8807)</td>\n",
       "      <td>tensor(-0.4671)</td>\n",
       "      <td>tensor(-2.2015)</td>\n",
       "      <td>tensor(1.5113)</td>\n",
       "      <td>tensor(-1.2477)</td>\n",
       "      <td>tensor(0.7252)</td>\n",
       "      <td>tensor(-1.0329)</td>\n",
       "      <td>tensor(-0.9388)</td>\n",
       "      <td>tensor(0.5623)</td>\n",
       "      <td>tensor(-1.8487)</td>\n",
       "      <td>tensor(-1.1583)</td>\n",
       "      <td>tensor(-1.3891)</td>\n",
       "      <td>tensor(0.2192)</td>\n",
       "      <td>tensor(-0.3293)</td>\n",
       "      <td>tensor(0.3003)</td>\n",
       "      <td>tensor(0.9298)</td>\n",
       "      <td>tensor(0.8206)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(0.5909)</td>\n",
       "      <td>tensor(-0.3114)</td>\n",
       "      <td>tensor(0.5571)</td>\n",
       "      <td>tensor(0.7769)</td>\n",
       "      <td>tensor(-0.2031)</td>\n",
       "      <td>tensor(-0.0492)</td>\n",
       "      <td>tensor(-1.9010)</td>\n",
       "      <td>tensor(-0.1413)</td>\n",
       "      <td>tensor(-0.9198)</td>\n",
       "      <td>tensor(-0.3160)</td>\n",
       "      <td>tensor(-1.6592)</td>\n",
       "      <td>tensor(-1.5972)</td>\n",
       "      <td>tensor(0.1778)</td>\n",
       "      <td>tensor(0.6365)</td>\n",
       "      <td>tensor(1.0252)</td>\n",
       "      <td>tensor(-1.0993)</td>\n",
       "      <td>tensor(-0.4021)</td>\n",
       "      <td>tensor(-1.6923)</td>\n",
       "      <td>tensor(1.6547)</td>\n",
       "      <td>tensor(0.4241)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0                1                2               3  \\\n",
       "0   tensor(1.3035)  tensor(-0.2441)  tensor(-0.2721)  tensor(1.8012)   \n",
       "1  tensor(-2.2034)  tensor(-1.1245)   tensor(0.0411)  tensor(0.7757)   \n",
       "2  tensor(-1.6404)   tensor(0.8272)   tensor(0.1735)  tensor(0.4321)   \n",
       "3  tensor(-1.6998)   tensor(1.4340)  tensor(-0.2018)  tensor(0.8807)   \n",
       "4   tensor(0.5909)  tensor(-0.3114)   tensor(0.5571)  tensor(0.7769)   \n",
       "\n",
       "                 4                5                6                7  \\\n",
       "0   tensor(1.9294)   tensor(2.4222)   tensor(1.5510)  tensor(-0.7361)   \n",
       "1  tensor(-0.8950)  tensor(-1.4705)  tensor(-2.1596)  tensor(-0.3662)   \n",
       "2  tensor(-0.0466)   tensor(1.1273)  tensor(-0.6599)  tensor(-1.0778)   \n",
       "3  tensor(-0.4671)  tensor(-2.2015)   tensor(1.5113)  tensor(-1.2477)   \n",
       "4  tensor(-0.2031)  tensor(-0.0492)  tensor(-1.9010)  tensor(-0.1413)   \n",
       "\n",
       "                 8                9               10               11  \\\n",
       "0   tensor(0.6903)   tensor(1.0940)   tensor(0.6094)  tensor(-1.0502)   \n",
       "1  tensor(-1.1190)   tensor(1.0754)  tensor(-0.3060)   tensor(0.3282)   \n",
       "2   tensor(0.8083)   tensor(1.3652)   tensor(2.2923)   tensor(2.6808)   \n",
       "3   tensor(0.7252)  tensor(-1.0329)  tensor(-0.9388)   tensor(0.5623)   \n",
       "4  tensor(-0.9198)  tensor(-0.3160)  tensor(-1.6592)  tensor(-1.5972)   \n",
       "\n",
       "                12               13               14               15  \\\n",
       "0   tensor(0.9670)   tensor(1.1579)   tensor(0.7707)   tensor(0.5152)   \n",
       "1  tensor(-0.7042)  tensor(-1.1023)  tensor(-0.5411)   tensor(0.8595)   \n",
       "2   tensor(0.5248)  tensor(-0.4709)  tensor(-0.7522)  tensor(-1.1187)   \n",
       "3  tensor(-1.8487)  tensor(-1.1583)  tensor(-1.3891)   tensor(0.2192)   \n",
       "4   tensor(0.1778)   tensor(0.6365)   tensor(1.0252)  tensor(-1.0993)   \n",
       "\n",
       "                16               17               18               19  \n",
       "0   tensor(0.2413)   tensor(0.9307)  tensor(-0.1898)   tensor(0.0967)  \n",
       "1  tensor(-1.4358)   tensor(0.5764)  tensor(-0.6538)  tensor(-0.2309)  \n",
       "2  tensor(-1.0345)   tensor(1.3595)   tensor(0.5311)   tensor(1.5078)  \n",
       "3  tensor(-0.3293)   tensor(0.3003)   tensor(0.9298)   tensor(0.8206)  \n",
       "4  tensor(-0.4021)  tensor(-1.6923)   tensor(1.6547)   tensor(0.4241)  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(input)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 20)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
