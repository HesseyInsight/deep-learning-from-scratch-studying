{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN 직접 만들어보기!(Feat. 쉽게 씌여진 GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This Notebook referenced <code><a href='https://dreamgonfly.github.io/2018/03/17/gan-explained.html'>쉽게 씌여진 GAN</a></code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "* 오늘 풀어볼 문제(GAN Tutorial)\n",
    "    * 0부터 9까지 숫자 모양의 손글씨 이미지를 생성하는 문제\n",
    "    * Dataset: MNIST(손글씨 데이터셋으로 딥러닝계의 \"Hello World!\"라고 합니다!)\n",
    "    * 비교적 간단한 문제지만 GAN의 원리는 어떤 문제에도 동일하게 적용되기 때문에 유용한 예제가 될 것이라고 합니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 전체코드는 <a href='https://github.com/dreamgonfly/GAN-tutorial'>여기서</a> 확인 가능하다고 합니다!(쉽씌 GAN 저자 조용래님의 코드)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시작하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "가장 먼저 할 일은 library를 불러오는 일입니다.<br>\n",
    "본 튜토리얼에서 사용하는 MNIST Dataset은 Pytorch torchivision에서 받을 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <코드1> 라이브러리 및 데이터 불러오기\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform\n",
    "* 전처리 방식 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>torchvision.transforms</code>?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # 데이터를 파이토치의 Tensor 형식으로 바꿔준다.\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))  # 픽셀 값 0~1 -> -1 ~ 1 변경\n",
    "])\n",
    "'''\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                          # 데이터를 파이토치의 Tensor 형태로 변환\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))  # 0~1인 픽셀값 -> -1 ~ 1로 변경! \n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "* 데이터 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Original Code\n",
    "\n",
    "mnist = datasets.MNIST(root='data', download=True, transform=transform)\n",
    "'''\n",
    "\n",
    "# Review\n",
    "# MNIST 데이터셋을 불러옵니다. 지정한 폴더에 없을 경우 자동으로 다운로드 합니다.\n",
    "\n",
    "mnist = datasets.MNIST(root='data', download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "* 데이터를 한 번에 batch_size만큼만 가져오는 dataloader를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "'''\n",
    "# Original Code\n",
    "\n",
    "dataloader = DataLoader(mnist, batch_size=60, shuffle=True)\n",
    "'''\n",
    "\n",
    "# Review\n",
    "dataloader = DataLoader(mnist, batch_size=60, shuffle=True)  # batch_size:\n",
    "                                                             # shuffle=True: have the data reshuffled at every epoch (default: ``False``).\n",
    "                                                             # https://pytorch.org/docs/1.1.0/_modules/torch/utils/data/dataloader.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n=======\\nSummary\\n=======\\n\\n# <코드1> 라이브러리 및 데이터 불러오기\\n\\nimport torch\\nimport torch.nn as nn\\nfrom torch.optim import Adam\\nfrom torchvision import datasets, transforms\\nfrom torch.utils.data import DataLoader\\nfrom torch.autograd import Variable\\n\\n#데이터 전처리 방식을 지정한다.\\ntransform = transforms.Compose([\\n  transforms.ToTensor(), # 데이터를 파이토치의 Tensor 형식으로바꾼다.\\n  transforms.Normalize(mean=(0.5,), std=(0.5,)) # 픽셀값 0 ~ 1 -> -1 ~ 1\\n])\\n\\n#MNIST 데이터셋을 불러온다. 지정한 폴더에 없을 경우 자동으로 다운로드한다.\\nmnist =datasets.MNIST(root='data', download=True, transform=transform)\\n\\n#데이터를 한번에 batch_size만큼만 가져오는 dataloader를 만든다.\\ndataloader =DataLoader(mnist, batch_size=60, shuffle=True)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "===========\n",
    "  Summary\n",
    "===========\n",
    "\n",
    "# <코드1> 라이브러리 및 데이터 불러오기\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#데이터 전처리 방식을 지정한다.\n",
    "transform = transforms.Compose([\n",
    "  transforms.ToTensor(), # 데이터를 파이토치의 Tensor 형식으로바꾼다.\n",
    "  transforms.Normalize(mean=(0.5,), std=(0.5,)) # 픽셀값 0 ~ 1 -> -1 ~ 1\n",
    "])\n",
    "\n",
    "#MNIST 데이터셋을 불러온다. 지정한 폴더에 없을 경우 자동으로 다운로드한다.\n",
    "mnist =datasets.MNIST(root='data', download=True, transform=transform)\n",
    "\n",
    "#데이터를 한번에 batch_size만큼만 가져오는 dataloader를 만든다.\n",
    "dataloader =DataLoader(mnist, batch_size=60, shuffle=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리와 데이터를 불러왔다. 이제 다음으로 할 일은 GAN의 2가지 요소인 생성자와 구분자를 만들어보는 일이다. 우선 생성자(Generator)를 먼저 만들어보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 생성자(Generator)\n",
    "    * 랜덤 벡터 'z'를 입력으로 받아 가짜 이미지를 출력하는 함수이다.\n",
    "    * 여기서 'z'는 단순하게 균등 분포(Uniform Distribution)나 정규 분포(Normal Distribution)에서 무작위로 추출된 값이다.\n",
    "    * 생성자는 이렇게 단순한 분포를 사람 얼굴 이미지와 같은 복잡한 분포로 매핑(Mapping)하는 함수라고 볼수 있다.\n",
    "    * 생성자 모델에 충분한 수의 매개 변수가 있다면 어떤 복잡한 분포도 근사할 수 있다고 알려져있다.\n",
    "\n",
    "\n",
    "* 정리\n",
    "    * Generator는 Uniform Distribution 또는 Noraml Distribution에서 무작위로 추출한 z로부터 가짜 이미지를 생성한다.<br>\n",
    "    * Generator는 이처럼 단순한 분포를 사람 얼굴 이미지와 같은 복잡한 분포로 Mapping시켜주는 함수이다.\n",
    "    * 일반적으로 Generator Model에 충분한 수의 매개 변수가 있다면 어떤 복잡한 분포도 근사할 수 있다고 알려져있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*신기하다... 단순 분포의 값을 사람 얼굴 이미지와 같은 복잡한 분포로 어떻게 Mapping시켜주는걸까?*<br>\n",
    "Tutorial이 끝나갈때 쯤에는 알 수 있지 않을까? 기대되는 부분이다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 생성자 모델에 충분한 수의 매개 변수가 있다면 어떤 복잡한 분포도 근사할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/gan_distribution_mapping.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'z'벡터가 존재하는 공간 == Latent Space\n",
    "    * 'z'벡터가 존재하는 공간을 <code>잠재공간(Latent Space)</code>라고도 부르다.\n",
    "    * 본 Tutorial에서는 Latent Space의 크기를 임의로 100차원으로 뒀다.\n",
    "    * 제한은 없으나 우리가 나타내려고 하는 대상의 정보를 충분히 담을 수 있을 만큼 커야한다.\n",
    "    * GAN은 우리가 이해할 수 없는 방식이지만 'z'벡터의 값을 이미지의 속성에 매핑시키기 떄문이다. <- What?!\n",
    "    * 뒤에서 살펴볼 GAN의 파생 모델에서 잠재 공간의 의미를 더욱 자세히 이해할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 생성자에 충분한 수의 매개 변수를 확보하기 위해, 본 구현에서는 선형 레이어를 쌓아 생성자를 만들었다.\n",
    "    * 선형 레이어(Linear Layer, Fully Connected Layer, Linear Transformation)는 속해져있는 모든 뉴런이 이전 레이어의 모든 뉴런과 연결되는 가장 단순한 구조의 레이어이다. (Fully connected Layer를 의미하는게 아닌가요?)\n",
    "    * 이 모델에서는 100차원의 랜덤 벡터를 받아 이를 256개의 뉴런을 가진 레이어로 보내고 다시 레이어의 크기를 512, 1024로 점점 증가시켰다.\n",
    "    * 마지막에는 출력을 MNIST 이미지의 크기로 맞추기 위해 레이어의 크기를 28x28로 줄였다.\n",
    "    \n",
    "* 정리\n",
    "    * Generator에 충분한 수의 매개 변수 확보를 위한 선형 레이어 쌓기\n",
    "    * Fully connected Layer를 구성함\n",
    "    * <code>100차원의 Random Vector Z -> 256 -> 512 -> 1024 -> 28*28 변환(MNIST 이미지의 크기로 맞추기 위함)</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 활성화 함수로는 Leaky ReLU를 사용했다.\n",
    "    * Leaky ReLU에 대한 설명은 생략\n",
    "* 여러 레이어와 활성 함수를 쌓은 덕분에 MNIST 데이터 분포를 근사할 수 있는 충분한 표현력(Representation Power)를 얻을 수 있었다.\n",
    "* 더욱 복잡한 문제를 풀기 위해서는 더 깊은 레이어 구조와 더 많은 양의 매개 변수가 필요할 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generator Summary\n",
    "\n",
    "* Generator는 Uniform Distribution 또는 Noraml Distribution에서 <code>무작위로 추출한 z로부터 가짜 이미지를 생성</code>한다.\n",
    "* Generator는 이처럼 단순한 분포를 사람 얼굴 이미지와 같은 복잡한 분포로 Mapping시켜주는 함수이다.\n",
    "* 일반적으로 Generator Model에 충분한 수의 매개 변수가 있다면 어떤 복잡한 분포도 근사할 수 있다고 알려져있다.\n",
    "* Generator에 충분한 수의 매개 변수(Parameter)를 확보하기 위해서는 선형 레이어를 쌓아햐 한다.\n",
    "* Fully Connected Layer로 구성을해준다.\n",
    "* 차원수: <code>100차원의 Random Vector Z -> 256 -> 512 -> 1024 -> 28*28 변환(MNIST 이미지의 크기로 맞추기 위함)</code>\n",
    "* 여러 레이어와 Leaky ReLU(활성화 함수를 쌓아 충분한 표현력(Representation Power)를 얻는다.\n",
    "* 더 복잡한 문제를 풀기 위해서는 더 깊은 레이어 구조와 더 많은 양의 매개 변수가 필요하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <코드 2> GAN의 생성자(Generator)\n",
    "\n",
    "# 생성자는 랜덤 벡터 z를 입력으로 받아 가짜 이미지를 출력한다.\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    # 네트워크 구조\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(in_features=100, out_features=256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=256, out_features=512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=1024, out_features=28*28),\n",
    "            nn.Tanh())\n",
    "    \n",
    "    # (batch_size x 100) 크기의 랜덤 벡터를 받아\n",
    "    # 이미지를 (batch_size x 1 x 28 x 28) 크기로 출력한다.\n",
    "    # batch_size는 60이기에 입력 값의 형상은 (60, 100)\n",
    "    # (60, 100) -> (60, 256), (60, 512), (60, 1024), (60, 28*28) -> (-1, 1, 28, 28)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        return self.main(inputs).view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 구분자(Discriminator)\n",
    "    * Discriminator는 이미지를 입력으로 받고 그 이미지가 진짜일 확률을 0과 1 사이의 숫자 하나로 출력하는 함수다.\n",
    "    * 구분자의 구현은 생성자와 마찬가지로 4개의 선형 레이어를 쌓았다.\n",
    "    * 마찬가지 활성화 함수로는 LeakyReLU를 사용했다.\n",
    "    * 입력 이미지의 크기인 28x28이 1024, 512, 256으로 줄다 마지막에는 확률값을 나타내는 숫자 하나를 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <코드 3> GAN의 구분자 (Discriminator)\n",
    "\n",
    "# 구분자는 이미지를 입력으로 받아 이미지가 진짜인지 가짜인지를 출력한다.\n",
    "'''\n",
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    # 네트워크 구조\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28, out_features=1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=256, out_features=1),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    # (batch_size x 1 x 28 x 28) 크기의 이미지를 받아\n",
    "    # 이미지가 진짜일 확률을 0~1 사이로 출력\n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs.view(-1, 28* 28)\n",
    "        return self.main(inputs)\n",
    "'''    \n",
    "    \n",
    "    \n",
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28, out_features=1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=256, out_features=1),\n",
    "            nn.Sigmoid())\n",
    "                \n",
    "    # (batch_size x 1 x 28 x 28)크기의 이미지를 입력으로 받아\n",
    "    # 이미지가 진짜일 확률을 0~1 사이의 값으로 출력한다\n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs.view(-1, 28*28)\n",
    "        return self.main(inputs)\n",
    "    \n",
    "    \n",
    "    # (batch_size, 1, 28, 28) -> (batch_size, 28, 28) -> (batch_size, 1024) -> (batch_size, 512) ->\n",
    "    # -> (batch_size, 256) -> (batch_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator와 Discriminator 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator()\n",
    "D = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 학습시키기\n",
    "    * 이제부터는 만들어진 네트워크 구조를 학습하는 방법에 대해 알아보자\n",
    "    * 학습을 위해서는 모델을 평가할 수 있어야 한다.\n",
    "        * 모델의 평가 지표가 좋아지는 방향으로 매개 변수를 업데이트 할 것이기 떄문이다.\n",
    "    * Discriminator(구분자)의 출력값은 이미지가 진짜일 확률이고, 이 확률이 얼마나 정답과 가까운지를 측정하기 위해 Binary Cross Entropy Loss Function을 사용할 것이다.\n",
    "    * 이 함수는 구분자가 출력한 확률값이 정답에 가까우면 낮아지고 구분자가 출력한 값이 정답에서 멀어지면 높아진다\n",
    "    * 즉 학습이 잘 됬을수록 손실 함수의 값은 작아진다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 매개변수 최적화 함수\n",
    "    * Generator(생성자)와 Discriminator(구분자)의 매개 변수를 업데이트하는 최적화 함수가 각각 하나 필요하다\n",
    "    * 가장 널리 사용되는 Adam을 사용하도록 한다.\n",
    "    * Adam은 매개변수마다 업데이트 속도를 최적으로 조절하는 효율적인 최적화 기법이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <코드 5> 손실 함수와 최적화 기법 지정하기\n",
    "\n",
    "# Binary Cross Entropy loss\n",
    "criterion = nn.BCELoss()  ## Binary Cross Entropy Loss\n",
    "\n",
    "# 생성자의 매개 변수를 최적화하는 Adam optimizer\n",
    "G_optimizer = Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))  # what is betas??\n",
    "# 구분자의 매개 변수를 최적화하는 Adam optimizer \n",
    "D_optimizer = Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))  #  coefficients \n",
    "                                                                   # used for computing running averages of gradient and its square (default: (0.9, 0.999))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Epoch\n",
    "    * 모델 학습을 위해 전체 데이터셋을 여러 번 돌며 매개 변수를 조금씩 업데이트한다.\n",
    "    * 데이터셋을 한 번 도는 것을 1 Epoch이라고 한다.\n",
    "    * 여기서는 100 Epoch을 돌 것이다.\n",
    "    * 각 Epoch마다 Batch Size인 60만큼 데이터를 가져와 모델을 학습시킨다.\n",
    "    * MNIST 학습 데이터의 개수가 6만개이니 1에폭마다 1000번씩 학습이 이루어지는 셈이다!\n",
    "        * e.g) 1-Epoch -> 60개의 batch가 1000번 학습된다(데이터의 개수가 6만개 이기 떄문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <코드 6> 모델 학습을 위한 반복문\n",
    "\n",
    "\n",
    "# 데이터셋을 100번 돌며 학습한다\n",
    "for epoch in range(100):\n",
    "    \n",
    "    # 한 번에 batch_size만큼 데이터를 가져온다.\n",
    "    for real_data, _ in dataloader:\n",
    "        batch_size = real_data.size(0)\n",
    "        \n",
    "    # 데이터를 파이토치의 변수로 변환한다.\n",
    "        real_data = Variable(real_data)\n",
    "        \n",
    "        # ...  코드 7과 이어지는구나!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 먼저 Discriminator를 학습시킨다\n",
    "    * Discriminator는 진짜 이미지를 입력하면 1에 가까운 확률값을 출력한다\n",
    "    * 가짜 데이터를 입력하면 0에 가까운 확률값을 출력한다.\n",
    "    * 따라서 Discriminator의 손실 함수는 두 가지의 합으로 이루어진다.\n",
    "    * (진짜 이미지를 입력했을 떄의 출력값과 1의 차이) + (가짜 이미지를 입력했을 때 출력값과 0의 차이)\n",
    "    * 이 손실 함수의 값을 최소화 하는 방향으로 매개변수가 업데이트 된다.\n",
    "    \n",
    "    \n",
    "* 파이토치에서는 역전파를 통해 간단한 방법으로 계산된 각 변수의 미분 값을 구할 수 있다.\n",
    "    * 그 상태에서 최적화 함수를 실행시키면 매개 변수가 한 번 업데이트된다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <코드7> Training Discriminator\n",
    "    ## 정답지에 해당하는 변수를 만든다\n",
    "    # Image가 진짜일 때 정답 값은 1이고 가짜일 때는 0이다\n",
    "    target_real = Variable(torch.ones(batch_size, 1))\n",
    "    target_fake = Variable(torch.zeros(batch_size, 1))\n",
    "    \n",
    "    ## Train real_data\n",
    "    # 진짜 이미지를 구분자에 넣는다\n",
    "    D_result_from_real = D(real_data)\n",
    "    # 구분자의 출력값이 정답지인 1에서 멀수록 loss가 높아진다\n",
    "    D_loss_real = criterion(D_result_from_real, target_real)\n",
    "   \n",
    "    ## Generating fake image \n",
    "    # 생성자에 입력으로 줄 랜덤 벡터 z를 만든다.\n",
    "    z = Variable(torch.randn((batch_size, 100)))\n",
    "    # 생성자로 가짜 이미지를 생성한다.\n",
    "    fake_data = G(z)  # fake_data == 가짜 이미지 데이터, \n",
    "                      # 이 데이터를 Discriminator로 학습시켜 loss를 구한다!\n",
    "                      # 가짜 이미지를 잘 구분할수록 loss는 줄어들고 반대의 경우 loss는 커지겠지!\n",
    "            \n",
    "    # 생성자가 만든 가짜 이미지를 구분자에 넣는다\n",
    "    D_result_from_fake = D(fake_data)\n",
    "    \n",
    "    # 구분자의 출력값이 정답인 0에서 멀수록 loss가 높아진다\n",
    "    D_loss_fake = criterion(D_result_from_fake, target_fake)\n",
    "    \n",
    "    ## Multi-Loss\n",
    "    # 구분자의 loss는 두 문제에서 계산된 loss의 합이다.\n",
    "    D_loss = D_loss_real + D_loss_fake\n",
    "    \n",
    "    # 구분자의 매개 변수의 미분값을 0으로 초기화한다.\n",
    "    D.zero_grad()\n",
    "    \n",
    "    # 역전파를 통해 매개변수의 loss에 대한 미분값을 계산한다.\n",
    "    D_loss.backward()\n",
    "    \n",
    "    # 최적화 기법을 이용해 구분자의 매개 변수를 업데이트하낟.\n",
    "    D_optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "와...이거 좋은데~? -20.06.01.mon-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-22-8aa9788c61e5>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-22-8aa9788c61e5>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    z = Variable(torch.randn((batch_size, 100)))\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# <code 8> 생성자 학습시키기\n",
    "# 잠깐, 위에서 생성자 학습시키거 아녔어?? Fake Image Data 생성했는데?!\n",
    "# 일단 진행해보자.\n",
    "\n",
    "    # 생성자에 입력으로 줄 랜덤 벡터 z를 만든다.\n",
    "    z = Variable(torch.randn((batch_size, 100)))\n",
    "    z = z.cuda()\n",
    "    \n",
    "    # 생성자로 가짜 이미지를 생성한다.\n",
    "    fake_data = G(z)\n",
    "    \n",
    "    # 생성자가 만든 가짜 이미지를 구분자에 넣는다\n",
    "    D_result_from_fake = D(fake_data)\n",
    "    # 생성자의 입장에서 구분자의 출력값이 1에서 멀어질수록 loss가 높아진다.\n",
    "    # 위조지폐범의 입장에서 경찰이 진짜 지폐로 분류하기 원할테니깐!(1은 진짜지폐로 분류!)\n",
    "    G_loss = criterion(D_result_from_fake, target_real)\n",
    "    \n",
    "    # 생성자의 매개 변수의 미분값을 0로 초기화\n",
    "    G.zero_grad()\n",
    "    \n",
    "    # 역전파를 통해 매개 변수의 loss에 대한 미분값 계산\n",
    "    G_loss.backward()\n",
    "    \n",
    "    # 최적화 기법을 이용해 생성자의 매개 변수 업데이트\n",
    "    G_optimizer.step()\n",
    "    \n",
    "    \n",
    "# 위에서는 Discriminator의 loss를 학습하기 위해 Generator로 Fake Image를 만들어 학습했다면\n",
    "# <Code 8>은 Generator를 학습시키기 위함이군!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>Code 6, 7, 8</code>을 합쳐준다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 update D_Loss: tensor(0.2865, grad_fn=<AddBackward0>)\n",
      "0 update G_Loss: tensor(1.5037, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1 update D_Loss: tensor(0.2832, grad_fn=<AddBackward0>)\n",
      "1 update G_Loss: tensor(2.8324, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2 update D_Loss: tensor(0.5949, grad_fn=<AddBackward0>)\n",
      "2 update G_Loss: tensor(2.4875, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "3 update D_Loss: tensor(0.7003, grad_fn=<AddBackward0>)\n",
      "3 update G_Loss: tensor(3.1609, grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-cfebf68ececd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;31m# 최적화 기법을 이용해 생성자의 매개 변수 업데이트\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[0mG_optimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"update D_Loss:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                 \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# <코드 6> 모델 학습을 위한 반복문\n",
    "\n",
    "# 데이터셋을 100번 돌며 학습한다\n",
    "for epoch in range(100):\n",
    "    \n",
    "    # 한 번에 batch_size만큼 데이터를 가져온다.\n",
    "    for real_data, _ in dataloader:\n",
    "        batch_size = real_data.size(0)\n",
    "        \n",
    "    # 데이터를 파이토치의 변수로 변환한다.\n",
    "        real_data = Variable(real_data)\n",
    "        \n",
    "        # ...  코드 7과 이어지는구나!\n",
    "            # <코드7> Training Discriminator\n",
    "        ## 정답지에 해당하는 변수를 만든다\n",
    "        # Image가 진짜일 때 정답 값은 1이고 가짜일 때는 0이다\n",
    "        target_real = Variable(torch.ones(batch_size, 1))\n",
    "        target_fake = Variable(torch.zeros(batch_size, 1))\n",
    "\n",
    "        ## Train real_data\n",
    "        # 진짜 이미지를 구분자에 넣는다\n",
    "        D_result_from_real = D(real_data)\n",
    "        # 구분자의 출력값이 정답지인 1에서 멀수록 loss가 높아진다\n",
    "        D_loss_real = criterion(D_result_from_real, target_real)\n",
    "\n",
    "        ## Generating fake image \n",
    "        # 생성자에 입력으로 줄 랜덤 벡터 z를 만든다.\n",
    "        z = Variable(torch.randn((batch_size, 100)))\n",
    "        # 생성자로 가짜 이미지를 생성한다.\n",
    "        fake_data = G(z)  # fake_data == 가짜 이미지 데이터, \n",
    "                          # 이 데이터를 Discriminator로 학습시켜 loss를 구한다!\n",
    "                          # 가짜 이미지를 잘 구분할수록 loss는 줄어들고 반대의 경우 loss는 커지겠지!\n",
    "\n",
    "        # 생성자가 만든 가짜 이미지를 구분자에 넣는다\n",
    "        D_result_from_fake = D(fake_data)\n",
    "\n",
    "        # 구분자의 출력값이 정답인 0에서 멀수록 loss가 높아진다\n",
    "        D_loss_fake = criterion(D_result_from_fake, target_fake)\n",
    "\n",
    "        ## Multi-Loss\n",
    "        # 구분자의 loss는 두 문제에서 계산된 loss의 합이다.\n",
    "        D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "        # 구분자의 매개 변수의 미분값을 0으로 초기화한다.\n",
    "        D.zero_grad()\n",
    "\n",
    "        # 역전파를 통해 매개변수의 loss에 대한 미분값을 계산한다.\n",
    "        D_loss.backward()\n",
    "\n",
    "        # 최적화 기법을 이용해 구분자의 매개 변수를 업데이트하낟.\n",
    "        D_optimizer.step()\n",
    "        \n",
    "# <code 8> 생성자 학습시키기\n",
    "# 잠깐, 위에서 생성자 학습시키거 아녔어?? Fake Image Data 생성했는데?!\n",
    "# 일단 진행해보자.\n",
    "\n",
    "        # 생성자에 입력으로 줄 랜덤 벡터 z를 만든다.\n",
    "        z = Variable(torch.randn((batch_size, 100)))\n",
    "#         z = z.cuda()\n",
    "\n",
    "        # 생성자로 가짜 이미지를 생성한다.\n",
    "        fake_data = G(z)\n",
    "\n",
    "        # 생성자가 만든 가짜 이미지를 구분자에 넣는다\n",
    "        D_result_from_fake = D(fake_data)\n",
    "        # 생성자의 입장에서 구분자의 출력값이 1에서 멀어질수록 loss가 높아진다.\n",
    "        # 위조지폐범의 입장에서 경찰이 진짜 지폐로 분류하기 원할테니깐!(1은 진짜지폐로 분류!)\n",
    "        G_loss = criterion(D_result_from_fake, target_real)\n",
    "\n",
    "        # 생성자의 매개 변수의 미분값을 0로 초기화\n",
    "        G.zero_grad()\n",
    "\n",
    "        # 역전파를 통해 매개 변수의 loss에 대한 미분값 계산\n",
    "        G_loss.backward()\n",
    "\n",
    "        # 최적화 기법을 이용해 생성자의 매개 변수 업데이트\n",
    "        G_optimizer.step()\n",
    "\n",
    "    print(epoch, \"update D_Loss:\", D_loss)\n",
    "    print(epoch, \"update G_Loss:\", G_loss)\n",
    "\n",
    "# 위에서는 Discriminator의 loss를 학습하기 위해 Generator로 Fake Image를 만들어 학습했다면\n",
    "# <Code 8>은 Generator를 학습시키기 위함이군!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on CUDA GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CUDA 사용환경 check!! \n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch GPU 사용법\n",
    "\n",
    "* PyTorch - CUDA(GPU)사용하기\n",
    "    * Reference - <a href='https://yonghyuc.wordpress.com/2019/08/06/pytorch-cuda-gpu-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/'>PyTorch CUDA(GPU 사용하기) 조용현님의 블로그</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Machine을 학습시킬 때 GPU를 사용하게 되면 월등히 성능이 좋아진다.\n",
    "    * 먼저 지금 GPU를 사용하여 학습을 하는지 CPU를 사용하고 있는지 확인부터해보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Reference:\n",
    "    * <a href='https://tutorials.pytorch.kr/beginner/pytorch_with_examples.html'>PyTorch Example - Tensors</a>\n",
    "    * Numpy와 달리 PyTorch Tensor는 GPU를 활용하여 수치 연산을 가속화 할 수 있다.\n",
    "    * GPU에서 PyTorch Tensor를 실행하기 위해서는 단지 새로운 자료형으로 변환해주기만 하면 된다(cast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Returns a bool indicating if CUDA is currently available\n",
    "torch.cuda.is_available()\n",
    "\n",
    "# Return the index of a currently selected device\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #2 'mat1' in call to _th_addmm",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-76a9f9549496>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;31m## Train real_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;31m# 진짜 이미지를 구분자에 넣는다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0mD_result_from_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[1;31m# 구분자의 출력값이 정답지인 1에서 멀수록 loss가 높아진다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mD_loss_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD_result_from_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_real\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-23c098551334>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1368\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1370\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1371\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #2 'mat1' in call to _th_addmm"
     ]
    }
   ],
   "source": [
    "# <코드 6> 모델 학습을 위한 반복문\n",
    "\n",
    "# Tensor를 새로운 자료형으로 변환하기(Cast)\n",
    "# dtype, device 정의\n",
    "'''\n",
    "# Use This\n",
    "dtype = torch.float\n",
    "device = torch.device(\"cpu\")\n",
    "device = torch.device(\"cuda:0\")  # GPU 실행방법\n",
    "\n",
    "# But it doesn't work in Variable\n",
    "\n",
    "'''\n",
    "\n",
    "'''\n",
    "# When Using Variable\n",
    "https://discuss.pytorch.org/t/will-all-variables-created-in-network-run-in-gpu/9968/7\n",
    "\n",
    "If you create a Variable in the forward(), it cannot switch to cuda automatically. \n",
    "you must specify .cuda() . Something like:\n",
    "\n",
    "h = Variable(torch.randn(2, batch_size, 256*2))\n",
    "h = h.cuda()\n",
    "\n",
    "My English is poor. Hope it can help you.\n",
    "\n",
    "'''\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "G = Generator().cuda()\n",
    "D = Discriminator().cuda()\n",
    "\n",
    "# 데이터셋을 100번 돌며 학습한다\n",
    "for epoch in range(100):\n",
    "    # 한 번에 batch_size만큼 데이터를 가져온다.\n",
    "    for real_data, _ in dataloader:\n",
    "        batch_size = real_data.size(0)\n",
    "        \n",
    "    # 데이터를 파이토치의 변수로 변환한다.\n",
    "        real_data = Variable(real_data)\n",
    "        \n",
    "# <코드7> Training Discriminator\n",
    "        ## 정답지에 해당하는 변수를 만든다\n",
    "        # Image가 진짜일 때 정답 값은 1이고 가짜일 때는 0이다\n",
    "        target_real = Variable(torch.ones(batch_size, 1))\n",
    "        target_real = target_real.cuda()\n",
    "        target_fake = Variable(torch.zeros(batch_size, 1))\n",
    "        target_fake = target_fake.cuda()\n",
    "\n",
    "        ## Train real_data\n",
    "        # 진짜 이미지를 구분자에 넣는다\n",
    "        D_result_from_real = D(real_data).cuda()\n",
    "        # 구분자의 출력값이 정답지인 1에서 멀수록 loss가 높아진다\n",
    "        D_loss_real = criterion(D_result_from_real, target_real)\n",
    "\n",
    "        ## Generating fake image \n",
    "        # 생성자에 입력으로 줄 랜덤 벡터 z를 만든다.\n",
    "        z = Variable(torch.randn((batch_size, 100)))\n",
    "        z = z.cuda()\n",
    "        # 생성자로 가짜 이미지를 생성한다.\n",
    "        fake_data = G(z)  # fake_data == 가짜 이미지 데이터, \n",
    "                          # 이 데이터를 Discriminator로 학습시켜 loss를 구한다!\n",
    "                          # 가짜 이미지를 잘 구분할수록 loss는 줄어들고 반대의 경우 loss는 커지겠지!\n",
    "\n",
    "        # 생성자가 만든 가짜 이미지를 구분자에 넣는다\n",
    "        D_result_from_fake = D(fake_data)\n",
    "\n",
    "        # 구분자의 출력값이 정답인 0에서 멀수록 loss가 높아진다\n",
    "        D_loss_fake = criterion(D_result_from_fake, target_fake)\n",
    "\n",
    "        ## Multi-Loss\n",
    "        # 구분자의 loss는 두 문제에서 계산된 loss의 합이다.\n",
    "        D_loss = D_loss_real + D_loss_fake\n",
    "\n",
    "        # 구분자의 매개 변수의 미분값을 0으로 초기화한다.\n",
    "        D.zero_grad()\n",
    "\n",
    "        # 역전파를 통해 매개변수의 loss에 대한 미분값을 계산한다.\n",
    "        D_loss.backward()\n",
    "\n",
    "        # 최적화 기법을 이용해 구분자의 매개 변수를 업데이트하낟.\n",
    "        D_optimizer.step()\n",
    "        \n",
    "# <code 8> 생성자 학습시키기\n",
    "# 잠깐, 위에서 생성자 학습시키거 아녔어?? Fake Image Data 생성했는데?!\n",
    "# 일단 진행해보자.\n",
    "\n",
    "        # 생성자에 입력으로 줄 랜덤 벡터 z를 만든다.\n",
    "        z = Variable(torch.randn((batch_size, 100)))\n",
    "        z = z.cuda()\n",
    "#         z = z.cuda()\n",
    "\n",
    "        # 생성자로 가짜 이미지를 생성한다.\n",
    "        fake_data = G(z)\n",
    "\n",
    "        # 생성자가 만든 가짜 이미지를 구분자에 넣는다\n",
    "        D_result_from_fake = D(fake_data)\n",
    "        # 생성자의 입장에서 구분자의 출력값이 1에서 멀어질수록 loss가 높아진다.\n",
    "        # 위조지폐범의 입장에서 경찰이 진짜 지폐로 분류하기 원할테니깐!(1은 진짜지폐로 분류!)\n",
    "        G_loss = criterion(D_result_from_fake, target_real)\n",
    "\n",
    "        # 생성자의 매개 변수의 미분값을 0로 초기화\n",
    "        G.zero_grad()\n",
    "\n",
    "        # 역전파를 통해 매개 변수의 loss에 대한 미분값 계산\n",
    "        G_loss.backward()\n",
    "\n",
    "        # 최적화 기법을 이용해 생성자의 매개 변수 업데이트\n",
    "        G_optimizer.step()\n",
    "\n",
    "    print(epoch, \"update D_Loss:\", D_loss)\n",
    "    print(epoch, \"update G_Loss:\", G_loss)\n",
    "\n",
    "# 위에서는 Discriminator의 loss를 학습하기 위해 Generator로 Fake Image를 만들어 학습했다면\n",
    "# <Code 8>은 Generator를 학습시키기 위함이군!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
