{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN 직접 만들어보기!(Feat. 쉽게 씌여진 GAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This Notebook referenced <code><a href='https://dreamgonfly.github.io/2018/03/17/gan-explained.html'>쉽게 씌여진 GAN</a></code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "* 오늘 풀어볼 문제(GAN Tutorial)\n",
    "    * 0부터 9까지 숫자 모양의 손글씨 이미지를 생성하는 문제\n",
    "    * Dataset: MNIST(손글씨 데이터셋으로 딥러닝계의 \"Hello World!\"라고 합니다!)\n",
    "    * 비교적 간단한 문제지만 GAN의 원리는 어떤 문제에도 동일하게 적용되기 때문에 유용한 예제가 될 것이라고 합니다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 전체코드는 <a href='https://github.com/dreamgonfly/GAN-tutorial'>여기서</a> 확인 가능하다고 합니다!(저자의 코드)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시작하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <코드1> 라이브러리 및 데이터 불러오기\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform\n",
    "* 전처리 방식 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>torchvision.transforms</code>?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # 데이터를 파이토치의 Tensor 형식으로 바꿔준다.\n",
    "    transforms.Normalize(mean=(0.5,), std=(0.5,))  # 픽셀 값 0~1 -> -1 ~ 1 변경\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "* 데이터 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b643b46049194fa5ad3a2b1aa6c0e1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f68cc689104b4ca7b146ac695859df5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3e5c4c3d3e408a922cf53a7e0f261a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to data\\MNIST\\raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6800af79d544cf0aac7506ff88272f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to data\\MNIST\\raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "mnist = datasets.MNIST(root='data', download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "* 데이터를 한 번에 batch_size만큼만 가져오는 dataloader를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(mnist, batch_size=60, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# <코드1> 라이브러리 및 데이터 불러오기\\n\\nimport torch\\nimport torch.nn as nn\\nfrom torch.optim import Adam\\nfrom torchvision import datasets, transforms\\nfrom torch.utils.data import DataLoader\\nfrom torch.autograd import Variable\\n\\n#데이터 전처리 방식을 지정한다.\\ntransform = transforms.Compose([\\n  transforms.ToTensor(), # 데이터를 파이토치의 Tensor 형식으로바꾼다.\\n  transforms.Normalize(mean=(0.5,), std=(0.5,)) # 픽셀값 0 ~ 1 -> -1 ~ 1\\n])\\n\\n#MNIST 데이터셋을 불러온다. 지정한 폴더에 없을 경우 자동으로 다운로드한다.\\nmnist =datasets.MNIST(root='data', download=True, transform=transform)\\n\\n#데이터를 한번에 batch_size만큼만 가져오는 dataloader를 만든다.\\ndataloader =DataLoader(mnist, batch_size=60, shuffle=True)\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "=======\n",
    "Summary\n",
    "=======\n",
    "\n",
    "# <코드1> 라이브러리 및 데이터 불러오기\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#데이터 전처리 방식을 지정한다.\n",
    "transform = transforms.Compose([\n",
    "  transforms.ToTensor(), # 데이터를 파이토치의 Tensor 형식으로바꾼다.\n",
    "  transforms.Normalize(mean=(0.5,), std=(0.5,)) # 픽셀값 0 ~ 1 -> -1 ~ 1\n",
    "])\n",
    "\n",
    "#MNIST 데이터셋을 불러온다. 지정한 폴더에 없을 경우 자동으로 다운로드한다.\n",
    "mnist =datasets.MNIST(root='data', download=True, transform=transform)\n",
    "\n",
    "#데이터를 한번에 batch_size만큼만 가져오는 dataloader를 만든다.\n",
    "dataloader =DataLoader(mnist, batch_size=60, shuffle=True)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라이브러리와 데이터를 불러왔다. 이제 다음으로 할 일은 GAN의 2가지 요소인 생성자와 구분자를 만들어보는 일이다. 우선 생성자(Generator)를 먼저 만들어보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 생성자(Generator)\n",
    "    * 랜덤 벡터 'z'를 입력으로 받아 가짜 이미지를 출력하는 함수이다.\n",
    "    * 여기서 'z'는 단순하게 균등 분포(Uniform Distribution)나 정규 분포(Normal Distribution)에서 무작위로 추출된 값이다.\n",
    "    * 생성자는 이렇게 단순한 분포를 사람 얼굴 이미지와 같은 복잡한 분포로 매핑(Mapping)하는 함수라고 볼수 있다.\n",
    "    * 생성자 모델에 충분한 수의 매개 변수가 있다면 어떤 복잡한 분포도 근사할 수 있다고 알려져있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*신기하다... 단순 분포의 값을 사람 얼굴 이미지와 같은 복잡한 분포로 어떻게 Mapping시켜주는걸까?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 생성자 모델에 충분한 수의 매개 변수가 있다면 어떤 복잡한 분포도 근사할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/gan_distribution_mapping.png\"></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'z'벡터가 존재하는 공간 == Latent Space\n",
    "    * 'z'벡터가 존재하는 공간을 잠재공간(Latent Space)라고도 부르다.\n",
    "    * 본 Tutorial에서는 Latent Space의 크기를 임의로 100차원으로 뒀다.\n",
    "    * 제한은 없으나 우리가 나타내려고 하는 대상의 정보를 충분히 담을 수 있을 만큼 커야한다.\n",
    "    * GAN은 우리가 이해할 수 없는 방식이지만 'z'벡터의 값을 이미지의 속성에 매핑시키기 떄문이다. <- What?!\n",
    "    * 뒤에서 살펴볼 GAN의 파생 모델에서 잠재 공간의 의미를 더욱 자세히 이해할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 생성자에 충분한 수의 매개 변수를 확보하기 위해, 본 구현에서는 선형 레이어를 쌓아 생성자를 만들었다.\n",
    "    * 선형 레이터(Linear Layer, Fully Connected Layer, Linear Transformation)는 속해져있는 모든 뉴런이 이전 레이어의 모든 뉴런과 연결되는 가장 단순한 구조의 레이어이다.\n",
    "    * 이 모델에서는 100차원의 랜덤 벡터를 받아 이를 256개의 뉴런을 가진 레이어로 보내고 다시 레이어의 크기를 512, 1024로 점점 증가시켰다.\n",
    "    * 마지막에는 출력을 MNIST 이미지의 크기로 맞추기 위해 레이어의 크기를 28x28로 줄였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 활성화 함수로는 Leaky ReLU를 사용했다.\n",
    "    * Leaky ReLU에 대한 설명은 생략\n",
    "* 여러 레이어와 활성 함수를 쌓은 덕분에 MNIST 데이터 분포를 근사할 수 있는 충분한 표현력(Representation Power)를 얻을 수 있었다.\n",
    "* 더욱 복잡한 문제를 풀기 위해서는 더 깊은 레이어 구조와 더 많은 양의 매개 변수가 필요할 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <코드 2> GAN의 생성자(Generator)\n",
    "\n",
    "# 생성자는 랜덤 벡터 z를 입력으로 받아 가짜 이미지를 출력한다.\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    # 네트워크 구조\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(in_features=100, out_features=256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=256, out_features=512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=1024, out_features=28*28),\n",
    "            nn.Tanh())\n",
    "    \n",
    "    # (batch_size x 100) 크기의 랜덤 벡터를 받아\n",
    "    # 이미지를 (batch_size x 1 x 28 x 28) 크기로 출력한다.\n",
    "    def forward(self, inputs):\n",
    "        return self.main(inputs).view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 구분자(Discriminator)\n",
    "    * Discriminator는 이미지를 입력으로 받고 그 이미지가 진짜일 확률을 0과 1 사이의 숫자 하나로 출력하는 함수다.\n",
    "    * 구분자의 구현은 생성자와 마찬가지로 4개의 선형 레이어를 쌓았다.\n",
    "    * 마찬가지 활성화 함수로는 LeakyReLU를 사용했다.\n",
    "    * 입력 이미지의 크기인 28x28이 1024, 512, 256으로 줄다 마지막에는 확률값을 나타내는 숫자 하나를 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <코드 3> GAN의 구분자 (Discriminator)\n",
    "\n",
    "# 구분자는 이미지를 입력으로 받아 이미지가 진짜인지 가짜인지를 출력한다.\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    # 네트워크 구조\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(in_features=28*28, out_features=1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=1024, out_features=512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=512, out_features=256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(in_features=256, out_features=1),\n",
    "            nn.Sigmoid())\n",
    "        \n",
    "    # (batch_size x 1 x 28 x 28) 크기의 이미지를 받아\n",
    "    # 이미지가 진짜일 확률을 0~1 사이로 출력\n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs.view(-1, 28, 28)\n",
    "        return self.main(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator와 Discriminator 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = Generator()\n",
    "D = Discriminator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 학습시키기\n",
    "    * 이제부터는 만들어진 네트워크 구조를 학습하는 방법에 대해 알아보자\n",
    "    * 학습을 위해서는 모델을 평가할 수 있어야 한다.\n",
    "        * 모델의 평가 지표가 좋아지는 방향으로 매개 변수를 업데이트 할 것이기 떄문이다.\n",
    "    * Discriminator(구분자)의 출력값은 이미지가 진짜일 확률이고, 이 확률이 얼마나 정답과 가까운지를 측정하기 위해 Binary Cross Entropy Loss Function을 사용할 것이다.\n",
    "    * 이 함수는 구분자가 출력한 확률값이 정답에 가까우면 낮아지고 구분자가 출력한 값이 정답에서 멀어지면 높아진다\n",
    "    * 즉 학습이 잘 됬을수록 손실 함수의 값은 작아진다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 매개변수 최적화 함수\n",
    "    * Generator(생성자)와 Discriminator(구분자)의 매개 변수를 업데이트하는 최적화 함수가 각각 하나 필요하다\n",
    "    * 가장 널리 사용되는 Adam을 사용하도록 한다.\n",
    "    * Adam은 매개변수마다 업데이트 속도를 최적으로 조절하는 효율적인 최적화 기법이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <코드 5> 손실 함수와 최적화 기법 지정하기\n",
    "\n",
    "# Binary Cross Entropy loss\n",
    "criterion = nn.BCELoss()  ## Binary Cross Entropy Loss\n",
    "\n",
    "# 생성자의 매개 변수를 최적화하는 Adam optimizer\n",
    "G_optimizer = Adam(G.parameters(), lr=0.0002, betas=(0.5, 0.999))  # what is betas??\n",
    "# 구분자의 매개 변수를 최적화하는 Adam optimizer \n",
    "D_optimizer = Adam(D.parameters(), lr=0.0002, betas=(0.5, 0.999))  #  coefficients \n",
    "                                                                   # used for computing running averages of gradient and its square (default: (0.9, 0.999))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Epoch\n",
    "    * 모델 학습을 위해 전체 데이터셋을 여러 번 돌며 매개 변수를 조금씩 업데이트한다.\n",
    "    * 데이터셋을 한 번 도는 것을 1 Epoch이라고 한다.\n",
    "    * 여기서는 100 Epoch을 돌 것이다.\n",
    "    * 각 Epoch마다 Batch Size인 60만큼 데이터를 가져와 모델을 학습시킨다.\n",
    "    * MNIST 학습 데이터의 개수가 6만개이니 1에폭마다 1000번씩 학습이 이루어지는 셈이다?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <코드 6> 모델 학습을 위한 반복문\n",
    "\n",
    "# 데이터셋을 100번 돌며 학습한다\n",
    "for epoch in range(100):\n",
    "    \n",
    "    # 한 번에 batch_size만큼 데이터를 가져온다.\n",
    "    for real_data, _ in dataloader:\n",
    "        batch_size = real_data.size(0)\n",
    "        \n",
    "    # 데이터를 파이토치의 변수로 변환한다.\n",
    "        real_data = Variable(real_data)\n",
    "        \n",
    "        # ...  코드 7과 이어지는구나!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 먼저 Discriminator를 학습시킨다\n",
    "    * Discriminator는 진짜 이미지를 입력하면 1에 가까운 확률값을 출력한다\n",
    "    * 가짜 데이터를 입력하면 0에 가까운 확률값을 출력한다.\n",
    "    * 따라서 Discriminator의 손실 함수는 두 가지의 합으로 이루어진다.\n",
    "    * (진짜 이미지를 입력했을 떄의 출력값과 1의 차이) + (가짜 이미지를 입력했을 때 출력값과 0의 차이)\n",
    "    * 이 손실 함수의 값을 최소화 하는 방향으로 매개변수가 업데이트 된다.\n",
    "    \n",
    "* 파이토치에서는 간단한 방법으로 역전파를 통해 계산된 각 변수의 미분 값을 구할 수 있다.\n",
    "    * 그 상태에서 최적화 함수를 실행시키면 매개 변수가 한 번 업데이트된다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <코드7> Training Discriminator\n",
    "    ## 정답지에 해당하는 변수를 만든다\n",
    "    # Image가 진짜일 때 정답 값은 1이고 가짜일 때는 0이다\n",
    "    target_real = Variable(torch.ones(batch_size, 1))\n",
    "    target_fake = Variable(torch.zeros(batch_size_size, 1))\n",
    "    \n",
    "    ## Train real_data\n",
    "    # 진짜 이미지를 구분자에 넣는다\n",
    "    D_result_from_real = D(real_data)\n",
    "    # 구분자의 출력값이 정답지인 1에서 멀수록 loss가 높아진다\n",
    "    D_loss_real = criterion(D_result_from_real, target_real)\n",
    "   \n",
    "    ## Generating fake image \n",
    "    # 생성자에 입력으로 줄 랜덤 벡터 z를 만든다.\n",
    "    z = Variable(torch.randn((batch_size, 100)))\n",
    "    # 생성자로 가짜 이미지를 생성한다.\n",
    "    fake_data = G(z)\n",
    "    # 생성자가 만든 가짜 이미지를 구분자에 넣는다\n",
    "    D_result_from_fake = D(fake_data)\n",
    "    \n",
    "    # 구분자의 출력값이 정답인 0에서 멀수록 loss가 높아진다\n",
    "    D_loss_fake = criterion(D_result_from_fake, target_fake)\n",
    "    \n",
    "    ## Multi-Loss\n",
    "    # 구분자의 loss는 두 문제에서 계산된 loss의 합이다.\n",
    "    D_loss = D_loss_real + D_loss_fake\n",
    "    \n",
    "    # 구분자의 매개 변수의 미분값을 0으로 초기화한다.\n",
    "    D.zero_grad()\n",
    "    \n",
    "    # 역전파를 통해 매개변수의 loss에 대한 미분갑슬ㄹ 계산한다.\n",
    "    D_loss.backward()\n",
    "    \n",
    "    # 최적화 기법을 이용해 구분자의 매개 변수를 업데이트하낟.\n",
    "    D_optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
