{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 쉽게 풀어쓰는 GAN 2번 째 시간"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This Notebook referenced <code><a href='https://dreamgonfly.github.io/2018/03/17/gan-explained.html'>쉽게 씌여진 GAN</a></code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "* 쉽게 풀어쓰는 GAN 2번째 시간\n",
    "    * from DCGAN to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* GAN Model은 학습이 불안정한 특징이 있다\n",
    "    * GAN은 학습이 불안정하기로 악명이 높다. 이러한 점은 GAN 모델이 다양한 곳에서 응용되는 것을 가로막는 큰 장애물이 된다.\n",
    "    * 이러한 상황 속에서 안정적으로 학습이 가능한 GAN 모델 구조를 찾았는데 바로 DCGAN이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DCGAN의 특징\n",
    "    * 선형 레이어와 풀링 레이어를 최대한 배제하고 합성곱과 Transposed Convolution으로 네트워크 구조를 만들었다.\n",
    "    * Pooling Layer는 여러 딥러닝 모델에서 불필요한 매개변수의 수를 줄이고 중요한 특징만 골라내는 역할을 하는 레이어지만 이미지의 위치 정보를 잃어버린다는 단점이 있다.\n",
    "    * 이미지를 생성하기 위해서는 위치 정보가 중요하기 때문에 DCGAN은 pooling Layer를 배제했다.\n",
    "    * 선형 레이어 역시 마찬가지로 위치 정보를 잃어버리므로 모델의 깊은 레이어에서는 선형 레이어를 사용하지 않았다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./img/DCGAN.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* DCGAN과 Batch-Norm\n",
    "    * DCGAN의 또 다른 특징은 배치 정규화(Batch Normalization)을 사용했다는 점이다.\n",
    "    * Batch-Norm은 레이어의 입력 데이터 분포가 치우쳐져 있을 때 평균과 분산을 조정해주는 역할을 한다.\n",
    "    * 이는 역전파가 각 레이어에 쉽게 전달되도록 해 학습이 안정적으로 이뤄지도록 돕는데 중요한 역할을 한다.\n",
    "  \n",
    "* DCGAN 이외의 특징\n",
    "    * 마지막 레이어를 제외하고 Generator의 모든 레이어에 ReLU 사용\n",
    "    * Discriminator의 모든 레이어에 Leaky ReLU 사용\n",
    "    * 가장 좋은 최적화 기법과 적절한 학습속도를 실험을 통해 찾아내었다\n",
    "    \n",
    "* DCGAN 구조\n",
    "    * DCGAN 네트워크 구조는 기존 GAN에서 Generator와 Discriminator만 교체하는 것으로 간단히 구현할 수 있다.\n",
    "    * GAN과 마찬가지로 random vector z를 받고 가짜 이미지를 생성한다.\n",
    "    * 단지 Transposed Convolution과 배치 정규화를 사용한다는 점이 다르다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <코드 9> DCGAN의 생성자\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    \n",
    "    # 네트워크 구조\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "        nn.ConvTranspose2d(in_channels=100, out_channels=28*8, kernel_size=7, stride=1, padding=0, bias=False),\n",
    "        nn.BatchNorm2d(num_features=28*8),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.ConvTranspose2d(in_channels=28*8, out_channels=28*4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(num_features=28*4),\n",
    "        nn.ReLU(True),\n",
    "        nn.ConvTranspose2d(in_channels=28*4, out_channels=1, kerner_size=4, stride=2, padding=1, bias=False),\n",
    "        nn.Tanh())\n",
    "        \n",
    "        \n",
    "    # (batch_size x 100) 크기의 랜덤 벡터를 받아 \n",
    "    # 이미지를 (batch_size x 1 x 28 x 28)크기로 출력한다.\n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs.view(-1, 100, 1, 1)\n",
    "        return self.main(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <코드10> DCGAN의 구분자\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \n",
    "  # 네트워크 구조\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(nn.Conv2d(in_channels=1, out_channels=28*4, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(num_features=28*4),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Conv2d(in_channels=28*4, out_channels=28*8, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(num_features=28*8),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Conv2d(in_channels=28*8, out_channels=1, kernel_size=7, stride=1, padding=0, bias=False),\n",
    "        nn.Sigmoid())\n",
    "        \n",
    "  # (batch_size x 1 x 28 x 28) 크기의 이미지를 받아\n",
    "  # 이미지가 진짜일 확률을 0~1 사이로 출력한다.\n",
    "    def forward(self, inputs):\n",
    "        o = self.main(inputs)\n",
    "        return o.view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
