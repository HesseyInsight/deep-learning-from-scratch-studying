{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch란 무엇인가?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python 기반의 과학 연산 패키지로 다음과 같은 두 집단을 대상으로 한다.<br/>\n",
    "* NumPy를 대체하면서 GPU를 이용한 연산이 필요한 경우\n",
    "* 최대한의 유연성과 속도를 제공하는 딥러닝 연구 플랫폼이 필요한 경우"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "책을 통해 구현한 모델에서는...GPU를 안쓰고 CPU를 쓰더라...<br/>\n",
    "무엇보다도 이번에 연구에서 직접 사용을 해야 하기에...!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌다시 Remind하기 위해 내가 작성했던 코드로 되돌아왔다.  -20.03.31.Tue-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 Malimg 데이터를 Training하는 과정에서 GPU를 사용해 학습을 했다. 문제는... 연구 환경이 너무 열악...ㅠ<br>\n",
    "한편 PyTorch를 제대로 배워서 이후 연구에서 꾸준히 사용하기 위해 하나부터 열까지 제대로 짚고 넘어가려고 한다.<br>\n",
    "--20.04.18sat.pm3:2--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 시작하기\n",
    "### Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>Tensor</code>는 NumPy의 ndarray와 유사하며, 추가로 **GPU를 사용한 연산 가속**도 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "초기화되지 않은 5x3 행렬을 생성한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.0919e-39, 1.0102e-38, 8.9082e-39],\n",
      "        [8.4489e-39, 9.6429e-39, 8.4490e-39],\n",
      "        [9.6429e-39, 9.2755e-39, 1.0286e-38],\n",
      "        [9.0919e-39, 8.9082e-39, 9.2755e-39],\n",
      "        [8.4490e-39, 1.0378e-38, 1.0010e-38]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** <br/>\n",
    "초기화되지 않은 행렬이 선언되었지만, 사용하기 전에는 명확히 알려진 값을 포함하고 있지는 않는다.<br>\n",
    "초기화되지 않은 행렬이 생성되면 그 시점에 할당된 메모리에 존재하던 값들이 초기값으로 나타납니다.<br>\n",
    "<br>\n",
    "An uninitialized matrix is declared, but does not contain definite known values before it is used.<br>\n",
    "When an uninitialized matrix is created, whatever values were in the allocated memory at the time will appear as the initial values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "즉, 초기화 되지 않은 행렬을 생성하면 (행렬 생성시)할당된 메모리에 있던 값들이 초기값으로 나타나는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "무작위로 초기화된 행렬을 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1158, 0.0272, 0.2279],\n",
      "        [0.3041, 0.6386, 0.6715],\n",
      "        [0.4595, 0.2303, 0.9833],\n",
      "        [0.5917, 0.4397, 0.6358],\n",
      "        [0.2656, 0.9180, 0.5446]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**지금까지 수행한 코드**<br>\n",
    "초기화되지 않은 행렬에 무작위로 값을 생성해 초기화한다<br>\n",
    "empty(초기화 되지 않은 행렬)행렬을 선언한 뒤 무작위 값으로 행렬을 초기화 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dtype이 long이고 0으로 채워진 행렬을 생성한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터로부터 tensor를 직접 생성한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5.5000, 3.0000])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "또는 존재하는 tensor를 바탕으로 tensor를 만든다. 이 메소드(method)들은 사용자로부터 제공된 새로운 값이 없는 한, 입력 tensor의 속성들(예. dtype)을 재사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>new_*</code>메소드는 크기를 받는다.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n",
      "tensor([[ 0.2460, -0.1727,  0.1039],\n",
      "        [ 0.2247, -1.0739,  0.6645],\n",
      "        [-0.1406,  0.9457,  0.6406],\n",
      "        [ 0.2709,  0.1124,  0.2458],\n",
      "        [-1.1464,  0.4633,  1.1385]])\n"
     ]
    }
   ],
   "source": [
    "x = x.new_ones(5, 3, dtype=torch.double)  # new_*메소드는 크기를 받는다.\n",
    "print(x)\n",
    "\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>torch.randn_like</code><br>\n",
    "input과 동일한 크기의 텐서를 반환한다.<br>\n",
    "평균이 0, 분산이 1인 정규분포에서 난수 텐서 생성<br>\n",
    "dtype은 오버라이드(Override)하며 결과는 동일한 크기를 갖는다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "행렬의 크기를 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3])\n"
     ]
    }
   ],
   "source": [
    "print(x.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**<br>\n",
    "<code>torch.size</code>는 사실 튜플(tuple)과 같으며, 모든 튜플 연산을 지원한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Size'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x.size()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()[0] + x.size()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 연산(Operations)\n",
    "연산을 위한 여러가지 문법을 제공한다. 다음 예제들을 통해 덧셈 연산을 살펴보자"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**덧셈: 문법1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7322,  0.1403, -0.2827],\n",
      "        [ 1.4889,  0.4204, -0.0738],\n",
      "        [-0.8681,  0.0837, -0.2213],\n",
      "        [ 0.1833,  1.4449, -0.2183],\n",
      "        [ 2.3133,  0.9188,  0.7352]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(5, 3)\n",
    "# print(x)\n",
    "x = torch.randn_like(x, dtype=torch.float)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5641, 0.4617, 0.1161],\n",
      "        [0.2940, 0.2443, 0.2030],\n",
      "        [0.5232, 0.4948, 0.4879],\n",
      "        [0.1911, 0.6648, 0.3556],\n",
      "        [0.2657, 0.8633, 0.9464]])\n",
      "========================================\n",
      "x+y:  tensor([[ 2.2963,  0.6020, -0.1666],\n",
      "        [ 1.7830,  0.6646,  0.1292],\n",
      "        [-0.3449,  0.5785,  0.2666],\n",
      "        [ 0.3744,  2.1097,  0.1373],\n",
      "        [ 2.5791,  1.7821,  1.6816]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.rand(5, 3)\n",
    "print(y)\n",
    "print('='*40)\n",
    "print('x+y: ', x+y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**덧셈: 문법2**<br>\n",
    "<code>torch.add()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2963,  0.6020, -0.1666],\n",
      "        [ 1.7830,  0.6646,  0.1292],\n",
      "        [-0.3449,  0.5785,  0.2666],\n",
      "        [ 0.3744,  2.1097,  0.1373],\n",
      "        [ 2.5791,  1.7821,  1.6816]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.add(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2963,  0.6020, -0.1666],\n",
      "        [ 1.7830,  0.6646,  0.1292],\n",
      "        [-0.3449,  0.5785,  0.2666],\n",
      "        [ 0.3744,  2.1097,  0.1373],\n",
      "        [ 2.5791,  1.7821,  1.6816]])\n"
     ]
    }
   ],
   "source": [
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True],\n",
      "        [True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "print( (x+y) == torch.add(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**덧셈: 결과 tensor를 인자로 제공**<br>\n",
    "<code>torch.add(x, y, out = **)</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "result라는 빈 torch를 만들고, x와 y의 덧셈 결과를 tensor인자로 제공해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2963,  0.6020, -0.1666],\n",
      "        [ 1.7830,  0.6646,  0.1292],\n",
      "        [-0.3449,  0.5785,  0.2666],\n",
      "        [ 0.3744,  2.1097,  0.1373],\n",
      "        [ 2.5791,  1.7821,  1.6816]])\n"
     ]
    }
   ],
   "source": [
    "result = torch.empty(5, 3)\n",
    "torch.add(x, y, out = result)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**덧셈: 바꿔치기(In-place)방식**<br>\n",
    "<code>.add_()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.0285,  0.7422, -0.4493],\n",
      "        [ 3.2719,  1.0850,  0.0554],\n",
      "        [-1.2130,  0.6622,  0.0453],\n",
      "        [ 0.5577,  3.5547, -0.0810],\n",
      "        [ 4.8924,  2.7009,  2.4168]])\n"
     ]
    }
   ],
   "source": [
    "# y에 x 더하기\n",
    "y.add_(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x, y) == y.add_(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy스러운 인덱싱 표기 방법을 사용할 수도 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1403, 0.4204, 0.0837, 1.4449, 0.9188])\n"
     ]
    }
   ],
   "source": [
    "print(x[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**크기 변경**<br>\n",
    "tensor의 크기(size)나 모양(shape)을 변경하고 싶다면 <code>torch.view</code>를 사용한다<br>\n",
    "Q. reshape과는 다른건가..?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(-1)\n",
    "z = x.view(-1, 8)\n",
    "print(x.size(), y.size(), z.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 tensor에 하나의 값만 존재한다면, item()을 사용하면 숫자 값을 얻을 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.3133])\n",
      "-0.31325775384902954\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy변환(Bridge)\n",
    "Torch Tensor를 NumPy배열(array)로 변환하거나, 그 반대로 하는 것은 매우 쉽다<br/>\n",
    "(CPU 상의) Torch Tensor와 NumPy배열은 **저장 공간을 공유**하기 때문에, 하나를 변경하면 다른 하나도 변경된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📌 (CPU 상의) Torch Tensor와 NumPy배열은 같은 저장 공간을 공유한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torch Tensor를 NumPy배열로 변환하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "너무 심플하군!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy 배열의 값이 어떻게 변하는지 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "같은 저장공간을 공유하기 때문에 tensor에 1을 더해도 numpy값이 1씩 더해진다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy 배열을 Torch Tensor로 변환하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "자주쓰는 표현이니 잘 기억해두자<br>\n",
    "<code>torch.from_numpy()</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy(np)배열을 변경하면 Torch Tensor의 값도 자동 변경되는 것을 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "np.add(a, 1, out=a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CPU상에서는 같은 저장공간을 공유하기 떄문에 b의 값도 같지 않을까?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Char Tensor를 제외한 CPU상의 모든 Tensor는 NumPy로의 변환을 지원하며, (Numpy에서 Tensor로의) 반대 변환도 지원한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>.to</code> 메소드를 사용하여 Tensor를 어떠한 장치로도 옮길 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손글씨 데이터 CUDA로 학습시켜볼까?<br/>\n",
    "CPU로 2레이어 ConV돌리는데도 진짜 힘들어해서 안쓰러웠어..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3133])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이 코드는 CUDA가 사용 가능한 황경에서만 실행된다.\n",
    "# 'torch.device'를 사용하여 tensor를 GPU안팎으로 이동한다.\n",
    "\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'True'로 CUDA 사용이 가능하기에 CUDA로 Tensor를 학습시켜보자.<br>\n",
    "\n",
    "cuda device를 선언한다. => device = <code>torch.device(\"cuda\")</code>\n",
    "1. <code>to(device)</code>\n",
    "2. <code>torch.**(, device = device)</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6867], device='cuda:0')\n",
      "tensor([0.6867], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          \n",
    "    y = torch.ones_like(x, device=device)  # 1. CUDA 장치 객체(device object)로 GPU상에 직접적으로 tensor를 생성하는 방법\n",
    "    x = x.to(device)                       # 2. .to(\"cuda\")를 사용하면 된다.\n",
    "    z = x + y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\", torch.double))       # .to는 dtype도 함께 변경해준다.\n",
    "    \n",
    "else:\n",
    "    print(\"OOOOOOOOOOOOOOOOOps!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어제 사용한 또 다른 방법<br>\n",
    "<code>.cuda()</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6867], device='cuda:0')\n",
      "tensor([0.6867]) torch.float64\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    \n",
    "    y = torch.ones_like(x).cuda()\n",
    "    x = x.to(device)\n",
    "    z = y.add_(x)\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\"), torch.double)\n",
    "else:\n",
    "    print(\"OOOpps!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "https://tutorials.pytorch.kr/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
