{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep-Learning-from-Scratch\n",
    "## Chap07.CNN\n",
    "## 7.5 CNN구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "합성곱 계층과 풀링 계층을 구현했으니, 이제 이 계층들을 조합하여 손글씨 숫자를 인식하는 CNN을 조립해보도록 하자!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* SimpleConvNet\n",
    "    * Convolution-ReLU-Pooling-Affine-ReLU-Affine-Softmax "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SimpleConvNet 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 초기화 때 받는 인수\n",
    "    * input_dim - 입력 데이터(채널 수, 높이, 너비)의 차원\n",
    "    * conv_param - 합성곱 계층의 하이퍼파라미터(딕셔너리)\n",
    "        * filter_num\n",
    "        * filter_size\n",
    "        * stride\n",
    "        * pad\n",
    "    * hidden_size - 은닉층(완전연결)의 뉴런수\n",
    "    * output_size - 출력층(완전연결)의 뉴런수\n",
    "    * weight_init_std - 초기화때의 가중치 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import OrderedDict  # forward를 위해 순서가 있는 list로 저장\n",
    "from im2colLayer import *\n",
    "from im2colFunction import *\n",
    "\n",
    "class SimpleConvNet:\n",
    "    def __init__(self, input_dim=(1, 28, 28),\n",
    "                conv_params={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_params['filter_num']\n",
    "        filter_size = conv_params['filter_size']\n",
    "        filter_pad = conv_params['pad']\n",
    "        filter_stride = conv_params['stride']\n",
    "        input_size = input_dim[1]  # Mnist Data에서 input의 사이즈는 28  -> malimg에 적용할 경우 128 또는 지정해준 값이 되겠지!\n",
    "        conv_output_size = 1 + (input_size - filter_size + 2*filter_pad) / filter_stride\n",
    "        pool_out_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))  # ??\n",
    "        \n",
    "    # 가중치 매개변수 초기화 코드\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0],\n",
    "                                           filter_size, filter_size)  # 데이터의 개수, 채널 수, 필터 사이즈\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_out_size,\n",
    "                                           hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "        \n",
    "        # Deep-Learning-from-Scratch pp252\n",
    "        self.layers = OrderedDict()\n",
    "        \n",
    "        # ConV1-ReLU1-Pooling\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], \n",
    "                                           self.params['b1'],\n",
    "                                           conv_params['stride'],\n",
    "                                           conv_params['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        \n",
    "        # Affine1-ReLU2\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'],\n",
    "                                       self.params['b2'])\n",
    "        self.layers['Rele2'] = Relu()\n",
    "        \n",
    "        # Affine2-SoftmaxWithLoss()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'],\n",
    "                                       self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "        \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "    \n",
    "    # 오차역전파법으로 기울기 구하기\n",
    "    \n",
    "    def gradient(self, x, t):\n",
    "        # 순전파\n",
    "        self.loss(x, t)\n",
    "        \n",
    "        # 역전파\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "        \n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "            \n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'] = self.layers['Conv1'].dW\n",
    "        grads['b1'] = self.layers['Conv1'].db\n",
    "        grads['W2'] = self.layers['Affine1'].dW\n",
    "        grads['b2'] = self.layers['Affine1'].db\n",
    "        grads['W3'] = self.layers['Affine2'].dW\n",
    "        grads['b3'] = self.layers['Affine2'].db\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "앞장 7.4에서 pooling을 구현하고...|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss:2.2987433632681813\n",
      "=== epoch:1, train acc:0.162, test acc:0.161 ===\n",
      "train loss:2.2973542585536735\n",
      "train loss:2.292683566805368\n",
      "train loss:2.28247900051346\n",
      "train loss:2.2670780390931613\n",
      "train loss:2.2574569195111094\n",
      "train loss:2.252809952693756\n",
      "train loss:2.231010948793149\n",
      "train loss:2.2096660095890654\n",
      "train loss:2.175883706311892\n",
      "train loss:2.1359538694829725\n",
      "train loss:2.0966995284140633\n",
      "train loss:2.075175419445637\n",
      "train loss:2.001567355449671\n",
      "train loss:1.9742165455699812\n",
      "train loss:1.8435469355925258\n",
      "train loss:1.8512171824483103\n",
      "train loss:1.7672130171114082\n",
      "train loss:1.7477854079332018\n",
      "train loss:1.5330505274538846\n",
      "train loss:1.5103428053738635\n",
      "train loss:1.4140117019005265\n",
      "train loss:1.445024844898262\n",
      "train loss:1.3737650439629274\n",
      "train loss:1.203467525161972\n",
      "train loss:1.1721545085497578\n",
      "train loss:1.1169232780164209\n",
      "train loss:1.1809608745421025\n",
      "train loss:1.0483714815018634\n",
      "train loss:1.0504935644374394\n",
      "train loss:0.7950775319903152\n",
      "train loss:0.7852163365930797\n",
      "train loss:0.8189901808197392\n",
      "train loss:0.733299902524275\n",
      "train loss:0.7721011209372146\n",
      "train loss:0.6712232100069638\n",
      "train loss:0.6575573621671179\n",
      "train loss:0.9220391133689944\n",
      "train loss:0.8300012551115669\n",
      "train loss:0.6763667259258771\n",
      "train loss:0.8974820380336499\n",
      "train loss:0.6265245531805195\n",
      "train loss:0.5740252248944027\n",
      "train loss:0.5537246296537263\n",
      "train loss:0.5255861231141656\n",
      "train loss:0.6059556833047509\n",
      "train loss:0.6393032041847588\n",
      "train loss:0.732700783148664\n",
      "train loss:0.589267544049128\n",
      "train loss:0.5145721197805145\n",
      "train loss:0.4793258798660976\n",
      "train loss:0.47859931638040915\n",
      "train loss:0.4746348236245499\n",
      "train loss:0.5015092272935773\n",
      "train loss:0.45986512054839196\n",
      "train loss:0.48527834056984526\n",
      "train loss:0.5811946649048917\n",
      "train loss:0.43581239755691875\n",
      "train loss:0.41340099507951117\n",
      "train loss:0.6470085787399078\n",
      "train loss:0.3746951407328138\n",
      "train loss:0.4792427312040718\n",
      "train loss:0.531865540439128\n",
      "train loss:0.48418459868065755\n",
      "train loss:0.5819246186814229\n",
      "train loss:0.38323249815167854\n",
      "train loss:0.3309046297807673\n",
      "train loss:0.4393197977948887\n",
      "train loss:0.41362977573783766\n",
      "train loss:0.570378582684844\n",
      "train loss:0.33611169487587333\n",
      "train loss:0.3810433165027597\n",
      "train loss:0.5939520518850733\n",
      "train loss:0.46447492682512725\n",
      "train loss:0.2951957590064271\n",
      "train loss:0.528909697238878\n",
      "train loss:0.48792154275560934\n",
      "train loss:0.38824194578318005\n",
      "train loss:0.48371537495720934\n",
      "train loss:0.42506570898904433\n",
      "train loss:0.3746426764262971\n",
      "train loss:0.5416598631910174\n",
      "train loss:0.2993195269437391\n",
      "train loss:0.372598214981797\n",
      "train loss:0.4846207534485498\n",
      "train loss:0.3305672783160469\n",
      "train loss:0.5103624883638013\n",
      "train loss:0.35833433715215834\n",
      "train loss:0.45944724244370067\n",
      "train loss:0.43026635692515486\n",
      "train loss:0.3513332349782347\n",
      "train loss:0.43640813721434357\n",
      "train loss:0.28069564570793826\n",
      "train loss:0.3541021043466038\n",
      "train loss:0.3486338646322964\n",
      "train loss:0.3475798019940528\n",
      "train loss:0.3495704607869715\n",
      "train loss:0.4624224133242712\n",
      "train loss:0.326283467869247\n",
      "train loss:0.35266172901866194\n",
      "train loss:0.28777654887510495\n",
      "train loss:0.3228131607103801\n",
      "train loss:0.3235102637219336\n",
      "train loss:0.4362089752353866\n",
      "train loss:0.35401974632191463\n",
      "train loss:0.3734342902848607\n",
      "train loss:0.17610896692113387\n",
      "train loss:0.3077859061152663\n",
      "train loss:0.5003652012099254\n",
      "train loss:0.5032681152805548\n",
      "train loss:0.2983704501321513\n",
      "train loss:0.38140699543726414\n",
      "train loss:0.37396123049654356\n",
      "train loss:0.3995479328023271\n",
      "train loss:0.3614033519085343\n",
      "train loss:0.36298956903127516\n",
      "train loss:0.5306642321684819\n",
      "train loss:0.27139761776922977\n",
      "train loss:0.37695164532460745\n",
      "train loss:0.2808824384579527\n",
      "train loss:0.3613410260559254\n",
      "train loss:0.5360703616222332\n",
      "train loss:0.7492610882954377\n",
      "train loss:0.2671018594775562\n",
      "train loss:0.420787425948898\n",
      "train loss:0.42543457517607974\n",
      "train loss:0.5036215622265905\n",
      "train loss:0.23438062362672427\n",
      "train loss:0.2278166280183443\n",
      "train loss:0.22228493969330723\n",
      "train loss:0.355562781520544\n",
      "train loss:0.39088208497551497\n",
      "train loss:0.23093430990490418\n",
      "train loss:0.4230543928320543\n",
      "train loss:0.16914736161807475\n",
      "train loss:0.2966274555974784\n",
      "train loss:0.3255829388593873\n",
      "train loss:0.20153587230473174\n",
      "train loss:0.42718539937607297\n",
      "train loss:0.305374446253858\n",
      "train loss:0.42589586809860647\n",
      "train loss:0.2263392496389216\n",
      "train loss:0.42352581243144316\n",
      "train loss:0.3931698409308206\n",
      "train loss:0.3163161295439007\n",
      "train loss:0.45452266941826025\n",
      "train loss:0.2842708074233056\n",
      "train loss:0.34247628456133056\n",
      "train loss:0.23966554245999697\n",
      "train loss:0.305678558427518\n",
      "train loss:0.33922776442542035\n",
      "train loss:0.40120531746923077\n",
      "train loss:0.18643291499030437\n",
      "train loss:0.1765106291666128\n",
      "train loss:0.22151880804155075\n",
      "train loss:0.3354667906255051\n",
      "train loss:0.3793160084303817\n",
      "train loss:0.3439683437767142\n",
      "train loss:0.27244100448808894\n",
      "train loss:0.39792502719311423\n",
      "train loss:0.2642111240338375\n",
      "train loss:0.32966165030750844\n",
      "train loss:0.44258861530267896\n",
      "train loss:0.30358385129873666\n",
      "train loss:0.2917528791178125\n",
      "train loss:0.15139937967710262\n",
      "train loss:0.25244738261943916\n",
      "train loss:0.20852874133957616\n",
      "train loss:0.3355151713878164\n",
      "train loss:0.30603760024815996\n",
      "train loss:0.1692216607812569\n",
      "train loss:0.267330002761029\n",
      "train loss:0.3077675866446293\n",
      "train loss:0.2630511902061861\n",
      "train loss:0.1518962833879497\n",
      "train loss:0.4021764247349197\n",
      "train loss:0.2562004189096272\n",
      "train loss:0.1913373992998823\n",
      "train loss:0.3666259421884629\n",
      "train loss:0.3524703096020886\n",
      "train loss:0.2011380414191732\n",
      "train loss:0.48761070976320225\n",
      "train loss:0.29702816369500273\n",
      "train loss:0.3773464621344399\n",
      "train loss:0.200817549444512\n",
      "train loss:0.2360738035558378\n",
      "train loss:0.2810773975379354\n",
      "train loss:0.2379942929079407\n",
      "train loss:0.26981132141844505\n",
      "train loss:0.225529120363494\n",
      "train loss:0.3296311719885662\n",
      "train loss:0.2998380682213224\n",
      "train loss:0.12097473257046727\n",
      "train loss:0.21352482552893023\n",
      "train loss:0.22322387608556682\n",
      "train loss:0.21392931745258967\n",
      "train loss:0.31218147995874185\n",
      "train loss:0.2167168137036191\n",
      "train loss:0.2073004304305318\n",
      "train loss:0.21180958757061943\n",
      "train loss:0.3273629623772716\n",
      "train loss:0.40309624483599515\n",
      "train loss:0.24847133067533317\n",
      "train loss:0.19724263589068458\n",
      "train loss:0.4079172798172311\n",
      "train loss:0.22310171044562316\n",
      "train loss:0.3188982595632835\n",
      "train loss:0.36363477452283627\n",
      "train loss:0.33283191255778116\n",
      "train loss:0.20637691414334824\n",
      "train loss:0.30438876531542913\n",
      "train loss:0.14749437791139897\n",
      "train loss:0.2768101400924998\n",
      "train loss:0.23370559107924943\n",
      "train loss:0.221258606926929\n",
      "train loss:0.3234058596037104\n",
      "train loss:0.16164759320103225\n",
      "train loss:0.2919961161208357\n",
      "train loss:0.21740106708312035\n",
      "train loss:0.3040209434569501\n",
      "train loss:0.2785146726918535\n",
      "train loss:0.3235522748433061\n",
      "train loss:0.34327831428220656\n",
      "train loss:0.2585375013364147\n",
      "train loss:0.1814950017208731\n",
      "train loss:0.21265394719994332\n",
      "train loss:0.1644870213823551\n",
      "train loss:0.1792740966341736\n",
      "train loss:0.18037782510938552\n",
      "train loss:0.2588552470479838\n",
      "train loss:0.18409762118669\n",
      "train loss:0.2610030100297275\n",
      "train loss:0.2285103965442056\n",
      "train loss:0.23697332129695117\n",
      "train loss:0.3772174582344235\n",
      "train loss:0.3138541849858514\n",
      "train loss:0.26143498262513387\n",
      "train loss:0.15628326982578877\n",
      "train loss:0.22493646441740484\n",
      "train loss:0.20930376893330369\n",
      "train loss:0.5419371638450659\n",
      "train loss:0.29133253310719875\n",
      "train loss:0.27965852076281217\n",
      "train loss:0.17317889916084594\n",
      "train loss:0.23244479999281695\n",
      "train loss:0.2742131101626381\n",
      "train loss:0.2467890973398801\n",
      "train loss:0.18700210477792115\n",
      "train loss:0.40207374209719454\n",
      "train loss:0.20341105093118345\n",
      "train loss:0.27499853714902045\n",
      "train loss:0.16211521466628784\n",
      "train loss:0.28188449237760077\n",
      "train loss:0.11837541955165445\n",
      "train loss:0.2607829784302917\n",
      "train loss:0.2366261485459848\n",
      "train loss:0.20465579418463245\n",
      "train loss:0.21966154399262755\n",
      "train loss:0.2674992096254874\n",
      "train loss:0.26518914060893295\n",
      "train loss:0.3673417341513568\n",
      "train loss:0.19772399301629495\n",
      "train loss:0.29149134782866576\n",
      "train loss:0.2105110804008208\n",
      "train loss:0.230272737947663\n",
      "train loss:0.19689360238941528\n",
      "train loss:0.22426043452266206\n",
      "train loss:0.10237335386215256\n",
      "train loss:0.21177171482942592\n",
      "train loss:0.1859673628632417\n",
      "train loss:0.14459875071035244\n",
      "train loss:0.15001281683221668\n",
      "train loss:0.2382191497367615\n",
      "train loss:0.351853427184385\n",
      "train loss:0.15152489738183225\n",
      "train loss:0.4226789095786455\n",
      "train loss:0.2283481717925098\n",
      "train loss:0.23947766677921148\n",
      "train loss:0.1891188505493627\n",
      "train loss:0.28299408988914515\n",
      "train loss:0.19416316214270204\n",
      "train loss:0.27303271476684204\n",
      "train loss:0.22494615754062866\n",
      "train loss:0.30995666154371665\n",
      "train loss:0.24606015621606453\n",
      "train loss:0.15457260319243515\n",
      "train loss:0.3941309832667833\n",
      "train loss:0.27969494905313763\n",
      "train loss:0.15274901261115362\n",
      "train loss:0.266107754889035\n",
      "train loss:0.19689802622357966\n",
      "train loss:0.15680001371222937\n",
      "train loss:0.3304274069507018\n",
      "train loss:0.1446558838948354\n",
      "train loss:0.13793186615073622\n",
      "train loss:0.19020902532515882\n",
      "train loss:0.28381453623950653\n",
      "train loss:0.23252501333603218\n",
      "train loss:0.32701679065385797\n",
      "train loss:0.17113018167167773\n",
      "train loss:0.1454922765733955\n",
      "train loss:0.28899681771004515\n",
      "train loss:0.30904855150414684\n",
      "train loss:0.20630918556829833\n",
      "train loss:0.1457878563841529\n",
      "train loss:0.16792468012852982\n",
      "train loss:0.2613265628499895\n",
      "train loss:0.1793068143234748\n",
      "train loss:0.21228487398747903\n",
      "train loss:0.18570532348191024\n",
      "train loss:0.1992842550683182\n",
      "train loss:0.16653482749181794\n",
      "train loss:0.1719745787960201\n",
      "train loss:0.18342065947921962\n",
      "train loss:0.21565803055703273\n",
      "train loss:0.2529817251233528\n",
      "train loss:0.1479351332183841\n",
      "train loss:0.057892713178139245\n",
      "train loss:0.20787081708089994\n",
      "train loss:0.18201166884996844\n",
      "train loss:0.09140681013699624\n",
      "train loss:0.28840165669740114\n",
      "train loss:0.13278146274435423\n",
      "train loss:0.24216025596804555\n",
      "train loss:0.24424660085182212\n",
      "train loss:0.28859166311605866\n",
      "train loss:0.11469103342610615\n",
      "train loss:0.2647678851428297\n",
      "train loss:0.1332718244388051\n",
      "train loss:0.3187858870573862\n",
      "train loss:0.19917262650742068\n",
      "train loss:0.20280615941931554\n",
      "train loss:0.22059986518329022\n",
      "train loss:0.10468929233120226\n",
      "train loss:0.4212258938017275\n",
      "train loss:0.32182818513530437\n",
      "train loss:0.13293069253956938\n",
      "train loss:0.1503577648947744\n",
      "train loss:0.2597449954841681\n",
      "train loss:0.1878077203763\n",
      "train loss:0.09062875154674194\n",
      "train loss:0.26226666447264657\n",
      "train loss:0.17383034044826207\n",
      "train loss:0.25852891001311645\n",
      "train loss:0.12936073188147565\n",
      "train loss:0.20852203802297326\n",
      "train loss:0.1402633320936761\n",
      "train loss:0.18741820620425537\n",
      "train loss:0.1834927569552676\n",
      "train loss:0.12400296992540172\n",
      "train loss:0.1437951597306468\n",
      "train loss:0.21795960842431572\n",
      "train loss:0.13579816602719919\n",
      "train loss:0.12617322898354558\n",
      "train loss:0.16243365058763662\n",
      "train loss:0.1830356446865301\n",
      "train loss:0.13502777332139082\n",
      "train loss:0.3618451061532171\n",
      "train loss:0.12915277521928195\n",
      "train loss:0.16020334459095115\n",
      "train loss:0.28603075569187464\n",
      "train loss:0.16071035096130168\n",
      "train loss:0.21166577950503584\n",
      "train loss:0.09254238768186442\n",
      "train loss:0.13456750033938011\n",
      "train loss:0.16394699101486127\n",
      "train loss:0.14367696690160253\n",
      "train loss:0.17835217135192746\n",
      "train loss:0.19047245732537538\n",
      "train loss:0.13025626634392695\n",
      "train loss:0.12707953111374282\n",
      "train loss:0.18023938217867466\n",
      "train loss:0.09502147068228776\n",
      "train loss:0.27709520094701984\n",
      "train loss:0.1749989553740049\n",
      "train loss:0.2329820836608714\n",
      "train loss:0.2407361081869358\n",
      "train loss:0.08394399439737747\n",
      "train loss:0.08530346363488096\n",
      "train loss:0.2822870768403623\n",
      "train loss:0.23095045632247102\n",
      "train loss:0.17424010886081653\n",
      "train loss:0.1474224722331965\n",
      "train loss:0.11575554622997533\n",
      "train loss:0.1501661492662106\n",
      "train loss:0.18358303226042444\n",
      "train loss:0.10194019741846701\n",
      "train loss:0.11808628012111955\n",
      "train loss:0.196599468356267\n",
      "train loss:0.15194624109838734\n",
      "train loss:0.22845669527502596\n",
      "train loss:0.11112031216647003\n",
      "train loss:0.18197246543339507\n",
      "train loss:0.1271773483890143\n",
      "train loss:0.15291717591295043\n",
      "train loss:0.24354228547853118\n",
      "train loss:0.15058994433003406\n",
      "train loss:0.1626447450827201\n",
      "train loss:0.18347029969560935\n",
      "train loss:0.12115882975032327\n",
      "train loss:0.11271732568222836\n",
      "train loss:0.20180394448026173\n",
      "train loss:0.13410439200442442\n",
      "train loss:0.13197190818166174\n",
      "train loss:0.11500124945691395\n",
      "train loss:0.1419409161861144\n",
      "train loss:0.17904273187227457\n",
      "train loss:0.06446140453856952\n",
      "train loss:0.25342913779722226\n",
      "train loss:0.1468600171364999\n",
      "train loss:0.1840061289104616\n",
      "train loss:0.18264998468287139\n",
      "train loss:0.09900341989174109\n",
      "train loss:0.08297498855583604\n",
      "train loss:0.13620269909512125\n",
      "train loss:0.14030559988427263\n",
      "train loss:0.10155589061452287\n",
      "train loss:0.20860216200481382\n",
      "train loss:0.10020750038797946\n",
      "train loss:0.22024031707181335\n",
      "train loss:0.1537961481395467\n",
      "train loss:0.19496494427145827\n",
      "train loss:0.2247572107790196\n",
      "train loss:0.12315569575686394\n",
      "train loss:0.14130871147630755\n",
      "train loss:0.0791562888782151\n",
      "train loss:0.13726327800708205\n",
      "train loss:0.16905001364388564\n",
      "train loss:0.08001983022388551\n",
      "train loss:0.2134608540118297\n",
      "train loss:0.15291624223227301\n",
      "train loss:0.20123273475029055\n",
      "train loss:0.1234633599772231\n",
      "train loss:0.22990581919286765\n",
      "train loss:0.14394825205254563\n",
      "train loss:0.16718894384632882\n",
      "train loss:0.10862547970672937\n",
      "train loss:0.13639860013173877\n",
      "train loss:0.11920547190679068\n",
      "train loss:0.06178163189053824\n",
      "train loss:0.11114854848772024\n",
      "train loss:0.19314447475717475\n",
      "train loss:0.11082658618461705\n",
      "train loss:0.09926758612692123\n",
      "train loss:0.11335984482450623\n",
      "train loss:0.10040161420359574\n",
      "train loss:0.1729403544625457\n",
      "train loss:0.21923864795804932\n",
      "train loss:0.15189659773363864\n",
      "train loss:0.15336082173625368\n",
      "train loss:0.11583860608428101\n",
      "train loss:0.10882722937735967\n",
      "train loss:0.1861365860617637\n",
      "train loss:0.19087970750272384\n",
      "train loss:0.1686138841438579\n",
      "train loss:0.1881596262951163\n",
      "train loss:0.19062949864032347\n",
      "train loss:0.13405847793569262\n",
      "train loss:0.19060573243099074\n",
      "train loss:0.21036976702832008\n",
      "train loss:0.11130081700077608\n",
      "train loss:0.18053785597901928\n",
      "train loss:0.11044998378442741\n",
      "train loss:0.22933509380463282\n",
      "train loss:0.07427069540250991\n",
      "train loss:0.09910494620239292\n",
      "train loss:0.1044920762040776\n",
      "train loss:0.08555424271153393\n",
      "train loss:0.09037129547186092\n",
      "train loss:0.11895136324505344\n",
      "train loss:0.16415643758645054\n",
      "train loss:0.064293797873213\n",
      "train loss:0.08343439137761594\n",
      "train loss:0.14194069842560914\n",
      "train loss:0.16232590857577833\n",
      "train loss:0.09355336490340438\n",
      "train loss:0.3814957070286936\n",
      "train loss:0.10672147887362932\n",
      "train loss:0.07241615276532266\n",
      "train loss:0.12034518194402924\n",
      "train loss:0.26523646790850597\n",
      "train loss:0.24648345640199484\n",
      "train loss:0.11578118482084557\n",
      "train loss:0.31180188789575947\n",
      "train loss:0.1105751655150124\n",
      "train loss:0.2353893322044296\n",
      "train loss:0.15367031660024089\n",
      "train loss:0.11664401512123418\n",
      "train loss:0.050487947161563955\n",
      "train loss:0.10547405938987117\n",
      "train loss:0.2819659247201237\n",
      "train loss:0.13240190313949202\n",
      "train loss:0.16616154138122838\n",
      "train loss:0.1777913078356337\n",
      "train loss:0.17804192781811515\n",
      "train loss:0.19772461252557977\n",
      "train loss:0.14414604369620918\n",
      "train loss:0.15269256158679334\n",
      "train loss:0.20929595132818413\n",
      "train loss:0.22446737418896284\n",
      "train loss:0.09309367618762993\n",
      "train loss:0.26449695883603824\n",
      "train loss:0.14074586801769468\n",
      "train loss:0.16569861104401934\n",
      "train loss:0.11094275053907135\n",
      "train loss:0.07995555610396812\n",
      "train loss:0.14206239695846717\n",
      "train loss:0.08503219066110691\n",
      "train loss:0.32018344700713847\n",
      "train loss:0.09609210326860948\n",
      "train loss:0.16483000581009846\n",
      "train loss:0.10433920885409112\n",
      "train loss:0.14893571793294322\n",
      "train loss:0.04552788661108344\n",
      "train loss:0.14304431142916585\n",
      "train loss:0.14261782880767335\n",
      "train loss:0.14304993836116375\n",
      "train loss:0.1949201044900528\n",
      "train loss:0.08511142224460758\n",
      "train loss:0.09686042355932795\n",
      "train loss:0.07963675152322941\n",
      "train loss:0.12448972427772306\n",
      "train loss:0.16899370527650134\n",
      "train loss:0.12976848786550302\n",
      "train loss:0.1945362990601308\n",
      "train loss:0.14862172296339904\n",
      "train loss:0.07302680895950167\n",
      "train loss:0.25235761398130147\n",
      "train loss:0.0359652111326842\n",
      "train loss:0.0806245615175496\n",
      "train loss:0.09513508995419323\n",
      "train loss:0.1299958652182871\n",
      "train loss:0.20450300224667728\n",
      "train loss:0.1474534837018799\n",
      "train loss:0.16462856118025637\n",
      "train loss:0.09486014262756416\n",
      "train loss:0.12736722185296948\n",
      "train loss:0.14281181279251026\n",
      "train loss:0.23185708671763527\n",
      "train loss:0.18220905091414277\n",
      "train loss:0.12851258792283965\n",
      "train loss:0.10242165617874777\n",
      "train loss:0.060195853839489534\n",
      "train loss:0.17106708030112214\n",
      "train loss:0.14125431061039076\n",
      "train loss:0.1386654249437992\n",
      "train loss:0.07977329278209931\n",
      "train loss:0.20755259042839838\n",
      "train loss:0.13416556575383504\n",
      "train loss:0.08935264283148245\n",
      "train loss:0.16107494048506252\n",
      "train loss:0.1655089062847557\n",
      "train loss:0.07905631935196224\n",
      "train loss:0.11986862854386643\n",
      "train loss:0.07831300702914905\n",
      "train loss:0.15438618103975743\n",
      "train loss:0.09694780687924337\n",
      "train loss:0.11718740279454913\n",
      "train loss:0.09383979297301057\n",
      "train loss:0.07022646647034728\n",
      "train loss:0.07257713256064974\n",
      "train loss:0.0943225787381621\n",
      "train loss:0.075395877251522\n",
      "train loss:0.23933260133198897\n",
      "train loss:0.0861691382009987\n",
      "train loss:0.20603420353209387\n",
      "train loss:0.06639322192035711\n",
      "train loss:0.19206921346474484\n",
      "train loss:0.08660534889894488\n",
      "train loss:0.08489597503165269\n",
      "train loss:0.17042260979289445\n",
      "train loss:0.10735483146052857\n",
      "train loss:0.08163776342044697\n",
      "train loss:0.2229249006622077\n",
      "train loss:0.06520233793052471\n",
      "train loss:0.04017745204669335\n",
      "train loss:0.04009429899766054\n",
      "train loss:0.12926442779935648\n",
      "train loss:0.09378320853125391\n",
      "train loss:0.08300574010045661\n",
      "train loss:0.051435239325100544\n",
      "train loss:0.06056295305039996\n",
      "train loss:0.052610984535577734\n",
      "train loss:0.11368768043235765\n",
      "train loss:0.0734230572524007\n",
      "train loss:0.05304440939718144\n",
      "train loss:0.10223776442321529\n",
      "train loss:0.06730877835726305\n",
      "train loss:0.1313188695189896\n",
      "train loss:0.05813260699357456\n",
      "train loss:0.12840537800095364\n",
      "train loss:0.09459363112762627\n",
      "train loss:0.08240226528172294\n",
      "train loss:0.10833948543989147\n",
      "train loss:0.1020530713544571\n",
      "train loss:0.11966699971787705\n",
      "train loss:0.06828788779382938\n",
      "train loss:0.08054545185340706\n",
      "train loss:0.11885068832288644\n",
      "train loss:0.0644703779437729\n",
      "train loss:0.10464328728558028\n",
      "=== epoch:2, train acc:0.962, test acc:0.961 ===\n",
      "train loss:0.08099267095138654\n",
      "train loss:0.08535907426618125\n",
      "train loss:0.09433796709576651\n",
      "train loss:0.06983428916718457\n",
      "train loss:0.0696377256398619\n",
      "train loss:0.1891537948200684\n",
      "train loss:0.06409920265807764\n",
      "train loss:0.10958536779267866\n",
      "train loss:0.07862004886909894\n",
      "train loss:0.1169416515769883\n",
      "train loss:0.11042022994268262\n",
      "train loss:0.12098699037224693\n",
      "train loss:0.08294152230747728\n",
      "train loss:0.16388198047299882\n",
      "train loss:0.05879655021452598\n",
      "train loss:0.05247300277147828\n",
      "train loss:0.25910852803768236\n",
      "train loss:0.1048224354387824\n",
      "train loss:0.07317918463333528\n",
      "train loss:0.08144366362595104\n",
      "train loss:0.09451266771761295\n",
      "train loss:0.12738674026918592\n",
      "train loss:0.09519625507583201\n",
      "train loss:0.041449817991232735\n",
      "train loss:0.11064434604819846\n",
      "train loss:0.07787493976196372\n",
      "train loss:0.09904895362281757\n",
      "train loss:0.1898872808450847\n",
      "train loss:0.07913962488831772\n",
      "train loss:0.12542819012975162\n",
      "train loss:0.06630560563129528\n",
      "train loss:0.056147160344746865\n",
      "train loss:0.2554353939209844\n",
      "train loss:0.0882545003418688\n",
      "train loss:0.09270586720852204\n",
      "train loss:0.05999064714522644\n",
      "train loss:0.08429001952177967\n",
      "train loss:0.07040295557728164\n",
      "train loss:0.13754232037205413\n",
      "train loss:0.08892728546082884\n",
      "train loss:0.07718724320914677\n",
      "train loss:0.09682181810380422\n",
      "train loss:0.12959717596887502\n",
      "train loss:0.15412684751825986\n",
      "train loss:0.18794153722052453\n",
      "train loss:0.09549348528534919\n",
      "train loss:0.10496202879032554\n",
      "train loss:0.11740425179786984\n",
      "train loss:0.03679787285504827\n",
      "train loss:0.057609015850683655\n",
      "train loss:0.1404313292206019\n",
      "train loss:0.09433141933217305\n",
      "train loss:0.09612414060762521\n",
      "train loss:0.084870664337615\n",
      "train loss:0.0747464129302536\n",
      "train loss:0.06224030854121801\n",
      "train loss:0.07727788478617797\n",
      "train loss:0.1088298634568477\n",
      "train loss:0.07158802228241236\n",
      "train loss:0.07432572159052554\n",
      "train loss:0.2553235217242159\n",
      "train loss:0.042058640978470986\n",
      "train loss:0.17678768679084786\n",
      "train loss:0.12414871883657033\n",
      "train loss:0.13707682879388072\n",
      "train loss:0.17200191787930902\n",
      "train loss:0.14551133454748655\n",
      "train loss:0.149162986585759\n",
      "train loss:0.08711495448925048\n",
      "train loss:0.11612066808367802\n",
      "train loss:0.0846491806975177\n",
      "train loss:0.08455569805750411\n",
      "train loss:0.07750617355002182\n",
      "train loss:0.05688678326947953\n",
      "train loss:0.10518055450026775\n",
      "train loss:0.21399683463796618\n",
      "train loss:0.06601240725178908\n",
      "train loss:0.025201029261637295\n",
      "train loss:0.12448983214619835\n",
      "train loss:0.10519684746101442\n",
      "train loss:0.07810850612894832\n",
      "train loss:0.11673209640261113\n",
      "train loss:0.1358937019306855\n",
      "train loss:0.04980798546725376\n",
      "train loss:0.17266975254761885\n",
      "train loss:0.06141356835077308\n",
      "train loss:0.12319153955022762\n",
      "train loss:0.05117866961588168\n",
      "train loss:0.14527305882314243\n",
      "train loss:0.07336454833497165\n",
      "train loss:0.07844257034339656\n",
      "train loss:0.07374045508215403\n",
      "train loss:0.06717539831601972\n",
      "train loss:0.1180805649977148\n",
      "train loss:0.06276032154591822\n",
      "train loss:0.08779626907114664\n",
      "train loss:0.11049549828435547\n",
      "train loss:0.075983535695787\n",
      "train loss:0.09054112950705315\n",
      "train loss:0.13283921496020537\n",
      "train loss:0.03064086485161044\n",
      "train loss:0.04799837475282978\n",
      "train loss:0.0303713121906687\n",
      "train loss:0.09318675558706596\n",
      "train loss:0.05012092166008629\n",
      "train loss:0.1268385184810354\n",
      "train loss:0.06481734918941401\n",
      "train loss:0.12580388963164357\n",
      "train loss:0.11173155536550691\n",
      "train loss:0.16524886606132316\n",
      "train loss:0.07724295461568308\n",
      "train loss:0.045170130187610506\n",
      "train loss:0.07305907293119222\n",
      "train loss:0.15498525875814792\n",
      "train loss:0.11674281826998674\n",
      "train loss:0.12451557097178113\n",
      "train loss:0.036284464657932426\n",
      "train loss:0.135745394669536\n",
      "train loss:0.0757998363180943\n",
      "train loss:0.053162350825237514\n",
      "train loss:0.14906412879056183\n",
      "train loss:0.06530136087182288\n",
      "train loss:0.12409643023364217\n",
      "train loss:0.1000183497583383\n",
      "train loss:0.2002835982440591\n",
      "train loss:0.12639819101119193\n",
      "train loss:0.039372532119119154\n",
      "train loss:0.13306949133338772\n",
      "train loss:0.0912468882199714\n",
      "train loss:0.09771933708566563\n",
      "train loss:0.028133638533304382\n",
      "train loss:0.10245587907167002\n",
      "train loss:0.11155357841264264\n",
      "train loss:0.09255739391800889\n",
      "train loss:0.12753205793202688\n",
      "train loss:0.07506262023812886\n",
      "train loss:0.16398100513601072\n",
      "train loss:0.21122846780471088\n",
      "train loss:0.07505137644868627\n",
      "train loss:0.06647675894044607\n",
      "train loss:0.04750425221548895\n",
      "train loss:0.0799868668421376\n",
      "train loss:0.03822862781161446\n",
      "train loss:0.11327950968395477\n",
      "train loss:0.13703536391266813\n",
      "train loss:0.15412501754536675\n",
      "train loss:0.15160297888594362\n",
      "train loss:0.02889892141311184\n",
      "train loss:0.18649017657069117\n",
      "train loss:0.04557925890536077\n",
      "train loss:0.0556649811710328\n",
      "train loss:0.11741613708391492\n",
      "train loss:0.08703190685985024\n",
      "train loss:0.11541895124618876\n",
      "train loss:0.14000212129905626\n",
      "train loss:0.03016164938327758\n",
      "train loss:0.11458751911989408\n",
      "train loss:0.13258473778924948\n",
      "train loss:0.10072566634551754\n",
      "train loss:0.0833983953416899\n",
      "train loss:0.1154386044498448\n",
      "train loss:0.07355701234673813\n",
      "train loss:0.16200151124107862\n",
      "train loss:0.07135828797780736\n",
      "train loss:0.0544570351728009\n",
      "train loss:0.06727988369320066\n",
      "train loss:0.11705297508078943\n",
      "train loss:0.07693266558654509\n",
      "train loss:0.04877361167398447\n",
      "train loss:0.07134769425857349\n",
      "train loss:0.04497057904941197\n",
      "train loss:0.05925994850048289\n",
      "train loss:0.15948595968896936\n",
      "train loss:0.09218083534193408\n",
      "train loss:0.09653002684160959\n",
      "train loss:0.03381555504124329\n",
      "train loss:0.150504307949962\n",
      "train loss:0.10418790354113401\n",
      "train loss:0.032144779424868625\n",
      "train loss:0.10542015562037442\n",
      "train loss:0.07295348778025637\n",
      "train loss:0.050271011944862665\n",
      "train loss:0.09749888000518289\n",
      "train loss:0.06040248971776142\n",
      "train loss:0.1478358881311294\n",
      "train loss:0.048017377969144744\n",
      "train loss:0.10197783788782636\n",
      "train loss:0.06467182389422257\n",
      "train loss:0.2342567656728808\n",
      "train loss:0.07660474233275358\n",
      "train loss:0.1270809167221246\n",
      "train loss:0.05834275144849872\n",
      "train loss:0.09748573324865589\n",
      "train loss:0.06541603959252758\n",
      "train loss:0.04462222015523074\n",
      "train loss:0.05675974734232717\n",
      "train loss:0.19679089916916356\n",
      "train loss:0.14914770243050418\n",
      "train loss:0.05507709501060332\n",
      "train loss:0.07878345756672514\n",
      "train loss:0.10906995514305955\n",
      "train loss:0.02946249110312684\n",
      "train loss:0.06528552264019379\n",
      "train loss:0.1041772456734376\n",
      "train loss:0.06769340027607298\n",
      "train loss:0.10569067606161521\n",
      "train loss:0.050256242017924106\n",
      "train loss:0.13910999456460268\n",
      "train loss:0.05407287036794472\n",
      "train loss:0.08364004955013284\n",
      "train loss:0.07093191576897775\n",
      "train loss:0.03200094184005069\n",
      "train loss:0.11703913537666841\n",
      "train loss:0.02748822367543743\n",
      "train loss:0.11297832322924718\n",
      "train loss:0.08008794447511373\n",
      "train loss:0.06565725414508396\n",
      "train loss:0.0855649339763589\n",
      "train loss:0.11135663461061972\n",
      "train loss:0.08030677950870681\n",
      "train loss:0.028494453023924428\n",
      "train loss:0.06545049639986013\n",
      "train loss:0.18002939886458258\n",
      "train loss:0.04957364023330992\n",
      "train loss:0.08028446407121574\n",
      "train loss:0.08387584826546299\n",
      "train loss:0.017760866523163377\n",
      "train loss:0.2978754207773661\n",
      "train loss:0.19069048159593371\n",
      "train loss:0.08329731788849747\n",
      "train loss:0.10601185723833112\n",
      "train loss:0.09096877831093923\n",
      "train loss:0.03095447872811581\n",
      "train loss:0.08076318171851739\n",
      "train loss:0.053437350511860736\n",
      "train loss:0.0451490264856607\n",
      "train loss:0.07398099646897788\n",
      "train loss:0.10683040992685724\n",
      "train loss:0.11204913040490633\n",
      "train loss:0.04858502508779642\n",
      "train loss:0.16034768783590664\n",
      "train loss:0.04598444069645081\n",
      "train loss:0.03923303033712007\n",
      "train loss:0.03370879216294391\n",
      "train loss:0.05781263882888598\n",
      "train loss:0.08800260686789901\n",
      "train loss:0.07078082538923289\n",
      "train loss:0.06126655869726868\n",
      "train loss:0.05055525080892216\n",
      "train loss:0.08270935433212219\n",
      "train loss:0.05829755321554639\n",
      "train loss:0.07629363018872516\n",
      "train loss:0.024239353086812084\n",
      "train loss:0.18444667717923044\n",
      "train loss:0.0601410134819724\n",
      "train loss:0.05277689150094532\n",
      "train loss:0.03806132614277128\n",
      "train loss:0.0790439753704543\n",
      "train loss:0.03783838040898691\n",
      "train loss:0.11311580807888369\n",
      "train loss:0.03522594699551673\n",
      "train loss:0.03625920577776756\n",
      "train loss:0.07312009628636704\n",
      "train loss:0.11451664280098357\n",
      "train loss:0.04670466191382972\n",
      "train loss:0.03929359632096291\n",
      "train loss:0.0993579453875509\n",
      "train loss:0.13058302454139367\n",
      "train loss:0.06197987289003127\n",
      "train loss:0.04055405651610557\n",
      "train loss:0.05982647588383649\n",
      "train loss:0.12026566839495588\n",
      "train loss:0.03222051276645941\n",
      "train loss:0.12745338888340232\n",
      "train loss:0.05394897523100815\n",
      "train loss:0.07085357255822798\n",
      "train loss:0.046218789497976046\n",
      "train loss:0.10804269508112835\n",
      "train loss:0.042302314516532206\n",
      "train loss:0.047453306522679525\n",
      "train loss:0.06468867338424743\n",
      "train loss:0.0453877283340075\n",
      "train loss:0.09563322016962784\n",
      "train loss:0.15520172718405476\n",
      "train loss:0.12610858131261884\n",
      "train loss:0.13469064889283638\n",
      "train loss:0.08434612774167041\n",
      "train loss:0.047061002483422154\n",
      "train loss:0.045222330891286126\n",
      "train loss:0.09198722209884327\n",
      "train loss:0.09375327248208633\n",
      "train loss:0.060602971280565285\n",
      "train loss:0.052759185257915925\n",
      "train loss:0.13891485586487531\n",
      "train loss:0.08219444147073694\n",
      "train loss:0.08260611119475957\n",
      "train loss:0.09371467103649048\n",
      "train loss:0.03708852265945341\n",
      "train loss:0.0595752924599219\n",
      "train loss:0.04919141684592786\n",
      "train loss:0.18306813853982093\n",
      "train loss:0.05818698740683751\n",
      "train loss:0.056566397353638706\n",
      "train loss:0.06795987579977668\n",
      "train loss:0.040021494514306574\n",
      "train loss:0.045870942196923045\n",
      "train loss:0.06328683604453908\n",
      "train loss:0.033829787326578355\n",
      "train loss:0.07753806454242827\n",
      "train loss:0.07211589513887215\n",
      "train loss:0.029841832879067942\n",
      "train loss:0.08515672129286464\n",
      "train loss:0.16833577985377257\n",
      "train loss:0.19531405121919868\n",
      "train loss:0.151369245661236\n",
      "train loss:0.02342300032700671\n",
      "train loss:0.0964005622957246\n",
      "train loss:0.11830985562625973\n",
      "train loss:0.12197842892685917\n",
      "train loss:0.0979140893514245\n",
      "train loss:0.06559793692264584\n",
      "train loss:0.12358702192098113\n",
      "train loss:0.117881247616651\n",
      "train loss:0.11863315883774528\n",
      "train loss:0.13441927458423256\n",
      "train loss:0.14531019097834305\n",
      "train loss:0.04669115980954123\n",
      "train loss:0.09414952341463896\n",
      "train loss:0.1324631019033167\n",
      "train loss:0.082538969123442\n",
      "train loss:0.051645070687951856\n",
      "train loss:0.08356375375903127\n",
      "train loss:0.2306787348683781\n",
      "train loss:0.014690368050107698\n",
      "train loss:0.09220426819187627\n",
      "train loss:0.06996039056059139\n",
      "train loss:0.10126392874261599\n",
      "train loss:0.08877778576552343\n",
      "train loss:0.0848150423554333\n",
      "train loss:0.08896287175465716\n",
      "train loss:0.028553531188323288\n",
      "train loss:0.08162342201062048\n",
      "train loss:0.059712542503815504\n",
      "train loss:0.07952511200902891\n",
      "train loss:0.1463964502000404\n",
      "train loss:0.06827252988131734\n",
      "train loss:0.04894189307458549\n",
      "train loss:0.0701747246691967\n",
      "train loss:0.08039329718600706\n",
      "train loss:0.03495091871008206\n",
      "train loss:0.08124913333062271\n",
      "train loss:0.06358370105404021\n",
      "train loss:0.12438239571507106\n",
      "train loss:0.04751167891246255\n",
      "train loss:0.055886053713671106\n",
      "train loss:0.1146990125630985\n",
      "train loss:0.07850810438634306\n",
      "train loss:0.0800457332584505\n",
      "train loss:0.039668913305962776\n",
      "train loss:0.033078397561713026\n",
      "train loss:0.05950593553579523\n",
      "train loss:0.041574733611689174\n",
      "train loss:0.05817699334644036\n",
      "train loss:0.045379815666643536\n",
      "train loss:0.06442729506560856\n",
      "train loss:0.1256000960463064\n",
      "train loss:0.04944508924460063\n",
      "train loss:0.07089110926326814\n",
      "train loss:0.0856851369168327\n",
      "train loss:0.04125335207125169\n",
      "train loss:0.2571053714229549\n",
      "train loss:0.10833820390219287\n",
      "train loss:0.038468703426620766\n",
      "train loss:0.07430074352780794\n",
      "train loss:0.07788853262745582\n",
      "train loss:0.045421765422503035\n",
      "train loss:0.10825389475143626\n",
      "train loss:0.03761200997732266\n",
      "train loss:0.20099485255930452\n",
      "train loss:0.06063576326456268\n",
      "train loss:0.04097163274521518\n",
      "train loss:0.17505555143591697\n",
      "train loss:0.03352429233348206\n",
      "train loss:0.0909150908859038\n",
      "train loss:0.10106339703268481\n",
      "train loss:0.028540329800399902\n",
      "train loss:0.1306624308927149\n",
      "train loss:0.02226209281171643\n",
      "train loss:0.08777933499414192\n",
      "train loss:0.10266136140313512\n",
      "train loss:0.08531693884281343\n",
      "train loss:0.04483336059862224\n",
      "train loss:0.09636705534378338\n",
      "train loss:0.04032232297618398\n",
      "train loss:0.06573101741571373\n",
      "train loss:0.0557675446707307\n",
      "train loss:0.13317186179988952\n",
      "train loss:0.14277690606800617\n",
      "train loss:0.10898431096668865\n",
      "train loss:0.020952284709240453\n",
      "train loss:0.04872602796761592\n",
      "train loss:0.046416533703434994\n",
      "train loss:0.04399658439942361\n",
      "train loss:0.09129919466865705\n",
      "train loss:0.05843317666240047\n",
      "train loss:0.06742042988700525\n",
      "train loss:0.19583956035993252\n",
      "train loss:0.06642026984302359\n",
      "train loss:0.05187130883072481\n",
      "train loss:0.12215759744269417\n",
      "train loss:0.05257164676276794\n",
      "train loss:0.1622122973963867\n",
      "train loss:0.018782825139894033\n",
      "train loss:0.029128904961118415\n",
      "train loss:0.10680443569105164\n",
      "train loss:0.03718227497470441\n",
      "train loss:0.14129406870829497\n",
      "train loss:0.02278919763794876\n",
      "train loss:0.08192654756929248\n",
      "train loss:0.04880337950777898\n",
      "train loss:0.09500611616897298\n",
      "train loss:0.036999617564970104\n",
      "train loss:0.061003702800611063\n",
      "train loss:0.09903367711291709\n",
      "train loss:0.1934530502709265\n",
      "train loss:0.020053171936484416\n",
      "train loss:0.03357457688428436\n",
      "train loss:0.06228396033831122\n",
      "train loss:0.03577211668508379\n",
      "train loss:0.02496020588380496\n",
      "train loss:0.06417455794628538\n",
      "train loss:0.08079291516634042\n",
      "train loss:0.15498028116449108\n",
      "train loss:0.04992366010322173\n",
      "train loss:0.055344723540765035\n",
      "train loss:0.2297447316762912\n",
      "train loss:0.035625034019897334\n",
      "train loss:0.07854162186692742\n",
      "train loss:0.05771095416559935\n",
      "train loss:0.10834690176307202\n",
      "train loss:0.06903770026557578\n",
      "train loss:0.03807031838960495\n",
      "train loss:0.027111542376798976\n",
      "train loss:0.052286847772117506\n",
      "train loss:0.048338585352444445\n",
      "train loss:0.023609132344474055\n",
      "train loss:0.16981777978818965\n",
      "train loss:0.016207799458874718\n",
      "train loss:0.03886175348473155\n",
      "train loss:0.06511065076547164\n",
      "train loss:0.08616310088201558\n",
      "train loss:0.07018895477377264\n",
      "train loss:0.07952475957448643\n",
      "train loss:0.12704698922708324\n",
      "train loss:0.05226595106654933\n",
      "train loss:0.13156660625399838\n",
      "train loss:0.09692950034123379\n",
      "train loss:0.046927265765585154\n",
      "train loss:0.21860063519643425\n",
      "train loss:0.09359776491078828\n",
      "train loss:0.03461396973023992\n",
      "train loss:0.055507302119052186\n",
      "train loss:0.07678389508744411\n",
      "train loss:0.0771114544187363\n",
      "train loss:0.03645009435217904\n",
      "train loss:0.051931471098917055\n",
      "train loss:0.07400333191217061\n",
      "train loss:0.17775529087614259\n",
      "train loss:0.047075013071092686\n",
      "train loss:0.059347436201024874\n",
      "train loss:0.047239909936956294\n",
      "train loss:0.08337648548947486\n",
      "train loss:0.04075140310644649\n",
      "train loss:0.01785185630385048\n",
      "train loss:0.11501730365279528\n",
      "train loss:0.10689299455022512\n",
      "train loss:0.1293165559366313\n",
      "train loss:0.06676006486422982\n",
      "train loss:0.06889613927990214\n",
      "train loss:0.06768238103626684\n",
      "train loss:0.07666439871154675\n",
      "train loss:0.03552059099654363\n",
      "train loss:0.023552579641643888\n",
      "train loss:0.09252763103532846\n",
      "train loss:0.11926026940510197\n",
      "train loss:0.035941918309264\n",
      "train loss:0.05772239432091568\n",
      "train loss:0.0782343317453808\n",
      "train loss:0.13958748056448314\n",
      "train loss:0.05237587136128961\n",
      "train loss:0.07986413585047931\n",
      "train loss:0.0703306465039587\n",
      "train loss:0.05223798707569585\n",
      "train loss:0.03763716830907413\n",
      "train loss:0.059184196697160324\n",
      "train loss:0.12584171395256039\n",
      "train loss:0.06001171409896009\n",
      "train loss:0.08328962297125143\n",
      "train loss:0.06816333482434478\n",
      "train loss:0.04205498710358475\n",
      "train loss:0.04651822358199151\n",
      "train loss:0.035781332022759835\n",
      "train loss:0.1291092634232382\n",
      "train loss:0.06910279211403317\n",
      "train loss:0.10718541543290802\n",
      "train loss:0.060622013250545816\n",
      "train loss:0.13110510021870242\n",
      "train loss:0.05278501983433368\n",
      "train loss:0.041880999830109476\n",
      "train loss:0.06913964153285289\n",
      "train loss:0.034585089910016874\n",
      "train loss:0.08040075232387701\n",
      "train loss:0.05563067176093895\n",
      "train loss:0.03366184494689255\n",
      "train loss:0.0957905838585174\n",
      "train loss:0.12306069383095115\n",
      "train loss:0.08819026139933797\n",
      "train loss:0.057758613981814914\n",
      "train loss:0.12784315647725725\n",
      "train loss:0.03163553449891651\n",
      "train loss:0.06999712314830832\n",
      "train loss:0.08549332422180848\n",
      "train loss:0.04399719660013332\n",
      "train loss:0.08371597612183622\n",
      "train loss:0.08214032342990088\n",
      "train loss:0.05330578160327506\n",
      "train loss:0.051517255797798596\n",
      "train loss:0.047171802196649466\n",
      "train loss:0.05363219486779611\n",
      "train loss:0.02533900350665089\n",
      "train loss:0.1488635504710141\n",
      "train loss:0.09145800502367521\n",
      "train loss:0.09116435039501104\n",
      "train loss:0.04155204509069489\n",
      "train loss:0.03997666294604221\n",
      "train loss:0.05677386454170315\n",
      "train loss:0.07193777147223705\n",
      "train loss:0.0190710990982789\n",
      "train loss:0.048589539515602846\n",
      "train loss:0.025263489006108863\n",
      "train loss:0.04557671194285382\n",
      "train loss:0.09776140498182023\n",
      "train loss:0.05878066800693996\n",
      "train loss:0.0980611938368782\n",
      "train loss:0.030339215912297397\n",
      "train loss:0.027352687165325306\n",
      "train loss:0.07555397962756916\n",
      "train loss:0.02396825609962006\n",
      "train loss:0.0879543764444199\n",
      "train loss:0.144150865473269\n",
      "train loss:0.08262286293878575\n",
      "train loss:0.10204096205545021\n",
      "train loss:0.09146985010162341\n",
      "train loss:0.046162785851583656\n",
      "train loss:0.013217075420819116\n",
      "train loss:0.05832983885510345\n",
      "train loss:0.01600477069439012\n",
      "train loss:0.10976052818088497\n",
      "train loss:0.12358777972785877\n",
      "train loss:0.014649611051456504\n",
      "train loss:0.06283948746785689\n",
      "train loss:0.03430507464905973\n",
      "train loss:0.05771998034613434\n",
      "train loss:0.0483642928232146\n",
      "train loss:0.03949023243253644\n",
      "train loss:0.02683132438433359\n",
      "train loss:0.07921972807343085\n",
      "train loss:0.04039008347590169\n",
      "train loss:0.1331402787113377\n",
      "train loss:0.037494242032807545\n",
      "train loss:0.041485532802035\n",
      "train loss:0.055189201145404765\n",
      "train loss:0.05078458742210118\n",
      "train loss:0.09489321780879635\n",
      "train loss:0.1147505936789617\n",
      "train loss:0.08870711181738804\n",
      "train loss:0.05102854945736279\n",
      "train loss:0.04834987874094696\n",
      "train loss:0.09058614804663573\n",
      "train loss:0.06810660985563771\n",
      "train loss:0.041956886704809564\n",
      "train loss:0.027947205636559825\n",
      "train loss:0.02143036070725965\n",
      "train loss:0.05747997659413895\n",
      "train loss:0.107324896196261\n",
      "train loss:0.09611796368925102\n",
      "train loss:0.03215349708951123\n",
      "train loss:0.029414184020105063\n",
      "train loss:0.09615177538723435\n",
      "train loss:0.06150085824841891\n",
      "train loss:0.015850736775074453\n",
      "train loss:0.0559263460246964\n",
      "train loss:0.06112617761957804\n",
      "train loss:0.032530393531675666\n",
      "train loss:0.05850076306130899\n",
      "train loss:0.11584609178457063\n",
      "train loss:0.07936038961017346\n",
      "train loss:0.08841784964329127\n",
      "train loss:0.09238424184369874\n",
      "train loss:0.0669146173896761\n",
      "=== epoch:3, train acc:0.977, test acc:0.977 ===\n",
      "train loss:0.09470567353253324\n",
      "train loss:0.05040194685871549\n",
      "train loss:0.034157316675798285\n",
      "train loss:0.05430858487148451\n",
      "train loss:0.031602234420568066\n",
      "train loss:0.032723250445534285\n",
      "train loss:0.0537221923395271\n",
      "train loss:0.03754324208911483\n",
      "train loss:0.04288368977577086\n",
      "train loss:0.04039885042945479\n",
      "train loss:0.03058612420905158\n",
      "train loss:0.052641762090389524\n",
      "train loss:0.023739229502398117\n",
      "train loss:0.11488544482225625\n",
      "train loss:0.0683712503411722\n",
      "train loss:0.04226354488579275\n",
      "train loss:0.040922012003875914\n",
      "train loss:0.07263871204919571\n",
      "train loss:0.03613965114626564\n",
      "train loss:0.03536225611658997\n",
      "train loss:0.06032310405148264\n",
      "train loss:0.07012269181744275\n",
      "train loss:0.07573416830811767\n",
      "train loss:0.17655041454220274\n",
      "train loss:0.06936283165224466\n",
      "train loss:0.07206576856257813\n",
      "train loss:0.0692883678114347\n",
      "train loss:0.04847968219644477\n",
      "train loss:0.08885529945036576\n",
      "train loss:0.054785760328683535\n",
      "train loss:0.014479185355369538\n",
      "train loss:0.09016124294172397\n",
      "train loss:0.057138134151343466\n",
      "train loss:0.07209450914496472\n",
      "train loss:0.04224299572005785\n",
      "train loss:0.0706407245236882\n",
      "train loss:0.10970927183779523\n",
      "train loss:0.023184164304553088\n",
      "train loss:0.02511488017735591\n",
      "train loss:0.06290667719956465\n",
      "train loss:0.03671684855267398\n",
      "train loss:0.03702888140045563\n",
      "train loss:0.020561423726085555\n",
      "train loss:0.07518221500091839\n",
      "train loss:0.04576828202820973\n",
      "train loss:0.030608988502204615\n",
      "train loss:0.07247343067156359\n",
      "train loss:0.03217823547991609\n",
      "train loss:0.10331973331635606\n",
      "train loss:0.03628972402214128\n",
      "train loss:0.0440978158463339\n",
      "train loss:0.07880828153305751\n",
      "train loss:0.02409359202721814\n",
      "train loss:0.09705049511626304\n",
      "train loss:0.022953084414862986\n",
      "train loss:0.05463801758357865\n",
      "train loss:0.03385067975622182\n",
      "train loss:0.048653243097240235\n",
      "train loss:0.06202820989430436\n",
      "train loss:0.048154546295480015\n",
      "train loss:0.08223045429772304\n",
      "train loss:0.09928388203264174\n",
      "train loss:0.04355787010946401\n",
      "train loss:0.05560624330850551\n",
      "train loss:0.07927964796185966\n",
      "train loss:0.05122280979723959\n",
      "train loss:0.055178711118780095\n",
      "train loss:0.042008326794205096\n",
      "train loss:0.06150011368577142\n",
      "train loss:0.06617182405028645\n",
      "train loss:0.11799083349515367\n",
      "train loss:0.03122999725797176\n",
      "train loss:0.06465304070202267\n",
      "train loss:0.028649594902036127\n",
      "train loss:0.03737303912524745\n",
      "train loss:0.04696337674541558\n",
      "train loss:0.05532317083294942\n",
      "train loss:0.049602665320161145\n",
      "train loss:0.06482681545883404\n",
      "train loss:0.09494714353579986\n",
      "train loss:0.040259828638834\n",
      "train loss:0.10904379128931595\n",
      "train loss:0.05769834152845639\n",
      "train loss:0.02412601678430107\n",
      "train loss:0.0976354905575007\n",
      "train loss:0.015027436993420655\n",
      "train loss:0.0299714625773536\n",
      "train loss:0.08817995276530372\n",
      "train loss:0.034859547740481285\n",
      "train loss:0.04748262222803467\n",
      "train loss:0.05648406924774142\n",
      "train loss:0.04710877112363173\n",
      "train loss:0.03473569199003277\n",
      "train loss:0.09306098996239713\n",
      "train loss:0.07084626877402458\n",
      "train loss:0.07880761272309512\n",
      "train loss:0.0744382013294518\n",
      "train loss:0.06412917551343379\n",
      "train loss:0.030602117544500436\n",
      "train loss:0.02442571044339276\n",
      "train loss:0.03208799357358477\n",
      "train loss:0.1329354621145276\n",
      "train loss:0.022658567441267163\n",
      "train loss:0.10167934782695413\n",
      "train loss:0.12322374942325755\n",
      "train loss:0.06632097575423367\n",
      "train loss:0.016269194463329893\n",
      "train loss:0.02514526900465105\n",
      "train loss:0.10557394238480297\n",
      "train loss:0.11788992289975109\n",
      "train loss:0.057549949012303786\n",
      "train loss:0.1097154628353774\n",
      "train loss:0.052648102180345865\n",
      "train loss:0.02544649519102908\n",
      "train loss:0.1338744954749099\n",
      "train loss:0.02321250426679045\n",
      "train loss:0.09020545652515097\n",
      "train loss:0.038234991316638864\n",
      "train loss:0.03897303901748106\n",
      "train loss:0.07151344059132572\n",
      "train loss:0.032494966166837884\n",
      "train loss:0.04746026346124768\n",
      "train loss:0.069915505709809\n",
      "train loss:0.05166102371162163\n",
      "train loss:0.023241158797651998\n",
      "train loss:0.10697078898797145\n",
      "train loss:0.04697017193307596\n",
      "train loss:0.06150406809436307\n",
      "train loss:0.03968703646833913\n",
      "train loss:0.05214275340791723\n",
      "train loss:0.04024683585660023\n",
      "train loss:0.03452748373301363\n",
      "train loss:0.043722407448210536\n",
      "train loss:0.02710468819275111\n",
      "train loss:0.060037914601239147\n",
      "train loss:0.06849650323426192\n",
      "train loss:0.06519925873586026\n",
      "train loss:0.16481651005331543\n",
      "train loss:0.05971925040705642\n",
      "train loss:0.029301165850841873\n",
      "train loss:0.020298764682118643\n",
      "train loss:0.06556263207657552\n",
      "train loss:0.027027406900130266\n",
      "train loss:0.016929577457752056\n",
      "train loss:0.062439663873271815\n",
      "train loss:0.04485763732832039\n",
      "train loss:0.037092397138274585\n",
      "train loss:0.02265650595664948\n",
      "train loss:0.12211629540404118\n",
      "train loss:0.061300184929045744\n",
      "train loss:0.01943110623930408\n",
      "train loss:0.014904987890267854\n",
      "train loss:0.09405437929009935\n",
      "train loss:0.00894174223891978\n",
      "train loss:0.027689825591613818\n",
      "train loss:0.04933899750988078\n",
      "train loss:0.020110754678134436\n",
      "train loss:0.05893892106561137\n",
      "train loss:0.04341711845242826\n",
      "train loss:0.060921372289857716\n",
      "train loss:0.052017423999536794\n",
      "train loss:0.056647829084681994\n",
      "train loss:0.027402080521477003\n",
      "train loss:0.04780294515491018\n",
      "train loss:0.01584043970026548\n",
      "train loss:0.032111033863547966\n",
      "train loss:0.04322678523518111\n",
      "train loss:0.06505613894588705\n",
      "train loss:0.07842588293845446\n",
      "train loss:0.00969034293606527\n",
      "train loss:0.06610976769928423\n",
      "train loss:0.00413119943875181\n",
      "train loss:0.03347374118253211\n",
      "train loss:0.06713563979041683\n",
      "train loss:0.0536723408876111\n",
      "train loss:0.04309504128929308\n",
      "train loss:0.05173050937377346\n",
      "train loss:0.06046457904594014\n",
      "train loss:0.043466413534093605\n",
      "train loss:0.05169318275849223\n",
      "train loss:0.0698513237020619\n",
      "train loss:0.021025731432641147\n",
      "train loss:0.01476404535652912\n",
      "train loss:0.038576164110454024\n",
      "train loss:0.06329947897995701\n",
      "train loss:0.0776408393204103\n",
      "train loss:0.07401477356784653\n",
      "train loss:0.05283421727435319\n",
      "train loss:0.05584166024444934\n",
      "train loss:0.04728840025990258\n",
      "train loss:0.05200275411621763\n",
      "train loss:0.07404912775714868\n",
      "train loss:0.01771911772856108\n",
      "train loss:0.11426927907078056\n",
      "train loss:0.07937185871832432\n",
      "train loss:0.03422068479717944\n",
      "train loss:0.08043306377963655\n",
      "train loss:0.04798655493190746\n",
      "train loss:0.09375686023562914\n",
      "train loss:0.031143125426436397\n",
      "train loss:0.03380168422992682\n",
      "train loss:0.0825954087101686\n",
      "train loss:0.0750426527280043\n",
      "train loss:0.06924222327011903\n",
      "train loss:0.034940390501054124\n",
      "train loss:0.038001592053154634\n",
      "train loss:0.012990327948815631\n",
      "train loss:0.053497615885643\n",
      "train loss:0.08064160084084544\n",
      "train loss:0.05093415324607015\n",
      "train loss:0.06751274185422393\n",
      "train loss:0.06449581740623066\n",
      "train loss:0.06335304344325152\n",
      "train loss:0.06337443098820925\n",
      "train loss:0.023447560055241238\n",
      "train loss:0.03771103694196389\n",
      "train loss:0.06346889936098543\n",
      "train loss:0.0788038434330884\n",
      "train loss:0.1085482190081189\n",
      "train loss:0.05643938612306404\n",
      "train loss:0.09957415087366167\n",
      "train loss:0.03276052469608381\n",
      "train loss:0.028712676079057923\n",
      "train loss:0.014269392032585853\n",
      "train loss:0.01541389242198351\n",
      "train loss:0.13109046518151143\n",
      "train loss:0.09686597281658127\n",
      "train loss:0.036565398177509575\n",
      "train loss:0.03649060837798135\n",
      "train loss:0.05769180776973871\n",
      "train loss:0.013844012330508899\n",
      "train loss:0.011299155506718837\n",
      "train loss:0.11815278080772806\n",
      "train loss:0.04328173001135359\n",
      "train loss:0.019595347947961403\n",
      "train loss:0.10742296871523153\n",
      "train loss:0.09958593953953152\n",
      "train loss:0.01675135824090055\n",
      "train loss:0.027454206901983424\n",
      "train loss:0.05344276679129818\n",
      "train loss:0.021598960298402466\n",
      "train loss:0.052890432265727004\n",
      "train loss:0.07981201100007801\n",
      "train loss:0.023829715124536816\n",
      "train loss:0.05040055314725547\n",
      "train loss:0.05801266192499774\n",
      "train loss:0.04536181233372058\n",
      "train loss:0.054263295901768885\n",
      "train loss:0.04240413090561082\n",
      "train loss:0.04664538552541541\n",
      "train loss:0.03879655512777926\n",
      "train loss:0.01569806167571495\n",
      "train loss:0.1233868845259825\n",
      "train loss:0.14638120079986316\n",
      "train loss:0.05154435440808414\n",
      "train loss:0.19415303671539305\n",
      "train loss:0.08614631547738645\n",
      "train loss:0.054928611126780845\n",
      "train loss:0.018723223573010542\n",
      "train loss:0.025289030630761218\n",
      "train loss:0.04116525755462512\n",
      "train loss:0.06045209023154297\n",
      "train loss:0.07552782183406753\n",
      "train loss:0.1064766059128198\n",
      "train loss:0.0643793566968654\n",
      "train loss:0.04433782078639163\n",
      "train loss:0.028927807128924246\n",
      "train loss:0.06989141433445537\n",
      "train loss:0.012605650094191624\n",
      "train loss:0.08868142766249813\n",
      "train loss:0.0673318399548553\n",
      "train loss:0.02062775098303125\n",
      "train loss:0.05277937916259003\n",
      "train loss:0.028342222171605216\n",
      "train loss:0.04965151692988483\n",
      "train loss:0.02463720706859958\n",
      "train loss:0.03204940546722001\n",
      "train loss:0.031234882275655976\n",
      "train loss:0.08301054169554063\n",
      "train loss:0.05998938317460606\n",
      "train loss:0.058894759415658623\n",
      "train loss:0.054339102687442326\n",
      "train loss:0.04396361558415484\n",
      "train loss:0.024844705875015926\n",
      "train loss:0.03433821307585463\n",
      "train loss:0.03366184164477711\n",
      "train loss:0.01983141183292257\n",
      "train loss:0.03013114976705781\n",
      "train loss:0.036948166450294695\n",
      "train loss:0.0411403323800363\n",
      "train loss:0.021624562601026784\n",
      "train loss:0.1364983909807015\n",
      "train loss:0.07582978888459974\n",
      "train loss:0.03712683367521844\n",
      "train loss:0.024134633407805105\n",
      "train loss:0.040414238048440534\n",
      "train loss:0.034594748620737664\n",
      "train loss:0.0982548367775939\n",
      "train loss:0.052739499114562036\n",
      "train loss:0.04585295272259558\n",
      "train loss:0.04924363712468207\n",
      "train loss:0.105628960480631\n",
      "train loss:0.13355145456218234\n",
      "train loss:0.07207146385851775\n",
      "train loss:0.11870891454203157\n",
      "train loss:0.12830149344114328\n",
      "train loss:0.05672048509201348\n",
      "train loss:0.06949615756254342\n",
      "train loss:0.027457861662568334\n",
      "train loss:0.04057087407209569\n",
      "train loss:0.038747731764421804\n",
      "train loss:0.1247476009591951\n",
      "train loss:0.04217499498550382\n",
      "train loss:0.1303015925700647\n",
      "train loss:0.02367067511377098\n",
      "train loss:0.020314728135922448\n",
      "train loss:0.05686600355076183\n",
      "train loss:0.07170452248452257\n",
      "train loss:0.05551592908951295\n",
      "train loss:0.08354659701749442\n",
      "train loss:0.011979690773696837\n",
      "train loss:0.10739423490245173\n",
      "train loss:0.04608488433768399\n",
      "train loss:0.044701216269101375\n",
      "train loss:0.08759060148039044\n",
      "train loss:0.032556406853804905\n",
      "train loss:0.0705260698808771\n",
      "train loss:0.06996907591137423\n",
      "train loss:0.02502931610019961\n",
      "train loss:0.07518667230884779\n",
      "train loss:0.024583538627898277\n",
      "train loss:0.09966232721459534\n",
      "train loss:0.045406051140454304\n",
      "train loss:0.037738643060853394\n",
      "train loss:0.049465024634820554\n",
      "train loss:0.05149085893491926\n",
      "train loss:0.04714002192305047\n",
      "train loss:0.12240738817768121\n",
      "train loss:0.060929088238848995\n",
      "train loss:0.01591242976151935\n",
      "train loss:0.02429393068799974\n",
      "train loss:0.03613943450926654\n",
      "train loss:0.07724873409623056\n",
      "train loss:0.0374034242703414\n",
      "train loss:0.020966506343425298\n",
      "train loss:0.052422809688411884\n",
      "train loss:0.028376691408121886\n",
      "train loss:0.015909323158940704\n",
      "train loss:0.0675954547443526\n",
      "train loss:0.028073956936550716\n",
      "train loss:0.08397972149739105\n",
      "train loss:0.03693516544678888\n",
      "train loss:0.10343419945423397\n",
      "train loss:0.041083632399411076\n",
      "train loss:0.03890904194398341\n",
      "train loss:0.01827399868119392\n",
      "train loss:0.020526388933202817\n",
      "train loss:0.050851483505906646\n",
      "train loss:0.05429104238379015\n",
      "train loss:0.11518663903373713\n",
      "train loss:0.04939862340905611\n",
      "train loss:0.016427708256931288\n",
      "train loss:0.05767737854178424\n",
      "train loss:0.0137228257126881\n",
      "train loss:0.02108191262684359\n",
      "train loss:0.07526292396571664\n",
      "train loss:0.03158918859600613\n",
      "train loss:0.01855880869906649\n",
      "train loss:0.02343741180792686\n",
      "train loss:0.07828700570225393\n",
      "train loss:0.05094480069161693\n",
      "train loss:0.011194894041372914\n",
      "train loss:0.02829225768880904\n",
      "train loss:0.029610970297023864\n",
      "train loss:0.039593472476304\n",
      "train loss:0.06457216589205278\n",
      "train loss:0.021580054593662676\n",
      "train loss:0.01331722211636715\n",
      "train loss:0.03999078565413693\n",
      "train loss:0.060271128944345165\n",
      "train loss:0.01143285233510439\n",
      "train loss:0.03781424758873097\n",
      "train loss:0.036804605224731016\n",
      "train loss:0.030089957948265796\n",
      "train loss:0.04219914007573507\n",
      "train loss:0.04538113751584831\n",
      "train loss:0.12647733647566534\n",
      "train loss:0.038479279052980535\n",
      "train loss:0.041029072405568245\n",
      "train loss:0.023141950259247944\n",
      "train loss:0.05154044832633339\n",
      "train loss:0.05862246859747579\n",
      "train loss:0.027622704203942507\n",
      "train loss:0.043261399149448036\n",
      "train loss:0.01732660760112606\n",
      "train loss:0.06516071313782466\n",
      "train loss:0.01875664071980622\n",
      "train loss:0.1511629440207018\n",
      "train loss:0.018438671828397774\n",
      "train loss:0.04012621859808784\n",
      "train loss:0.05636762088671067\n",
      "train loss:0.047691860300397515\n",
      "train loss:0.09255301741968903\n",
      "train loss:0.024994683508559764\n",
      "train loss:0.020141164174869136\n",
      "train loss:0.040848474849277255\n",
      "train loss:0.04693276991208186\n",
      "train loss:0.021452764780180433\n",
      "train loss:0.029942409023691254\n",
      "train loss:0.024786290913872532\n",
      "train loss:0.052050223783265764\n",
      "train loss:0.02386501168011943\n",
      "train loss:0.029474453726899063\n",
      "train loss:0.058827276856470254\n",
      "train loss:0.06095000744346089\n",
      "train loss:0.018257713607230143\n",
      "train loss:0.08345516727947812\n",
      "train loss:0.041533657731079365\n",
      "train loss:0.05357919279518516\n",
      "train loss:0.09342482414922848\n",
      "train loss:0.14684701698869504\n",
      "train loss:0.11450590339443753\n",
      "train loss:0.02188938116864228\n",
      "train loss:0.1188465309063255\n",
      "train loss:0.04714296848728905\n",
      "train loss:0.02362989537571039\n",
      "train loss:0.06723183663023663\n",
      "train loss:0.054338473439639386\n",
      "train loss:0.08234135903354296\n",
      "train loss:0.08525434121863695\n",
      "train loss:0.046752007153390125\n",
      "train loss:0.03410328645809456\n",
      "train loss:0.044292781532588504\n",
      "train loss:0.06058277522113545\n",
      "train loss:0.04205691409709055\n",
      "train loss:0.0436203887715006\n",
      "train loss:0.038770899428025245\n",
      "train loss:0.02772235313600751\n",
      "train loss:0.038792401066752816\n",
      "train loss:0.02468736129164915\n",
      "train loss:0.05638213324382726\n",
      "train loss:0.046513377430234835\n",
      "train loss:0.034889270222114084\n",
      "train loss:0.09662785342804804\n",
      "train loss:0.03828472939448731\n",
      "train loss:0.04193812224897478\n",
      "train loss:0.07988089889584486\n",
      "train loss:0.03437024092795584\n",
      "train loss:0.03917771582549897\n",
      "train loss:0.050234628099783754\n",
      "train loss:0.1865794108097977\n",
      "train loss:0.03184662177275052\n",
      "train loss:0.01641578142303674\n",
      "train loss:0.032595938185985406\n",
      "train loss:0.03953192313168772\n",
      "train loss:0.04914132554376176\n",
      "train loss:0.05779843632478381\n",
      "train loss:0.032935104091672274\n",
      "train loss:0.05919996325321436\n",
      "train loss:0.06923326535211673\n",
      "train loss:0.06974174332488305\n",
      "train loss:0.06493688920933818\n",
      "train loss:0.05882213091276548\n",
      "train loss:0.06442971378606169\n",
      "train loss:0.019719784904051886\n",
      "train loss:0.07091680572733555\n",
      "train loss:0.12311453259166961\n",
      "train loss:0.014636232098107691\n",
      "train loss:0.05264350060896192\n",
      "train loss:0.0625891084665718\n",
      "train loss:0.030618417576833458\n",
      "train loss:0.034448872258408716\n",
      "train loss:0.0878654658908877\n",
      "train loss:0.014872369843570252\n",
      "train loss:0.011129270177639095\n",
      "train loss:0.0299658259221324\n",
      "train loss:0.013336483473005947\n",
      "train loss:0.029956025262446274\n",
      "train loss:0.016768063701379062\n",
      "train loss:0.07314173159076148\n",
      "train loss:0.013881737591747007\n",
      "train loss:0.015278155841413983\n",
      "train loss:0.03977228205872705\n",
      "train loss:0.0701198086706952\n",
      "train loss:0.049598654155742744\n",
      "train loss:0.07517251356192542\n",
      "train loss:0.1029435164928805\n",
      "train loss:0.04176635543822867\n",
      "train loss:0.0701903717442213\n",
      "train loss:0.008373582170911243\n",
      "train loss:0.03828652817908956\n",
      "train loss:0.129317223920904\n",
      "train loss:0.03178351370383589\n",
      "train loss:0.02681579551578376\n",
      "train loss:0.026936995325750782\n",
      "train loss:0.17627252003115637\n",
      "train loss:0.0770997343341791\n",
      "train loss:0.04070369960085754\n",
      "train loss:0.03344113389221126\n",
      "train loss:0.011482915367969247\n",
      "train loss:0.03941020427582523\n",
      "train loss:0.01608028128151661\n",
      "train loss:0.015927332785692697\n",
      "train loss:0.027816483618595362\n",
      "train loss:0.023305713840183814\n",
      "train loss:0.07642232402380107\n",
      "train loss:0.031270861663049015\n",
      "train loss:0.060365761876579764\n",
      "train loss:0.04823709909613455\n",
      "train loss:0.029342729415545006\n",
      "train loss:0.039572462754397277\n",
      "train loss:0.02897240244974455\n",
      "train loss:0.013409353510873452\n",
      "train loss:0.025995132687194635\n",
      "train loss:0.062479469648045474\n",
      "train loss:0.0206147324196189\n",
      "train loss:0.030036525290591934\n",
      "train loss:0.05755464162179675\n",
      "train loss:0.02343650664425182\n",
      "train loss:0.07761788314839464\n",
      "train loss:0.024116475058931913\n",
      "train loss:0.04485968595210846\n",
      "train loss:0.03847115998786084\n",
      "train loss:0.10319463211715436\n",
      "train loss:0.08308252667461981\n",
      "train loss:0.03758781966649111\n",
      "train loss:0.041309151766605705\n",
      "train loss:0.041056115407307976\n",
      "train loss:0.03030034818480736\n",
      "train loss:0.02058270664285795\n",
      "train loss:0.0376130135264969\n",
      "train loss:0.08057220976994134\n",
      "train loss:0.027538538163340304\n",
      "train loss:0.018835049966702936\n",
      "train loss:0.02317962380342409\n",
      "train loss:0.06841974573409795\n",
      "train loss:0.06371700062736516\n",
      "train loss:0.04803763190059224\n",
      "train loss:0.02598633603808304\n",
      "train loss:0.031221689907505384\n",
      "train loss:0.10960385990046415\n",
      "train loss:0.07578668089934623\n",
      "train loss:0.04048241147278229\n",
      "train loss:0.06563113831424588\n",
      "train loss:0.05821406109765779\n",
      "train loss:0.06982624762028278\n",
      "train loss:0.06355590366217494\n",
      "train loss:0.013497671075347585\n",
      "train loss:0.013583649766443934\n",
      "train loss:0.033807420056663394\n",
      "train loss:0.06678124916677375\n",
      "train loss:0.05176775118880175\n",
      "train loss:0.054718306581064094\n",
      "train loss:0.04079099537895157\n",
      "train loss:0.02859887988785656\n",
      "train loss:0.023146206404631133\n",
      "train loss:0.02983387242389688\n",
      "train loss:0.0754372778948837\n",
      "train loss:0.06795485710980671\n",
      "train loss:0.05924259524201215\n",
      "train loss:0.033319877429818505\n",
      "train loss:0.04435941853521918\n",
      "train loss:0.03646604385999904\n",
      "train loss:0.11086687243390803\n",
      "train loss:0.066040934580182\n",
      "train loss:0.06484830824986447\n",
      "train loss:0.09517295528309923\n",
      "train loss:0.04249870398499375\n",
      "train loss:0.03599864427533314\n",
      "train loss:0.05563949957200347\n",
      "train loss:0.1435745128549483\n",
      "train loss:0.023473266691593796\n",
      "train loss:0.05525096637674283\n",
      "train loss:0.012784215555611243\n",
      "train loss:0.05671461910608155\n",
      "train loss:0.02922981806637775\n",
      "train loss:0.03988076000336901\n",
      "train loss:0.018961582052566924\n",
      "train loss:0.03419756602105816\n",
      "train loss:0.023601640593587776\n",
      "train loss:0.012217280472376942\n",
      "train loss:0.045182725882785046\n",
      "train loss:0.04307010597932097\n",
      "train loss:0.02589914211428562\n",
      "train loss:0.027396943764641846\n",
      "train loss:0.1431296453555554\n",
      "train loss:0.01745610858669225\n",
      "train loss:0.06300357874286248\n",
      "train loss:0.10150957821469152\n",
      "train loss:0.02540173720925238\n",
      "train loss:0.04264470231867633\n",
      "train loss:0.06762147722282587\n",
      "train loss:0.028399787647608463\n",
      "train loss:0.0190885051285866\n",
      "train loss:0.06824732694641471\n",
      "train loss:0.053546057602884965\n",
      "train loss:0.057985975337211296\n",
      "train loss:0.06939532340015879\n",
      "train loss:0.014226774523533997\n",
      "train loss:0.07771437084394885\n",
      "=== epoch:4, train acc:0.983, test acc:0.984 ===\n",
      "train loss:0.00794374124361996\n",
      "train loss:0.03481247518827392\n",
      "train loss:0.011660092350946543\n",
      "train loss:0.01571789163800825\n",
      "train loss:0.05641824035346004\n",
      "train loss:0.039559714186046605\n",
      "train loss:0.016455581498546222\n",
      "train loss:0.05148719235554879\n",
      "train loss:0.1424014401904205\n",
      "train loss:0.02755841205566052\n",
      "train loss:0.022012888313810302\n",
      "train loss:0.03990979739326537\n",
      "train loss:0.025367559248568993\n",
      "train loss:0.10401534896176115\n",
      "train loss:0.024082842107394583\n",
      "train loss:0.02240990941675534\n",
      "train loss:0.02646942674857295\n",
      "train loss:0.13617200983890373\n",
      "train loss:0.029876611653069218\n",
      "train loss:0.045356787750124104\n",
      "train loss:0.03701887792413252\n",
      "train loss:0.10192720409481955\n",
      "train loss:0.06998939586248486\n",
      "train loss:0.039600736091597866\n",
      "train loss:0.05389311433384094\n",
      "train loss:0.043522177883917844\n",
      "train loss:0.07453903044724074\n",
      "train loss:0.02854276640925425\n",
      "train loss:0.05030521553032949\n",
      "train loss:0.04193775328945208\n",
      "train loss:0.05897713725210968\n",
      "train loss:0.006165566935367327\n",
      "train loss:0.08197490047220624\n",
      "train loss:0.01882940044028753\n",
      "train loss:0.040363157794382355\n",
      "train loss:0.03943529359543932\n",
      "train loss:0.017315187557243567\n",
      "train loss:0.025333750838127195\n",
      "train loss:0.06823900206048421\n",
      "train loss:0.05016079362830241\n",
      "train loss:0.04319626836951495\n",
      "train loss:0.06475909959408663\n",
      "train loss:0.032936237555736436\n",
      "train loss:0.024063621738775437\n",
      "train loss:0.0263440488687371\n",
      "train loss:0.011681959382327387\n",
      "train loss:0.017499602270563283\n",
      "train loss:0.017718166318827965\n",
      "train loss:0.02383215001541563\n",
      "train loss:0.034951005462140645\n",
      "train loss:0.017364508552905757\n",
      "train loss:0.08075352030460638\n",
      "train loss:0.033463582087879674\n",
      "train loss:0.05037916847599166\n",
      "train loss:0.023831440561292112\n",
      "train loss:0.03316688416905176\n",
      "train loss:0.06255921914915395\n",
      "train loss:0.04722932581873658\n",
      "train loss:0.04613730300658327\n",
      "train loss:0.01583886410898852\n",
      "train loss:0.07023508438206863\n",
      "train loss:0.014323359868866143\n",
      "train loss:0.014231934994780884\n",
      "train loss:0.049934892863778016\n",
      "train loss:0.03614644703199241\n",
      "train loss:0.014822653901301042\n",
      "train loss:0.05033654378437076\n",
      "train loss:0.03588553729325537\n",
      "train loss:0.06047361641588269\n",
      "train loss:0.013835331491135871\n",
      "train loss:0.025456652653488704\n",
      "train loss:0.023051512961439428\n",
      "train loss:0.025368341196057263\n",
      "train loss:0.020312002369746028\n",
      "train loss:0.02918379664824156\n",
      "train loss:0.02745615173814061\n",
      "train loss:0.040959330940475186\n",
      "train loss:0.09223138541563625\n",
      "train loss:0.07424345607114667\n",
      "train loss:0.037200029556297094\n",
      "train loss:0.01518740634821919\n",
      "train loss:0.02149457254167887\n",
      "train loss:0.0031124094917263667\n",
      "train loss:0.057073418178988915\n",
      "train loss:0.07039695242167782\n",
      "train loss:0.030468460095854574\n",
      "train loss:0.059515600730162994\n",
      "train loss:0.02449480139839602\n",
      "train loss:0.01044992099358976\n",
      "train loss:0.08337907098140103\n",
      "train loss:0.05373322937454451\n",
      "train loss:0.06405646547846656\n",
      "train loss:0.00587478882047521\n",
      "train loss:0.017550028853385236\n",
      "train loss:0.01812692779800895\n",
      "train loss:0.02199097868511249\n",
      "train loss:0.06675623779438729\n",
      "train loss:0.05581913662495916\n",
      "train loss:0.030717224141345416\n",
      "train loss:0.01898423410444216\n",
      "train loss:0.08685011076445572\n",
      "train loss:0.03999984736510905\n",
      "train loss:0.0373352328724208\n",
      "train loss:0.06583056622388711\n",
      "train loss:0.024601251987217392\n",
      "train loss:0.03570715185896057\n",
      "train loss:0.07303462821325293\n",
      "train loss:0.00324749860884948\n",
      "train loss:0.018239911946362174\n",
      "train loss:0.013575509822346036\n",
      "train loss:0.08218208168775815\n",
      "train loss:0.09255623222786567\n",
      "train loss:0.052411824549081096\n",
      "train loss:0.025467427389428633\n",
      "train loss:0.023961519957941647\n",
      "train loss:0.024737080549570675\n",
      "train loss:0.04127134618224119\n",
      "train loss:0.048974205249564653\n",
      "train loss:0.053250222733206704\n",
      "train loss:0.0672165763856061\n",
      "train loss:0.05275501440850526\n",
      "train loss:0.06870840939452648\n",
      "train loss:0.04338681085735449\n",
      "train loss:0.04313289932122241\n",
      "train loss:0.09385995163809435\n",
      "train loss:0.0632398129082031\n",
      "train loss:0.05401921604936652\n",
      "train loss:0.04886313000321157\n",
      "train loss:0.04406466081138519\n",
      "train loss:0.05549745635027368\n",
      "train loss:0.011018479600074637\n",
      "train loss:0.027116267754253534\n",
      "train loss:0.04375216014756389\n",
      "train loss:0.040872131308657564\n",
      "train loss:0.04098663160979081\n",
      "train loss:0.007256506304055764\n",
      "train loss:0.061631081969759326\n",
      "train loss:0.06897419999814304\n",
      "train loss:0.03675427010879037\n",
      "train loss:0.09322091182627387\n",
      "train loss:0.023564958712502238\n",
      "train loss:0.040458420228927455\n",
      "train loss:0.05260794352969835\n",
      "train loss:0.019780226423435\n",
      "train loss:0.0657961481012172\n",
      "train loss:0.02154350152325578\n",
      "train loss:0.021234296761831778\n",
      "train loss:0.08168399872627807\n",
      "train loss:0.031904206000786965\n",
      "train loss:0.026667280938360904\n",
      "train loss:0.04142056346349314\n",
      "train loss:0.04043564995430443\n",
      "train loss:0.04275655844277698\n",
      "train loss:0.0428805373407296\n",
      "train loss:0.04104256120406505\n",
      "train loss:0.01149326674200985\n",
      "train loss:0.04310833377211494\n",
      "train loss:0.06049285095624009\n",
      "train loss:0.011738862861378672\n",
      "train loss:0.05180412629463913\n",
      "train loss:0.020757677742455627\n",
      "train loss:0.05739651153864163\n",
      "train loss:0.031095157496870127\n",
      "train loss:0.04653402316542692\n",
      "train loss:0.018705250867919476\n",
      "train loss:0.018551375863550552\n",
      "train loss:0.007613060032420687\n",
      "train loss:0.017771154675052237\n",
      "train loss:0.007866233805006707\n",
      "train loss:0.02942321208810756\n",
      "train loss:0.044985374388070536\n",
      "train loss:0.10927055835324989\n",
      "train loss:0.0412301425596104\n",
      "train loss:0.0301125568957765\n",
      "train loss:0.08926530263360057\n",
      "train loss:0.0702744936178935\n",
      "train loss:0.011172376430978521\n",
      "train loss:0.02540874094921176\n",
      "train loss:0.07103498798159501\n",
      "train loss:0.03999239741165053\n",
      "train loss:0.07640403902576226\n",
      "train loss:0.03603710777069902\n",
      "train loss:0.1220232776667964\n",
      "train loss:0.029289500812539383\n",
      "train loss:0.040773211207010995\n",
      "train loss:0.14184412157994228\n",
      "train loss:0.025883335795692703\n",
      "train loss:0.008743725499033466\n",
      "train loss:0.06499741335202264\n",
      "train loss:0.03188888028028312\n",
      "train loss:0.06442955053836767\n",
      "train loss:0.0482222786487523\n",
      "train loss:0.0566944539849231\n",
      "train loss:0.06153785217642106\n",
      "train loss:0.018738458642934788\n",
      "train loss:0.025369276999393443\n",
      "train loss:0.17583158364177742\n",
      "train loss:0.014679214113667937\n",
      "train loss:0.045565723274710784\n",
      "train loss:0.06133724901757765\n",
      "train loss:0.0817418253145709\n",
      "train loss:0.0575961749369925\n",
      "train loss:0.015328507299725068\n",
      "train loss:0.010055457868276068\n",
      "train loss:0.10429665170440693\n",
      "train loss:0.04749751335787474\n",
      "train loss:0.04810041445987665\n",
      "train loss:0.0457961945318456\n",
      "train loss:0.028482691228663287\n",
      "train loss:0.06778423312640415\n",
      "train loss:0.21281850028473673\n",
      "train loss:0.012767008034869007\n",
      "train loss:0.042593051770842695\n",
      "train loss:0.04809562768400678\n",
      "train loss:0.04399267319574029\n",
      "train loss:0.054057700492447645\n",
      "train loss:0.020786573102353666\n",
      "train loss:0.05686916481160773\n",
      "train loss:0.04574118225266159\n",
      "train loss:0.035875932826514856\n",
      "train loss:0.0604051236156988\n",
      "train loss:0.047015190203138914\n",
      "train loss:0.024981112908192386\n",
      "train loss:0.025804363340402574\n",
      "train loss:0.09673196576611462\n",
      "train loss:0.017083893781009177\n",
      "train loss:0.00839661608945653\n",
      "train loss:0.030793535773058434\n",
      "train loss:0.013234403791493345\n",
      "train loss:0.04563893653857102\n",
      "train loss:0.016859772460557275\n",
      "train loss:0.017693501159081602\n",
      "train loss:0.0407156426752276\n",
      "train loss:0.04056005062909957\n",
      "train loss:0.02715442834478047\n",
      "train loss:0.02498884238280506\n",
      "train loss:0.04182473351027701\n",
      "train loss:0.015926534563520924\n",
      "train loss:0.02610668443710165\n",
      "train loss:0.052446863213186756\n",
      "train loss:0.04996323839765119\n",
      "train loss:0.05490558151014775\n",
      "train loss:0.01659264429188929\n",
      "train loss:0.020584724315597453\n",
      "train loss:0.12328775755264144\n",
      "train loss:0.021377682074520038\n",
      "train loss:0.011173241570994202\n",
      "train loss:0.03246915710964797\n",
      "train loss:0.03059181408861976\n",
      "train loss:0.0260746782105769\n",
      "train loss:0.011990335739205897\n",
      "train loss:0.011312210369738018\n",
      "train loss:0.05208474601940988\n",
      "train loss:0.07669203725532266\n",
      "train loss:0.04114479226063464\n",
      "train loss:0.013651179264225577\n",
      "train loss:0.025827848174893947\n",
      "train loss:0.013621587037938532\n",
      "train loss:0.02318921657778139\n",
      "train loss:0.042249228489972576\n",
      "train loss:0.046217796799772295\n",
      "train loss:0.03421738625748751\n",
      "train loss:0.06617297496918198\n",
      "train loss:0.03402349110692543\n",
      "train loss:0.015323116031240838\n",
      "train loss:0.05600286595167927\n",
      "train loss:0.0241900191492509\n",
      "train loss:0.015854175756922603\n",
      "train loss:0.036694991808882665\n",
      "train loss:0.01273350655901025\n",
      "train loss:0.0628853728838377\n",
      "train loss:0.07445391185042965\n",
      "train loss:0.05289270593006111\n",
      "train loss:0.01155765152661026\n",
      "train loss:0.036767220603129064\n",
      "train loss:0.018124485814204037\n",
      "train loss:0.02630852436364088\n",
      "train loss:0.024116103802272873\n",
      "train loss:0.01527480752902864\n",
      "train loss:0.04484806560633855\n",
      "train loss:0.015430201948052636\n",
      "train loss:0.04195623763143321\n",
      "train loss:0.014655484580133249\n",
      "train loss:0.10052630774530931\n",
      "train loss:0.036408332819907435\n",
      "train loss:0.03038115132781452\n",
      "train loss:0.01907552170596718\n",
      "train loss:0.05429600672941179\n",
      "train loss:0.024876888350337623\n",
      "train loss:0.024294474574804284\n",
      "train loss:0.02229824916617503\n",
      "train loss:0.034005348426073466\n",
      "train loss:0.021513206420666554\n",
      "train loss:0.047468366440874286\n",
      "train loss:0.025952658049939875\n",
      "train loss:0.043820609280358074\n",
      "train loss:0.014697039429378453\n",
      "train loss:0.024373699013239353\n",
      "train loss:0.021280581791176992\n",
      "train loss:0.09263419118038554\n",
      "train loss:0.025749896657495275\n",
      "train loss:0.013240462834086359\n",
      "train loss:0.03855445116933778\n",
      "train loss:0.19388787605469385\n",
      "train loss:0.04343442185832733\n",
      "train loss:0.019961960018975572\n",
      "train loss:0.029578657559371432\n",
      "train loss:0.040172832049450796\n",
      "train loss:0.23142344588726696\n",
      "train loss:0.04896524961626935\n",
      "train loss:0.04069123292444574\n",
      "train loss:0.019808333936621892\n",
      "train loss:0.020792228527365196\n",
      "train loss:0.010295017306099594\n",
      "train loss:0.041306291296829514\n",
      "train loss:0.01732837813646273\n",
      "train loss:0.01510222741554283\n",
      "train loss:0.05295632123420479\n",
      "train loss:0.024393845271161663\n",
      "train loss:0.012574031493765464\n",
      "train loss:0.022490503804737955\n",
      "train loss:0.08399223967861506\n",
      "train loss:0.019234516982684663\n",
      "train loss:0.04386015758511241\n",
      "train loss:0.028632673971501075\n",
      "train loss:0.057141655878528305\n",
      "train loss:0.009029396594878765\n",
      "train loss:0.013830875323379987\n",
      "train loss:0.017492581303971654\n",
      "train loss:0.044418940493649445\n",
      "train loss:0.00949817564165428\n",
      "train loss:0.024790987777817658\n",
      "train loss:0.014564510847229085\n",
      "train loss:0.04021692008819935\n",
      "train loss:0.039370242026531194\n",
      "train loss:0.03933648587589244\n",
      "train loss:0.08203418027619838\n",
      "train loss:0.03827191117800189\n",
      "train loss:0.02273187642027956\n",
      "train loss:0.05280667667636463\n",
      "train loss:0.01727444809535279\n",
      "train loss:0.011896201415300307\n",
      "train loss:0.04945814101416637\n",
      "train loss:0.019005827672189154\n",
      "train loss:0.031474022045815314\n",
      "train loss:0.0608127072423193\n",
      "train loss:0.02762801270592351\n",
      "train loss:0.06873580699548393\n",
      "train loss:0.05308937001143162\n",
      "train loss:0.03420528532683233\n",
      "train loss:0.04365711468727679\n",
      "train loss:0.07806835430610355\n",
      "train loss:0.038751644527014836\n",
      "train loss:0.031873964897514095\n",
      "train loss:0.06334451906806575\n",
      "train loss:0.06605108603829707\n",
      "train loss:0.05111167724026004\n",
      "train loss:0.02620793132630679\n",
      "train loss:0.007440638402419991\n",
      "train loss:0.035434452099348125\n",
      "train loss:0.008867862751311392\n",
      "train loss:0.039390141128197775\n",
      "train loss:0.03345020274763748\n",
      "train loss:0.022910390184429953\n",
      "train loss:0.037499735591408255\n",
      "train loss:0.022486172577805105\n",
      "train loss:0.013133068104097124\n",
      "train loss:0.019587034683253905\n",
      "train loss:0.008907905054550648\n",
      "train loss:0.014483758339086177\n",
      "train loss:0.061804516845653634\n",
      "train loss:0.014275505092713976\n",
      "train loss:0.018744120479346215\n",
      "train loss:0.05954873816333865\n",
      "train loss:0.01074000302607015\n",
      "train loss:0.03305248078336613\n",
      "train loss:0.08640377257563549\n",
      "train loss:0.02897733989400017\n",
      "train loss:0.04920999838950008\n",
      "train loss:0.0466808939864351\n",
      "train loss:0.007681562802474017\n",
      "train loss:0.005762848006903299\n",
      "train loss:0.005232333763000988\n",
      "train loss:0.03466581312439428\n",
      "train loss:0.03794558267117474\n",
      "train loss:0.019503069856509195\n",
      "train loss:0.03576395288191206\n",
      "train loss:0.00674052305599856\n",
      "train loss:0.05390099525388239\n",
      "train loss:0.021945185602032003\n",
      "train loss:0.017640352495285783\n",
      "train loss:0.07860609545647529\n",
      "train loss:0.007682361788723804\n",
      "train loss:0.023247771641591797\n",
      "train loss:0.0554506297552812\n",
      "train loss:0.07330541050418145\n",
      "train loss:0.02400638210127604\n",
      "train loss:0.08111981062362535\n",
      "train loss:0.02041133407662957\n",
      "train loss:0.056612501634085925\n",
      "train loss:0.032388693869201596\n",
      "train loss:0.02890920005233379\n",
      "train loss:0.015132699398770069\n",
      "train loss:0.05771870403851259\n",
      "train loss:0.02241002873789538\n",
      "train loss:0.00651963486416907\n",
      "train loss:0.02268889398517239\n",
      "train loss:0.005873083815357514\n",
      "train loss:0.009116778155099892\n",
      "train loss:0.07042490382244292\n",
      "train loss:0.051702426590200495\n",
      "train loss:0.019672713345447238\n",
      "train loss:0.05172054309051822\n",
      "train loss:0.0404821557814432\n",
      "train loss:0.07609684007399359\n",
      "train loss:0.028269369058766043\n",
      "train loss:0.013832725475110082\n",
      "train loss:0.045562804751870675\n",
      "train loss:0.021397622758420276\n",
      "train loss:0.04290397038510432\n",
      "train loss:0.02364698383681453\n",
      "train loss:0.01605579986098162\n",
      "train loss:0.011869760966809915\n",
      "train loss:0.11640098939173527\n",
      "train loss:0.06664838798446242\n",
      "train loss:0.028678803673322366\n",
      "train loss:0.06056317219781671\n",
      "train loss:0.01528919024988421\n",
      "train loss:0.03275474142208142\n",
      "train loss:0.007684535662012717\n",
      "train loss:0.03931601386996387\n",
      "train loss:0.006252575689958555\n",
      "train loss:0.02262767529795947\n",
      "train loss:0.022733426691350363\n",
      "train loss:0.02430956126823357\n",
      "train loss:0.028314886428840974\n",
      "train loss:0.00542605165453246\n",
      "train loss:0.016102882049958158\n",
      "train loss:0.012134465011767475\n",
      "train loss:0.020420774819452307\n",
      "train loss:0.03856864384598549\n",
      "train loss:0.008661449226146346\n",
      "train loss:0.042899457245356445\n",
      "train loss:0.004637931995729735\n",
      "train loss:0.09775704396346714\n",
      "train loss:0.026605438601317862\n",
      "train loss:0.015261657074358184\n",
      "train loss:0.13949403190070186\n",
      "train loss:0.01876971345529907\n",
      "train loss:0.009841178894716087\n",
      "train loss:0.05977693910433001\n",
      "train loss:0.020202456439137796\n",
      "train loss:0.04859858486812949\n",
      "train loss:0.016856271766242617\n",
      "train loss:0.01648266266738605\n",
      "train loss:0.025186909214992927\n",
      "train loss:0.02519662288448231\n",
      "train loss:0.024644394297003377\n",
      "train loss:0.02483882743741033\n",
      "train loss:0.025295464181593938\n",
      "train loss:0.02671512836890419\n",
      "train loss:0.10743444270870565\n",
      "train loss:0.026109317866737824\n",
      "train loss:0.03058916657457559\n",
      "train loss:0.040358085230917065\n",
      "train loss:0.060812328356773485\n",
      "train loss:0.013052916837321269\n",
      "train loss:0.024896503862386593\n",
      "train loss:0.02000028045682273\n",
      "train loss:0.02881954016685666\n",
      "train loss:0.06816492219844314\n",
      "train loss:0.008642526695627411\n",
      "train loss:0.058558242991733005\n",
      "train loss:0.012165604304882314\n",
      "train loss:0.025519561794861128\n",
      "train loss:0.020648690700032484\n",
      "train loss:0.013508102669329902\n",
      "train loss:0.006813908159172235\n",
      "train loss:0.11010260467581796\n",
      "train loss:0.04618162617344576\n",
      "train loss:0.020484059230328165\n",
      "train loss:0.014317039240833464\n",
      "train loss:0.02395974491540317\n",
      "train loss:0.027264744590386112\n",
      "train loss:0.03632871088446666\n",
      "train loss:0.05790450193330893\n",
      "train loss:0.011966295239356429\n",
      "train loss:0.050382001148401204\n",
      "train loss:0.1478176088354923\n",
      "train loss:0.030167899275813932\n",
      "train loss:0.0779360473067747\n",
      "train loss:0.025411548917021572\n",
      "train loss:0.04166030605142424\n",
      "train loss:0.04247044353358789\n",
      "train loss:0.030575309262039208\n",
      "train loss:0.027625906413071548\n",
      "train loss:0.03197599126479955\n",
      "train loss:0.02920128196559542\n",
      "train loss:0.02155012871294618\n",
      "train loss:0.015182786029492867\n",
      "train loss:0.16484606195257054\n",
      "train loss:0.026581144730684018\n",
      "train loss:0.013487747598796267\n",
      "train loss:0.007232712255924447\n",
      "train loss:0.011496356972402135\n",
      "train loss:0.04873618367921508\n",
      "train loss:0.04496191897441469\n",
      "train loss:0.016280122619381256\n",
      "train loss:0.009639147452276352\n",
      "train loss:0.015524590847373801\n",
      "train loss:0.020538386182288947\n",
      "train loss:0.021552215133214883\n",
      "train loss:0.023933213678588985\n",
      "train loss:0.026550596914039083\n",
      "train loss:0.07332131403500981\n",
      "train loss:0.028892423597209387\n",
      "train loss:0.044355504418752786\n",
      "train loss:0.02841214618464137\n",
      "train loss:0.004110718603266532\n",
      "train loss:0.017835732297253375\n",
      "train loss:0.021852003082370418\n",
      "train loss:0.008438118682809932\n",
      "train loss:0.027848573253823547\n",
      "train loss:0.08363678447797086\n",
      "train loss:0.05003680327480147\n",
      "train loss:0.020951600884454562\n",
      "train loss:0.042025350382798345\n",
      "train loss:0.022994370067492623\n",
      "train loss:0.036998624863056696\n",
      "train loss:0.019142923767308962\n",
      "train loss:0.010151184644375389\n",
      "train loss:0.0153734884303529\n",
      "train loss:0.0331603928878541\n",
      "train loss:0.03192360858343596\n",
      "train loss:0.03746998721819406\n",
      "train loss:0.023029315975099402\n",
      "train loss:0.06535431869204017\n",
      "train loss:0.004774216189245891\n",
      "train loss:0.017031214114746576\n",
      "train loss:0.030941985830249687\n",
      "train loss:0.015029091175127818\n",
      "train loss:0.16641525664855816\n",
      "train loss:0.017163506441467812\n",
      "train loss:0.019028951102934795\n",
      "train loss:0.014081212528405827\n",
      "train loss:0.018737965634282035\n",
      "train loss:0.017930932977435737\n",
      "train loss:0.045621994951179544\n",
      "train loss:0.0283295968925095\n",
      "train loss:0.009415735444330539\n",
      "train loss:0.010871658682132667\n",
      "train loss:0.052714629999536175\n",
      "train loss:0.015305027173920209\n",
      "train loss:0.02362148966746978\n",
      "train loss:0.010755353974048911\n",
      "train loss:0.06370656369294089\n",
      "train loss:0.01649279979942636\n",
      "train loss:0.05159113077297487\n",
      "train loss:0.035086248400670074\n",
      "train loss:0.01752457718900005\n",
      "train loss:0.040243135170057676\n",
      "train loss:0.010480801664213531\n",
      "train loss:0.007239127026112177\n",
      "train loss:0.03363242027334327\n",
      "train loss:0.011318453456255978\n",
      "train loss:0.013373806615192062\n",
      "train loss:0.02079042983758204\n",
      "train loss:0.010472683408055395\n",
      "train loss:0.014155845220732297\n",
      "train loss:0.007830953772319656\n",
      "train loss:0.06937697909962039\n",
      "train loss:0.007375537043783325\n",
      "train loss:0.057702974521378396\n",
      "train loss:0.01275564245530524\n",
      "train loss:0.021401700500472375\n",
      "train loss:0.042502548235357186\n",
      "train loss:0.08988804110530968\n",
      "train loss:0.02544388455959821\n",
      "train loss:0.012204881837871974\n",
      "train loss:0.03509029273750883\n",
      "train loss:0.019824579243307747\n",
      "train loss:0.07205179605226701\n",
      "train loss:0.003039031980131083\n",
      "train loss:0.009072732405617782\n",
      "train loss:0.05917825366631483\n",
      "train loss:0.05042134601738267\n",
      "train loss:0.037073948723973314\n",
      "train loss:0.03504935623427536\n",
      "train loss:0.07046893791115573\n",
      "train loss:0.040462861630141206\n",
      "train loss:0.03163567332539529\n",
      "train loss:0.012576502943770319\n",
      "train loss:0.016744842064275515\n",
      "train loss:0.011514626780615727\n",
      "train loss:0.014269276532857325\n",
      "train loss:0.007879995948448165\n",
      "train loss:0.080556131092743\n",
      "train loss:0.030544445971213214\n",
      "train loss:0.009707845327126206\n",
      "train loss:0.057826272518426806\n",
      "=== epoch:5, train acc:0.985, test acc:0.98 ===\n",
      "train loss:0.026170155928064334\n",
      "train loss:0.028224439687221752\n",
      "train loss:0.06723619762594776\n",
      "train loss:0.0642584885989931\n",
      "train loss:0.05195511339219899\n",
      "train loss:0.0509781266404721\n",
      "train loss:0.040508244616350685\n",
      "train loss:0.048733671944556474\n",
      "train loss:0.006340594879747905\n",
      "train loss:0.009240482132669729\n",
      "train loss:0.031667349064859365\n",
      "train loss:0.0400290515192705\n",
      "train loss:0.03287139152110282\n",
      "train loss:0.023757944055920684\n",
      "train loss:0.014887584135914013\n",
      "train loss:0.023377353252319214\n",
      "train loss:0.1376492923083937\n",
      "train loss:0.04282115416911962\n",
      "train loss:0.01700879832878966\n",
      "train loss:0.006519955107510812\n",
      "train loss:0.08480505739599545\n",
      "train loss:0.040919076902873074\n",
      "train loss:0.017780664976348996\n",
      "train loss:0.07366982282323542\n",
      "train loss:0.06224048740072966\n",
      "train loss:0.011413298106194182\n",
      "train loss:0.022965786660290047\n",
      "train loss:0.040608252185137333\n",
      "train loss:0.04457094155023511\n",
      "train loss:0.030340792521569786\n",
      "train loss:0.03048802631840656\n",
      "train loss:0.045555137851560776\n",
      "train loss:0.018595729343916224\n",
      "train loss:0.02705097310889608\n",
      "train loss:0.00925918075933241\n",
      "train loss:0.008096139628644269\n",
      "train loss:0.0042604272095835075\n",
      "train loss:0.05023344874346255\n",
      "train loss:0.04014675557428497\n",
      "train loss:0.02502140754285883\n",
      "train loss:0.07142004838920736\n",
      "train loss:0.049822067284558874\n",
      "train loss:0.021342518990414634\n",
      "train loss:0.024526755468912285\n",
      "train loss:0.020462782282895695\n",
      "train loss:0.024587386378730956\n",
      "train loss:0.04534709090172409\n",
      "train loss:0.009607452212415468\n",
      "train loss:0.020321392762665726\n",
      "train loss:0.015556429410413177\n",
      "train loss:0.007325640826509149\n",
      "train loss:0.01205310020909613\n",
      "train loss:0.039043134783993766\n",
      "train loss:0.007560426931571147\n",
      "train loss:0.05879928962273038\n",
      "train loss:0.043643153310651606\n",
      "train loss:0.03227520707491803\n",
      "train loss:0.02666517271141661\n",
      "train loss:0.0034724241160494934\n",
      "train loss:0.036477834526843\n",
      "train loss:0.0312450401165467\n",
      "train loss:0.01200591083917385\n",
      "train loss:0.021131467405880917\n",
      "train loss:0.01855251377077605\n",
      "train loss:0.017066713256919504\n",
      "train loss:0.08329586938915577\n",
      "train loss:0.012639780387509212\n",
      "train loss:0.00939127965552911\n",
      "train loss:0.017147382013915385\n",
      "train loss:0.05338982228280851\n",
      "train loss:0.12366394084120037\n",
      "train loss:0.01914287866029447\n",
      "train loss:0.019984322581794767\n",
      "train loss:0.05551684473587556\n",
      "train loss:0.04568482469824363\n",
      "train loss:0.0340242057508052\n",
      "train loss:0.027911068663259955\n",
      "train loss:0.008877640799357892\n",
      "train loss:0.018248972372708054\n",
      "train loss:0.058702057376274326\n",
      "train loss:0.01526241958529891\n",
      "train loss:0.021277616647599903\n",
      "train loss:0.006208064040715671\n",
      "train loss:0.05800894129705711\n",
      "train loss:0.028636515219345918\n",
      "train loss:0.011152926146385047\n",
      "train loss:0.02261072843240735\n",
      "train loss:0.03412899169278693\n",
      "train loss:0.012806945685066311\n",
      "train loss:0.016059804215537567\n",
      "train loss:0.07603638521277481\n",
      "train loss:0.010352073226409932\n",
      "train loss:0.09276146508353797\n",
      "train loss:0.013253673996719053\n",
      "train loss:0.004183139214460883\n",
      "train loss:0.04934924273814704\n",
      "train loss:0.03096883999422166\n",
      "train loss:0.015336637718114136\n",
      "train loss:0.009200063047402361\n",
      "train loss:0.03225206503001141\n",
      "train loss:0.07048605683688977\n",
      "train loss:0.030733127368452785\n",
      "train loss:0.014855310879561467\n",
      "train loss:0.025310729245891714\n",
      "train loss:0.020153256303425925\n",
      "train loss:0.11707171985342474\n",
      "train loss:0.018975260207430057\n",
      "train loss:0.012070606572370593\n",
      "train loss:0.045898219772137844\n",
      "train loss:0.005244618335637761\n",
      "train loss:0.012601138532047368\n",
      "train loss:0.08423967465234028\n",
      "train loss:0.014889981259156367\n",
      "train loss:0.0304620548565926\n",
      "train loss:0.007414619459562365\n",
      "train loss:0.042855738837701676\n",
      "train loss:0.018452997867789585\n",
      "train loss:0.041978121127890254\n",
      "train loss:0.015731068576677606\n",
      "train loss:0.005901548535379302\n",
      "train loss:0.03619083903917678\n",
      "train loss:0.06434251930487625\n",
      "train loss:0.03338331486123341\n",
      "train loss:0.029323060797551367\n",
      "train loss:0.0063439900677324974\n",
      "train loss:0.01460191218925605\n",
      "train loss:0.03013069692387522\n",
      "train loss:0.009044834637337037\n",
      "train loss:0.02734597947713234\n",
      "train loss:0.02727392144586061\n",
      "train loss:0.05216707073866418\n",
      "train loss:0.059348001293303726\n",
      "train loss:0.012970196783131095\n",
      "train loss:0.05785933683647397\n",
      "train loss:0.07633864366888736\n",
      "train loss:0.0409982546244911\n",
      "train loss:0.0168563227875206\n",
      "train loss:0.08433659772509428\n",
      "train loss:0.11033256445546842\n",
      "train loss:0.015433295045977848\n",
      "train loss:0.01621969249655415\n",
      "train loss:0.030808931392540786\n",
      "train loss:0.058732837138826405\n",
      "train loss:0.014363912408180326\n",
      "train loss:0.010021371187749031\n",
      "train loss:0.012500334275163163\n",
      "train loss:0.013126751464280726\n",
      "train loss:0.016027749890347345\n",
      "train loss:0.020203866462287567\n",
      "train loss:0.04147173732825807\n",
      "train loss:0.04470872748052205\n",
      "train loss:0.050223778584775225\n",
      "train loss:0.017063567349308643\n",
      "train loss:0.0034081881017323434\n",
      "train loss:0.0685049548310934\n",
      "train loss:0.025855861787900808\n",
      "train loss:0.013591031151571491\n",
      "train loss:0.022700500079933118\n",
      "train loss:0.0060642862418039505\n",
      "train loss:0.024208192250904394\n",
      "train loss:0.0236399307882106\n",
      "train loss:0.014469178475078807\n",
      "train loss:0.024025707415573715\n",
      "train loss:0.009471741466215676\n",
      "train loss:0.12545946770172184\n",
      "train loss:0.0335433959615652\n",
      "train loss:0.00921016977812569\n",
      "train loss:0.030023522954556993\n",
      "train loss:0.026094015344504787\n",
      "train loss:0.0188067419791779\n",
      "train loss:0.028493567721964652\n",
      "train loss:0.05356632667049891\n",
      "train loss:0.09673872046586869\n",
      "train loss:0.005668050528686024\n",
      "train loss:0.029686662160051617\n",
      "train loss:0.02103898151695766\n",
      "train loss:0.01598309696303865\n",
      "train loss:0.02902727618436282\n",
      "train loss:0.016392517929815692\n",
      "train loss:0.015683806757155562\n",
      "train loss:0.012541774848326068\n",
      "train loss:0.08482370951943496\n",
      "train loss:0.05810512523883439\n",
      "train loss:0.017128635857870157\n",
      "train loss:0.03457719390390707\n",
      "train loss:0.04307342126460089\n",
      "train loss:0.009416675781221845\n",
      "train loss:0.03547248308525319\n",
      "train loss:0.00716114063394286\n",
      "train loss:0.03797087217183408\n",
      "train loss:0.017056996434173008\n",
      "train loss:0.024096444512659524\n",
      "train loss:0.025581841279723877\n",
      "train loss:0.008541567583965563\n",
      "train loss:0.012126748991081156\n",
      "train loss:0.01513840271072604\n",
      "train loss:0.006823994491126886\n",
      "train loss:0.06599985747338799\n",
      "train loss:0.05093309598079379\n",
      "train loss:0.02457672651206003\n",
      "train loss:0.018617767660184158\n",
      "train loss:0.021792269910276565\n",
      "train loss:0.02657297912261253\n",
      "train loss:0.015465317031112941\n",
      "train loss:0.006388512231668664\n",
      "train loss:0.0227459358392919\n",
      "train loss:0.01500781904483172\n",
      "train loss:0.05321032045051765\n",
      "train loss:0.028577530062441094\n",
      "train loss:0.023270716011636695\n",
      "train loss:0.03340040108274989\n",
      "train loss:0.010083347229758627\n",
      "train loss:0.0070045202285223705\n",
      "train loss:0.04053679480368503\n",
      "train loss:0.046364247911916345\n",
      "train loss:0.02587265659638145\n",
      "train loss:0.10857463513105156\n",
      "train loss:0.023767242836288515\n",
      "train loss:0.018367881373713826\n",
      "train loss:0.009564923688220367\n",
      "train loss:0.01718735351680903\n",
      "train loss:0.016458676105194126\n",
      "train loss:0.043932585057459124\n",
      "train loss:0.03418503066290261\n",
      "train loss:0.03771651606433225\n",
      "train loss:0.017593082841670823\n",
      "train loss:0.031601232554499904\n",
      "train loss:0.07731489507959116\n",
      "train loss:0.005124384844110147\n",
      "train loss:0.01089444774599876\n",
      "train loss:0.04118287114141471\n",
      "train loss:0.12314876813381831\n",
      "train loss:0.01553945059650366\n",
      "train loss:0.010470768345872144\n",
      "train loss:0.03577114070434824\n",
      "train loss:0.024924049547100605\n",
      "train loss:0.07304463329550737\n",
      "train loss:0.009200252370735672\n",
      "train loss:0.012994420791117393\n",
      "train loss:0.061171051425625844\n",
      "train loss:0.029394650166931557\n",
      "train loss:0.00991080004804015\n",
      "train loss:0.013578731423568167\n",
      "train loss:0.006874196963242878\n",
      "train loss:0.00830815927968618\n",
      "train loss:0.09325053682529515\n",
      "train loss:0.06657197657551521\n",
      "train loss:0.04916491188536692\n",
      "train loss:0.04007054881844836\n",
      "train loss:0.021162098589392754\n",
      "train loss:0.013213146982334365\n",
      "train loss:0.01917573681375202\n",
      "train loss:0.060978014946155026\n",
      "train loss:0.051164472608620705\n",
      "train loss:0.019759854773389495\n",
      "train loss:0.030899697884905996\n",
      "train loss:0.08758523330609404\n",
      "train loss:0.011812277541656114\n",
      "train loss:0.012915929260937355\n",
      "train loss:0.011950061712360818\n",
      "train loss:0.07039308672030803\n",
      "train loss:0.004782867006639182\n",
      "train loss:0.015076870363761617\n",
      "train loss:0.011026330036072734\n",
      "train loss:0.016593085963030052\n",
      "train loss:0.03717122939076083\n",
      "train loss:0.012733775661876008\n",
      "train loss:0.042521910023689\n",
      "train loss:0.01935302038294137\n",
      "train loss:0.05135027964118597\n",
      "train loss:0.019722931160773303\n",
      "train loss:0.005778169772795613\n",
      "train loss:0.011227808362183476\n",
      "train loss:0.05831044274173421\n",
      "train loss:0.013872919184516424\n",
      "train loss:0.012037839772591636\n",
      "train loss:0.03919378321154512\n",
      "train loss:0.004123420537785976\n",
      "train loss:0.08905723878127227\n",
      "train loss:0.006036602017777785\n",
      "train loss:0.03771483986190337\n",
      "train loss:0.015492455887522764\n",
      "train loss:0.013902036510812888\n",
      "train loss:0.013243827117493714\n",
      "train loss:0.010144358704113548\n",
      "train loss:0.011834867366131265\n",
      "train loss:0.006161889433138484\n",
      "train loss:0.012972267173785272\n",
      "train loss:0.0525803000995081\n",
      "train loss:0.00855242492808712\n",
      "train loss:0.015945628991747132\n",
      "train loss:0.031169916023453315\n",
      "train loss:0.05054145184000561\n",
      "train loss:0.07296206541367212\n",
      "train loss:0.031547705170630595\n",
      "train loss:0.047688189446510654\n",
      "train loss:0.037713624511120994\n",
      "train loss:0.010834820442380187\n",
      "train loss:0.007992378183366459\n",
      "train loss:0.01402392122368224\n",
      "train loss:0.025817986246760766\n",
      "train loss:0.06829305582944918\n",
      "train loss:0.0146959242176647\n",
      "train loss:0.014139547577500815\n",
      "train loss:0.036901342544673366\n",
      "train loss:0.03908393798313997\n",
      "train loss:0.015289281332238945\n",
      "train loss:0.013822352444284291\n",
      "train loss:0.02065148860787364\n",
      "train loss:0.02988667072971916\n",
      "train loss:0.005140439589078889\n",
      "train loss:0.024395675763687043\n",
      "train loss:0.011100002126533826\n",
      "train loss:0.016488706170532743\n",
      "train loss:0.01273692448004301\n",
      "train loss:0.06802728938658191\n",
      "train loss:0.018657069518762573\n",
      "train loss:0.008762225408897876\n",
      "train loss:0.05148379365315888\n",
      "train loss:0.031989647205017804\n",
      "train loss:0.05149619594280309\n",
      "train loss:0.06299495645865645\n",
      "train loss:0.02649865780315043\n",
      "train loss:0.010510925137024292\n",
      "train loss:0.019146891188030934\n",
      "train loss:0.006810789009674475\n",
      "train loss:0.020141030668441254\n",
      "train loss:0.015329187703697433\n",
      "train loss:0.08219512236387266\n",
      "train loss:0.016024473586789625\n",
      "train loss:0.06071982470876866\n",
      "train loss:0.02765842766972894\n",
      "train loss:0.017910833606732766\n",
      "train loss:0.016856681748788804\n",
      "train loss:0.009467467475946664\n",
      "train loss:0.021164345044876392\n",
      "train loss:0.032062730563599394\n",
      "train loss:0.10554292493793069\n",
      "train loss:0.006016371474440621\n",
      "train loss:0.017860285163773585\n",
      "train loss:0.06845130819596788\n",
      "train loss:0.005156462583752995\n",
      "train loss:0.025431512506107604\n",
      "train loss:0.018050847811913087\n",
      "train loss:0.009215470860073054\n",
      "train loss:0.008140360412117041\n",
      "train loss:0.027908373898120956\n",
      "train loss:0.020748838342264736\n",
      "train loss:0.008721133795009259\n",
      "train loss:0.007482650320967307\n",
      "train loss:0.1180870476187395\n",
      "train loss:0.01142103697219542\n",
      "train loss:0.02459534678480946\n",
      "train loss:0.0543949036242616\n",
      "train loss:0.048633763040723636\n",
      "train loss:0.028337748032861945\n",
      "train loss:0.02531654713508877\n",
      "train loss:0.06932947094705356\n",
      "train loss:0.029000652751509422\n",
      "train loss:0.02274836989235975\n",
      "train loss:0.006987930323201177\n",
      "train loss:0.017685955399426963\n",
      "train loss:0.013634970067428982\n",
      "train loss:0.00613417228644897\n",
      "train loss:0.03209855824981988\n",
      "train loss:0.04322805384134609\n",
      "train loss:0.009692452495301514\n",
      "train loss:0.03686106580691065\n",
      "train loss:0.005287283528545798\n",
      "train loss:0.03683005162314529\n",
      "train loss:0.09372813996013311\n",
      "train loss:0.008378840987384594\n",
      "train loss:0.06530293504313273\n",
      "train loss:0.03614560387061195\n",
      "train loss:0.023937435056811958\n",
      "train loss:0.04560488710895756\n",
      "train loss:0.09555422822745499\n",
      "train loss:0.05539062510937499\n",
      "train loss:0.007753811839819389\n",
      "train loss:0.013753456106845386\n",
      "train loss:0.020653135435587378\n",
      "train loss:0.09833993587408278\n",
      "train loss:0.027357683082481845\n",
      "train loss:0.015942726142191787\n",
      "train loss:0.017995098387638457\n",
      "train loss:0.011277680482821137\n",
      "train loss:0.04151918749460528\n",
      "train loss:0.02241681241470984\n",
      "train loss:0.08560207563768586\n",
      "train loss:0.012810246132451518\n",
      "train loss:0.005989781604224705\n",
      "train loss:0.02332782377343122\n",
      "train loss:0.0052844755939777934\n",
      "train loss:0.024300227776600524\n",
      "train loss:0.025907902272998457\n",
      "train loss:0.019763785606207705\n",
      "train loss:0.008227687100866249\n",
      "train loss:0.06623611581911892\n",
      "train loss:0.02752169691670465\n",
      "train loss:0.031579704883076404\n",
      "train loss:0.019382635640597005\n",
      "train loss:0.008405520478691461\n",
      "train loss:0.025627330051976312\n",
      "train loss:0.033169834231784295\n",
      "train loss:0.013461213138328803\n",
      "train loss:0.03389655328030328\n",
      "train loss:0.033284166650687196\n",
      "train loss:0.014188726194502484\n",
      "train loss:0.05645734290895723\n",
      "train loss:0.016709547610238205\n",
      "train loss:0.026981556446644638\n",
      "train loss:0.008444946767998089\n",
      "train loss:0.008910050891795931\n",
      "train loss:0.05436128357070556\n",
      "train loss:0.0839317388866237\n",
      "train loss:0.044941072521392886\n",
      "train loss:0.05352530989921066\n",
      "train loss:0.010306373306094272\n",
      "train loss:0.017786042015316264\n",
      "train loss:0.09150661324833205\n",
      "train loss:0.003566432652193036\n",
      "train loss:0.016335848916234585\n",
      "train loss:0.012340370558161815\n",
      "train loss:0.011668675804625439\n",
      "train loss:0.015698139615546922\n",
      "train loss:0.02861478416002451\n",
      "train loss:0.007461283453735372\n",
      "train loss:0.03716148807559598\n",
      "train loss:0.06607994946942194\n",
      "train loss:0.013107879075384708\n",
      "train loss:0.01661642804147462\n",
      "train loss:0.006608987967598167\n",
      "train loss:0.05442940124003157\n",
      "train loss:0.02740915352779724\n",
      "train loss:0.016595923466397256\n",
      "train loss:0.025644741332720922\n",
      "train loss:0.00805343662398491\n",
      "train loss:0.016223999643761505\n",
      "train loss:0.012723909117086747\n",
      "train loss:0.031872314274837145\n",
      "train loss:0.007694083918119942\n",
      "train loss:0.010763147524797173\n",
      "train loss:0.016879231094104462\n",
      "train loss:0.018423622305940374\n",
      "train loss:0.03864887185827279\n",
      "train loss:0.009732707010865654\n",
      "train loss:0.06743841179658734\n",
      "train loss:0.081466923052601\n",
      "train loss:0.007901372971824023\n",
      "train loss:0.03635267793930486\n",
      "train loss:0.03322389581332916\n",
      "train loss:0.016546894138252735\n",
      "train loss:0.1486299620356138\n",
      "train loss:0.010643035352529586\n",
      "train loss:0.006013559532663638\n",
      "train loss:0.007584790941934777\n",
      "train loss:0.02425347446979006\n",
      "train loss:0.06850307498425057\n",
      "train loss:0.012218754562960397\n",
      "train loss:0.055119001995667716\n",
      "train loss:0.02362888859859788\n",
      "train loss:0.07200813030754967\n",
      "train loss:0.030511399419908963\n",
      "train loss:0.08026469845710717\n",
      "train loss:0.026396820933723527\n",
      "train loss:0.007943251886942244\n",
      "train loss:0.08150379827229573\n",
      "train loss:0.054414916864903164\n",
      "train loss:0.06736477523273195\n",
      "train loss:0.03790311816338197\n",
      "train loss:0.010373491552797393\n",
      "train loss:0.05158718715958137\n",
      "train loss:0.007711554540987474\n",
      "train loss:0.026911534268374268\n",
      "train loss:0.013634592740699227\n",
      "train loss:0.00373524447899471\n",
      "train loss:0.013760925386828646\n",
      "train loss:0.013059860667829144\n",
      "train loss:0.011114144315305517\n",
      "train loss:0.06322154421059883\n",
      "train loss:0.008454303796743617\n",
      "train loss:0.08089095620927537\n",
      "train loss:0.011129013995900985\n",
      "train loss:0.06388100297146856\n",
      "train loss:0.01409003658418001\n",
      "train loss:0.008277226799692193\n",
      "train loss:0.018585622537402906\n",
      "train loss:0.010487986238125756\n",
      "train loss:0.008569128719220305\n",
      "train loss:0.0353236544716398\n",
      "train loss:0.018445617650749754\n",
      "train loss:0.029716719851580954\n",
      "train loss:0.047914549843065514\n",
      "train loss:0.008139202145067116\n",
      "train loss:0.0373715414451697\n",
      "train loss:0.016342256703269865\n",
      "train loss:0.026430750520760504\n",
      "train loss:0.04849972785456589\n",
      "train loss:0.02495270221790026\n",
      "train loss:0.026386607062314424\n",
      "train loss:0.051359163981253564\n",
      "train loss:0.03780374802125053\n",
      "train loss:0.03687496636147993\n",
      "train loss:0.08114033646788008\n",
      "train loss:0.007927696828718196\n",
      "train loss:0.0321952090130497\n",
      "train loss:0.0427515036800201\n",
      "train loss:0.013480711429138783\n",
      "train loss:0.028494695736002062\n",
      "train loss:0.033623029655518596\n",
      "train loss:0.05568290193261133\n",
      "train loss:0.019500228740864486\n",
      "train loss:0.01348463772871922\n",
      "train loss:0.014490842580801631\n",
      "train loss:0.01843580692740294\n",
      "train loss:0.023541960455472716\n",
      "train loss:0.025940943245529483\n",
      "train loss:0.012624611369971582\n",
      "train loss:0.011920175903836277\n",
      "train loss:0.019148782196149447\n",
      "train loss:0.020571580669880157\n",
      "train loss:0.01704763375995424\n",
      "train loss:0.033072733717129064\n",
      "train loss:0.006640371552172949\n",
      "train loss:0.01732759971971968\n",
      "train loss:0.021373421459713167\n",
      "train loss:0.018999349466456334\n",
      "train loss:0.02539148572432098\n",
      "train loss:0.033548345036416995\n",
      "train loss:0.004903723682233911\n",
      "train loss:0.046988208276638216\n",
      "train loss:0.017204136692645915\n",
      "train loss:0.05561552115576439\n",
      "train loss:0.035093645531177865\n",
      "train loss:0.035079610193565494\n",
      "train loss:0.03505175198481497\n",
      "train loss:0.03420242979884992\n",
      "train loss:0.006930836401636558\n",
      "train loss:0.007341162983287341\n",
      "train loss:0.03216336907696807\n",
      "train loss:0.030204902493683638\n",
      "train loss:0.01671299922587297\n",
      "train loss:0.011008073934867047\n",
      "train loss:0.04486649391632005\n",
      "train loss:0.011899540734672523\n",
      "train loss:0.015436097223456555\n",
      "train loss:0.019703804829382235\n",
      "train loss:0.013956885718890432\n",
      "train loss:0.014442845873093546\n",
      "train loss:0.03462633053446092\n",
      "train loss:0.010913203101261077\n",
      "train loss:0.07352063511494956\n",
      "train loss:0.023162784292823063\n",
      "train loss:0.03197327441536868\n",
      "train loss:0.06438431113319508\n",
      "train loss:0.06488443037529092\n",
      "train loss:0.06604950949303422\n",
      "train loss:0.012160676871005775\n",
      "train loss:0.02139983297428989\n",
      "train loss:0.10202734986984117\n",
      "train loss:0.013789673643812547\n",
      "train loss:0.030982761188034322\n",
      "train loss:0.02171179832940418\n",
      "train loss:0.01383213369028207\n",
      "train loss:0.029527866905726778\n",
      "train loss:0.0413020795133977\n",
      "train loss:0.006389875272499055\n",
      "train loss:0.03324889662256674\n",
      "train loss:0.006059863755803726\n",
      "train loss:0.03576931873687015\n",
      "train loss:0.00253686436827951\n",
      "train loss:0.06613489970437852\n",
      "train loss:0.009168922957781926\n",
      "train loss:0.0027193546205131485\n",
      "train loss:0.02368285135814675\n",
      "train loss:0.05473048724522758\n",
      "train loss:0.014528152909152102\n",
      "train loss:0.001906134364251113\n",
      "train loss:0.006873289366694205\n",
      "train loss:0.034594108450644014\n",
      "train loss:0.005875471200407302\n",
      "train loss:0.018321228441020222\n",
      "train loss:0.007038305094285857\n",
      "train loss:0.03835895037255459\n",
      "train loss:0.04764695567030511\n",
      "train loss:0.011989865091639572\n",
      "train loss:0.008388554101378355\n",
      "train loss:0.006395884046010202\n",
      "train loss:0.007491970465637178\n",
      "train loss:0.03794666464415907\n",
      "train loss:0.039681114555660514\n",
      "train loss:0.01603768563990924\n",
      "train loss:0.02147014277598249\n",
      "train loss:0.04022395885172846\n",
      "train loss:0.02661091480559363\n",
      "train loss:0.054598930224569964\n",
      "train loss:0.004799579425353022\n",
      "train loss:0.016116283833681057\n",
      "train loss:0.027928940444550222\n",
      "train loss:0.01599063240728265\n",
      "=== epoch:6, train acc:0.985, test acc:0.984 ===\n",
      "train loss:0.0048956007073805725\n",
      "train loss:0.040466944620440495\n",
      "train loss:0.01970570161623146\n",
      "train loss:0.0817863971931018\n",
      "train loss:0.06891545009442145\n",
      "train loss:0.012216722893008547\n",
      "train loss:0.013312362700564613\n",
      "train loss:0.05171846109114758\n",
      "train loss:0.0052689603904467605\n",
      "train loss:0.04033055974676295\n",
      "train loss:0.005965181497135902\n",
      "train loss:0.024830735812406357\n",
      "train loss:0.017739703817462784\n",
      "train loss:0.03970607414193782\n",
      "train loss:0.021323959473478732\n",
      "train loss:0.03341799672843325\n",
      "train loss:0.054134998793753795\n",
      "train loss:0.0061263107556697805\n",
      "train loss:0.020928645142218927\n",
      "train loss:0.01764480974197082\n",
      "train loss:0.0304928808178657\n",
      "train loss:0.017630352552839304\n",
      "train loss:0.021589486191040064\n",
      "train loss:0.010161214188447011\n",
      "train loss:0.016677315957356626\n",
      "train loss:0.042361845352751164\n",
      "train loss:0.01339661122706972\n",
      "train loss:0.013587110359426382\n",
      "train loss:0.013032039138816922\n",
      "train loss:0.019097543119844424\n",
      "train loss:0.026554363894855663\n",
      "train loss:0.04670325438215415\n",
      "train loss:0.02728158931823948\n",
      "train loss:0.04478469836226348\n",
      "train loss:0.016312550333689987\n",
      "train loss:0.009121860185340025\n",
      "train loss:0.012964588255388829\n",
      "train loss:0.00555222522198206\n",
      "train loss:0.013092719595910955\n",
      "train loss:0.03256305390670575\n",
      "train loss:0.02217616366198065\n",
      "train loss:0.01891791154752985\n",
      "train loss:0.01881191645433647\n",
      "train loss:0.008731432124386554\n",
      "train loss:0.004494698040014208\n",
      "train loss:0.013567365449754613\n",
      "train loss:0.043132462713814254\n",
      "train loss:0.009991050319722122\n",
      "train loss:0.02042271810053225\n",
      "train loss:0.003874825184230138\n",
      "train loss:0.03474280629143674\n",
      "train loss:0.008569363536761526\n",
      "train loss:0.02753034429046284\n",
      "train loss:0.06318005843722779\n",
      "train loss:0.049992228913359964\n",
      "train loss:0.008942479157093968\n",
      "train loss:0.004556592545324713\n",
      "train loss:0.031608549734771\n",
      "train loss:0.002146274454130237\n",
      "train loss:0.015885897677405565\n",
      "train loss:0.04873257009369738\n",
      "train loss:0.012063219885858541\n",
      "train loss:0.012937924176157134\n",
      "train loss:0.018846447228039142\n",
      "train loss:0.004856052225002182\n",
      "train loss:0.05844472528798684\n",
      "train loss:0.01285403015239401\n",
      "train loss:0.027064486421934\n",
      "train loss:0.04288996721787984\n",
      "train loss:0.029487688193514838\n",
      "train loss:0.037102954753857935\n",
      "train loss:0.04806670445225838\n",
      "train loss:0.030643960070330288\n",
      "train loss:0.0136948983299472\n",
      "train loss:0.025208773784986274\n",
      "train loss:0.018075650580269033\n",
      "train loss:0.04208020097203812\n",
      "train loss:0.01799004414070737\n",
      "train loss:0.010412490198508642\n",
      "train loss:0.03504982234685088\n",
      "train loss:0.006695832887244273\n",
      "train loss:0.08734029304289857\n",
      "train loss:0.07680102223742107\n",
      "train loss:0.01793948492959472\n",
      "train loss:0.008140449572124312\n",
      "train loss:0.004294572648089666\n",
      "train loss:0.017631788574485198\n",
      "train loss:0.004197048921232416\n",
      "train loss:0.0033935577691627844\n",
      "train loss:0.007185402243197867\n",
      "train loss:0.017631442603318934\n",
      "train loss:0.028505918145063376\n",
      "train loss:0.012699189960247161\n",
      "train loss:0.09102993392313172\n",
      "train loss:0.0034512657929149635\n",
      "train loss:0.02829698362999967\n",
      "train loss:0.002170177404169564\n",
      "train loss:0.011832325691396339\n",
      "train loss:0.01394827626239512\n",
      "train loss:0.008912844301536037\n",
      "train loss:0.01908266618465995\n",
      "train loss:0.03784384181035669\n",
      "train loss:0.006613764880339202\n",
      "train loss:0.013171921795271468\n",
      "train loss:0.0058025858720939915\n",
      "train loss:0.05510032038347859\n",
      "train loss:0.03231459560414388\n",
      "train loss:0.003906241080138744\n",
      "train loss:0.012719980895579106\n",
      "train loss:0.022168289662917874\n",
      "train loss:0.06901124703192654\n",
      "train loss:0.005601023649475681\n",
      "train loss:0.013120402775703633\n",
      "train loss:0.012490334412593397\n",
      "train loss:0.023909544043212785\n",
      "train loss:0.013966105397238558\n",
      "train loss:0.04004826413386176\n",
      "train loss:0.032499055157332306\n",
      "train loss:0.04121064385380458\n",
      "train loss:0.018996529749047922\n",
      "train loss:0.0031631883370116\n",
      "train loss:0.0034511285608424896\n",
      "train loss:0.025506232911281703\n",
      "train loss:0.012900184922955676\n",
      "train loss:0.07561076268505626\n",
      "train loss:0.009920133224945582\n",
      "train loss:0.03399498356841976\n",
      "train loss:0.005986173447601688\n",
      "train loss:0.02792431683692925\n",
      "train loss:0.041719831400557954\n",
      "train loss:0.030121468207200297\n",
      "train loss:0.009602890598822857\n",
      "train loss:0.022944783582043174\n",
      "train loss:0.005934294545575345\n",
      "train loss:0.0059377200842416315\n",
      "train loss:0.015518633200047156\n",
      "train loss:0.06619424698387597\n",
      "train loss:0.008693614691555485\n",
      "train loss:0.08402295406410042\n",
      "train loss:0.01354996371035386\n",
      "train loss:0.010670944539545866\n",
      "train loss:0.025083196109016083\n",
      "train loss:0.006941763857024893\n",
      "train loss:0.027173603154409295\n",
      "train loss:0.008650038059514795\n",
      "train loss:0.008820994276174582\n",
      "train loss:0.024458527109144722\n",
      "train loss:0.022677841273355558\n",
      "train loss:0.019993810439186764\n",
      "train loss:0.03910869694904545\n",
      "train loss:0.05074168719863934\n",
      "train loss:0.0082199875858175\n",
      "train loss:0.014542801594716248\n",
      "train loss:0.013736206948332063\n",
      "train loss:0.07337434846664179\n",
      "train loss:0.01104112689230214\n",
      "train loss:0.005018925390753857\n",
      "train loss:0.07954322250886396\n",
      "train loss:0.14013177509411223\n",
      "train loss:0.04509124147497836\n",
      "train loss:0.02697286240277677\n",
      "train loss:0.015284578583925927\n",
      "train loss:0.012405202411444338\n",
      "train loss:0.0051229883800241235\n",
      "train loss:0.03143774693164131\n",
      "train loss:0.01653460109559637\n",
      "train loss:0.0161277465523204\n",
      "train loss:0.007421463609693944\n",
      "train loss:0.01191050322765518\n",
      "train loss:0.026670588595360457\n",
      "train loss:0.00807291116517049\n",
      "train loss:0.07236077542285678\n",
      "train loss:0.04253648150659177\n",
      "train loss:0.054898235921671874\n",
      "train loss:0.012281212963682517\n",
      "train loss:0.006821676391382509\n",
      "train loss:0.016252116015243373\n",
      "train loss:0.021640031653049084\n",
      "train loss:0.014301829264105025\n",
      "train loss:0.04150234280420656\n",
      "train loss:0.015622597963712832\n",
      "train loss:0.008673577856010818\n",
      "train loss:0.009858993192730103\n",
      "train loss:0.0017685982427145162\n",
      "train loss:0.018940463482087465\n",
      "train loss:0.013561211261760197\n",
      "train loss:0.004288485840923541\n",
      "train loss:0.018993263861646993\n",
      "train loss:0.003369142726032827\n",
      "train loss:0.014992791730766461\n",
      "train loss:0.043000615969386854\n",
      "train loss:0.005530832861219326\n",
      "train loss:0.004303225101336031\n",
      "train loss:0.016755963537288133\n",
      "train loss:0.03283100833032075\n",
      "train loss:0.013941763794470229\n",
      "train loss:0.02554319469238248\n",
      "train loss:0.007206345091794426\n",
      "train loss:0.03556405030949888\n",
      "train loss:0.04746354192155624\n",
      "train loss:0.011947197648867522\n",
      "train loss:0.013287987833965094\n",
      "train loss:0.06787711695771344\n",
      "train loss:0.020865639432527908\n",
      "train loss:0.023787431408094705\n",
      "train loss:0.020193523755150215\n",
      "train loss:0.06235912497273155\n",
      "train loss:0.0807416883206496\n",
      "train loss:0.0054193569545643305\n",
      "train loss:0.009589751729016164\n",
      "train loss:0.03912251629053711\n",
      "train loss:0.016152927784020072\n",
      "train loss:0.010358632432385464\n",
      "train loss:0.010516365311431184\n",
      "train loss:0.026983208733137972\n",
      "train loss:0.01976829027366747\n",
      "train loss:0.024993382896775294\n",
      "train loss:0.04290100715455925\n",
      "train loss:0.023542035846432628\n",
      "train loss:0.012288507511800774\n",
      "train loss:0.002283790455019464\n",
      "train loss:0.008044534507661847\n",
      "train loss:0.01875344207728412\n",
      "train loss:0.03180365061173409\n",
      "train loss:0.0027055672636187404\n",
      "train loss:0.016387181354155983\n",
      "train loss:0.03252121162858709\n",
      "train loss:0.013547352561335123\n",
      "train loss:0.04386479649421944\n",
      "train loss:0.04035237531264496\n",
      "train loss:0.04429336989297671\n",
      "train loss:0.035164466070896426\n",
      "train loss:0.007332499064419179\n",
      "train loss:0.020538128684373224\n",
      "train loss:0.022618078328903266\n",
      "train loss:0.03270037080007669\n",
      "train loss:0.027896111189351598\n",
      "train loss:0.029487274936998778\n",
      "train loss:0.07723308478771342\n",
      "train loss:0.008691230815031807\n",
      "train loss:0.010130339916931817\n",
      "train loss:0.02398293475392367\n",
      "train loss:0.02234212114644329\n",
      "train loss:0.006709122984391317\n",
      "train loss:0.010861023327488572\n",
      "train loss:0.05273697762803087\n",
      "train loss:0.007695954515353184\n",
      "train loss:0.015712451597441585\n",
      "train loss:0.005851703711531606\n",
      "train loss:0.041163819039376166\n",
      "train loss:0.012635172019333157\n",
      "train loss:0.022371622174721308\n",
      "train loss:0.0017298836040685259\n",
      "train loss:0.005521287742925461\n",
      "train loss:0.008503301654772694\n",
      "train loss:0.017855610046644675\n",
      "train loss:0.02231675851302522\n",
      "train loss:0.020035957400423177\n",
      "train loss:0.005609348357121119\n",
      "train loss:0.02559660011935949\n",
      "train loss:0.0016448889898133692\n",
      "train loss:0.023982090446458635\n",
      "train loss:0.005350045593604334\n",
      "train loss:0.022123482525694342\n",
      "train loss:0.015186361081485902\n",
      "train loss:0.027550579159544192\n",
      "train loss:0.051436796282391936\n",
      "train loss:0.009907527586687996\n",
      "train loss:0.053721818381623404\n",
      "train loss:0.020648795188969792\n",
      "train loss:0.006823947464178334\n",
      "train loss:0.0015952010619924516\n",
      "train loss:0.010649789796965065\n",
      "train loss:0.014258896031531689\n",
      "train loss:0.024325749644555493\n",
      "train loss:0.008288408406397966\n",
      "train loss:0.017019343412236432\n",
      "train loss:0.02732682989130466\n",
      "train loss:0.02630312197842633\n",
      "train loss:0.15254400316595576\n",
      "train loss:0.003413340193379646\n",
      "train loss:0.042083382925532764\n",
      "train loss:0.03355288259548573\n",
      "train loss:0.012468886356064445\n",
      "train loss:0.006436734448113767\n",
      "train loss:0.046269084726725127\n",
      "train loss:0.00868792200116229\n",
      "train loss:0.0459189327624686\n",
      "train loss:0.014184675052270472\n",
      "train loss:0.018890779640427978\n",
      "train loss:0.0022096298410248212\n",
      "train loss:0.024709206852570813\n",
      "train loss:0.010942084930186603\n",
      "train loss:0.013847393508673329\n",
      "train loss:0.0717718261949419\n",
      "train loss:0.018486320400816478\n",
      "train loss:0.024821274954278914\n",
      "train loss:0.016470117321873517\n",
      "train loss:0.011581358630754402\n",
      "train loss:0.005956795635894979\n",
      "train loss:0.017926145536290804\n",
      "train loss:0.013498013887527572\n",
      "train loss:0.023617866501567344\n",
      "train loss:0.011014002415695688\n",
      "train loss:0.029122226297983365\n",
      "train loss:0.006792528632455968\n",
      "train loss:0.009234670099420247\n",
      "train loss:0.0029230388924090032\n",
      "train loss:0.037222029201509146\n",
      "train loss:0.008802026642389028\n",
      "train loss:0.04483778412401796\n",
      "train loss:0.02944091476474746\n",
      "train loss:0.015603443100241926\n",
      "train loss:0.033691120585485616\n",
      "train loss:0.00627885348746616\n",
      "train loss:0.00785835478319818\n",
      "train loss:0.00406966019792773\n",
      "train loss:0.014144929817139154\n",
      "train loss:0.0029699140656973388\n",
      "train loss:0.0695436560179031\n",
      "train loss:0.028754972150703294\n",
      "train loss:0.008320528327571594\n",
      "train loss:0.013063384488192276\n",
      "train loss:0.054752326607225815\n",
      "train loss:0.020772549714178908\n",
      "train loss:0.003798491068547393\n",
      "train loss:0.009064034197874134\n",
      "train loss:0.025740108388122553\n",
      "train loss:0.015584862067264482\n",
      "train loss:0.017160776130704308\n",
      "train loss:0.017449177312338006\n",
      "train loss:0.00573766507253918\n",
      "train loss:0.017709344838835198\n",
      "train loss:0.02388166869932361\n",
      "train loss:0.012866649743177383\n",
      "train loss:0.03446990325119275\n",
      "train loss:0.055180137046650764\n",
      "train loss:0.01977134411231794\n",
      "train loss:0.03663518620610925\n",
      "train loss:0.07299245407130345\n",
      "train loss:0.013855928587368609\n",
      "train loss:0.024009244050844713\n",
      "train loss:0.02230335346875225\n",
      "train loss:0.057998169578510075\n",
      "train loss:0.008302325294387798\n",
      "train loss:0.00633214748865335\n",
      "train loss:0.023372010410599522\n",
      "train loss:0.0679107732483944\n",
      "train loss:0.008787952390111396\n",
      "train loss:0.016800444119903897\n",
      "train loss:0.02785645254459208\n",
      "train loss:0.008319180759411467\n",
      "train loss:0.009500010220954855\n",
      "train loss:0.03456648131115258\n",
      "train loss:0.015387691540179866\n",
      "train loss:0.024843464712378447\n",
      "train loss:0.031157301484251138\n",
      "train loss:0.02022643526896083\n",
      "train loss:0.010827769754985648\n",
      "train loss:0.004321706868437629\n",
      "train loss:0.005051236361639934\n",
      "train loss:0.02229553185797019\n",
      "train loss:0.05738678363096996\n",
      "train loss:0.026233554304837738\n",
      "train loss:0.021709072209384277\n",
      "train loss:0.0031515862610265078\n",
      "train loss:0.0069838466630649885\n",
      "train loss:0.005221085797799424\n",
      "train loss:0.009388936128454393\n",
      "train loss:0.008083428439555021\n",
      "train loss:0.007611748737315776\n",
      "train loss:0.014450238021555808\n",
      "train loss:0.0030128187551183455\n",
      "train loss:0.0473475868752177\n",
      "train loss:0.025280117945768964\n",
      "train loss:0.024051088746030548\n",
      "train loss:0.011511438184605989\n",
      "train loss:0.013594363301785855\n",
      "train loss:0.020100717515194804\n",
      "train loss:0.04174341090508177\n",
      "train loss:0.005900952739695029\n",
      "train loss:0.05777557517932691\n",
      "train loss:0.022297727156380027\n",
      "train loss:0.013928453555854115\n",
      "train loss:0.05682290657891203\n",
      "train loss:0.006721959124310758\n",
      "train loss:0.020501324857445116\n",
      "train loss:0.02955327709131137\n",
      "train loss:0.02171654497504498\n",
      "train loss:0.0018176769270498397\n",
      "train loss:0.02518471541168488\n",
      "train loss:0.015420677847536444\n",
      "train loss:0.01391802607961818\n",
      "train loss:0.03135187548850169\n",
      "train loss:0.008414299452425783\n",
      "train loss:0.0374836627552699\n",
      "train loss:0.0192265963912384\n",
      "train loss:0.009090245332387581\n",
      "train loss:0.0165935115619666\n",
      "train loss:0.01114535758993747\n",
      "train loss:0.012331075187447022\n",
      "train loss:0.011817397243623674\n",
      "train loss:0.01746282530966842\n",
      "train loss:0.003985982948002264\n",
      "train loss:0.01581798638470289\n",
      "train loss:0.05995564104196367\n",
      "train loss:0.00897203369992275\n",
      "train loss:0.04629521537838822\n",
      "train loss:0.006501197133489797\n",
      "train loss:0.009648980443102901\n",
      "train loss:0.010309755947987142\n",
      "train loss:0.016023950915453826\n",
      "train loss:0.0205330693255567\n",
      "train loss:0.004758201334425658\n",
      "train loss:0.014769621811201637\n",
      "train loss:0.011851599138529744\n",
      "train loss:0.01615366081083561\n",
      "train loss:0.013797487684158574\n",
      "train loss:0.004294170618177975\n",
      "train loss:0.02768943093081823\n",
      "train loss:0.01844057980573518\n",
      "train loss:0.051860591933925636\n",
      "train loss:0.007387336778743208\n",
      "train loss:0.02885947248099456\n",
      "train loss:0.003511090975690612\n",
      "train loss:0.009989413789525121\n",
      "train loss:0.012320198867652518\n",
      "train loss:0.007982936691502372\n",
      "train loss:0.020190872639715498\n",
      "train loss:0.003680301336751268\n",
      "train loss:0.013089251181999837\n",
      "train loss:0.02202584440706396\n",
      "train loss:0.011909573525137369\n",
      "train loss:0.04265597343154122\n",
      "train loss:0.008235537903092161\n",
      "train loss:0.018343161107063168\n",
      "train loss:0.025417369047661027\n",
      "train loss:0.014784252113310182\n",
      "train loss:0.009689631139540609\n",
      "train loss:0.0043301672758306545\n",
      "train loss:0.017167877325704097\n",
      "train loss:0.004910810183039126\n",
      "train loss:0.004488827855360312\n",
      "train loss:0.010506788849121032\n",
      "train loss:0.018032192365790674\n",
      "train loss:0.003475897557582892\n",
      "train loss:0.007510925136378391\n",
      "train loss:0.014149433156700702\n",
      "train loss:0.02044989295127513\n",
      "train loss:0.009146120286024425\n",
      "train loss:0.007657832077961713\n",
      "train loss:0.012675508995200747\n",
      "train loss:0.03394003203805036\n",
      "train loss:0.013627393978869888\n",
      "train loss:0.007395082543563085\n",
      "train loss:0.03792032646282979\n",
      "train loss:0.011007208467321101\n",
      "train loss:0.02010693883030497\n",
      "train loss:0.01973740854361215\n",
      "train loss:0.041924967616875454\n",
      "train loss:0.022364531968233296\n",
      "train loss:0.00710646662228391\n",
      "train loss:0.010933700350067839\n",
      "train loss:0.0521189821359411\n",
      "train loss:0.06362620015329065\n",
      "train loss:0.0696149353921023\n",
      "train loss:0.01937453887557865\n",
      "train loss:0.06258756415786004\n",
      "train loss:0.004667822617300344\n",
      "train loss:0.003052166019517807\n",
      "train loss:0.005014977942005384\n",
      "train loss:0.00364970646081084\n",
      "train loss:0.027580202938353632\n",
      "train loss:0.05155327201729779\n",
      "train loss:0.04268209274164815\n",
      "train loss:0.008060929743765401\n",
      "train loss:0.005641251342706204\n",
      "train loss:0.008649901740051223\n",
      "train loss:0.035673568483046106\n",
      "train loss:0.002640494019502469\n",
      "train loss:0.03720596233755103\n",
      "train loss:0.09325312440937271\n",
      "train loss:0.012174494747744296\n",
      "train loss:0.003370339101898922\n",
      "train loss:0.006011216526653198\n",
      "train loss:0.02674608218650928\n",
      "train loss:0.04456534282411285\n",
      "train loss:0.004196035507752582\n",
      "train loss:0.007941224319166525\n",
      "train loss:0.01236795966658379\n",
      "train loss:0.012337700078319936\n",
      "train loss:0.014770114889781907\n",
      "train loss:0.05279094564983085\n",
      "train loss:0.0342325499242624\n",
      "train loss:0.03866867050654966\n",
      "train loss:0.027221833408154664\n",
      "train loss:0.025738846134146662\n",
      "train loss:0.03635942655275463\n",
      "train loss:0.009275173237326031\n",
      "train loss:0.005419390289265555\n",
      "train loss:0.007002626375701771\n",
      "train loss:0.006957447366033962\n",
      "train loss:0.017201242139462898\n",
      "train loss:0.004156702992713663\n",
      "train loss:0.005856571697919563\n",
      "train loss:0.012084142996478787\n",
      "train loss:0.03764607576844044\n",
      "train loss:0.007507825463424081\n",
      "train loss:0.014945965133657655\n",
      "train loss:0.013484391238896103\n",
      "train loss:0.035330327545433894\n",
      "train loss:0.002148261557847979\n",
      "train loss:0.0167083681144633\n",
      "train loss:0.012966176622998309\n",
      "train loss:0.04383862419253457\n",
      "train loss:0.03173470089146094\n",
      "train loss:0.020679440003461665\n",
      "train loss:0.012491518685253982\n",
      "train loss:0.03185817498998398\n",
      "train loss:0.02198579165827097\n",
      "train loss:0.025688250420232813\n",
      "train loss:0.013347690711892728\n",
      "train loss:0.009578458727453729\n",
      "train loss:0.08038121296580915\n",
      "train loss:0.07701677047138528\n",
      "train loss:0.031478806889105475\n",
      "train loss:0.004726893655864552\n",
      "train loss:0.028138446713704853\n",
      "train loss:0.014237126819109573\n",
      "train loss:0.011695493643952459\n",
      "train loss:0.12997831703311888\n",
      "train loss:0.007467676092976014\n",
      "train loss:0.03770243333240806\n",
      "train loss:0.010892229721702541\n",
      "train loss:0.013823233750398395\n",
      "train loss:0.009323727437038885\n",
      "train loss:0.027792030063925468\n",
      "train loss:0.010844924611021768\n",
      "train loss:0.04581915504882314\n",
      "train loss:0.0029363978740060853\n",
      "train loss:0.012186462000868946\n",
      "train loss:0.010705286919742384\n",
      "train loss:0.01268489662729145\n",
      "train loss:0.024877207606883653\n",
      "train loss:0.003512920322641953\n",
      "train loss:0.01263533998703317\n",
      "train loss:0.009217156615941855\n",
      "train loss:0.0168057425847279\n",
      "train loss:0.012552443932924868\n",
      "train loss:0.015610131301482175\n",
      "train loss:0.015866883722186413\n",
      "train loss:0.011611743051163905\n",
      "train loss:0.017756986043779642\n",
      "train loss:0.046754245900552424\n",
      "train loss:0.0017778582373812436\n",
      "train loss:0.02337100672962391\n",
      "train loss:0.030979654389819387\n",
      "train loss:0.013674537909226223\n",
      "train loss:0.027737606317717618\n",
      "train loss:0.0032020854154300427\n",
      "train loss:0.08896421320995355\n",
      "train loss:0.010577150984765846\n",
      "train loss:0.016136000965414878\n",
      "train loss:0.12896876110064726\n",
      "train loss:0.02189523403804126\n",
      "train loss:0.015547027925387324\n",
      "train loss:0.016503429081759377\n",
      "train loss:0.02162554127749344\n",
      "train loss:0.041916833679923104\n",
      "train loss:0.007173031770447166\n",
      "train loss:0.024387920301220393\n",
      "train loss:0.03515361906580321\n",
      "train loss:0.055896018390941195\n",
      "train loss:0.007444547529983934\n",
      "train loss:0.027795506528428243\n",
      "train loss:0.005040727120766777\n",
      "train loss:0.015913916606144943\n",
      "train loss:0.05719142873837577\n",
      "train loss:0.01569067107362742\n",
      "train loss:0.014089766872452801\n",
      "train loss:0.0051458310204105405\n",
      "train loss:0.011860904543564234\n",
      "train loss:0.006562875046087345\n",
      "train loss:0.004944340499365298\n",
      "train loss:0.025488479056681595\n",
      "train loss:0.035123732885186665\n",
      "train loss:0.009803795705288661\n",
      "train loss:0.005174750667936211\n",
      "train loss:0.014598840853343266\n",
      "train loss:0.00938538537783658\n",
      "train loss:0.03939368204207914\n",
      "train loss:0.011948441923272707\n",
      "train loss:0.033590421075644784\n",
      "train loss:0.026397272138715216\n",
      "train loss:0.008822236637734439\n",
      "train loss:0.009296704233080828\n",
      "train loss:0.0021488842978086152\n",
      "train loss:0.0067419726585927\n",
      "train loss:0.020876613395707042\n",
      "train loss:0.018617252246030308\n",
      "=== epoch:7, train acc:0.994, test acc:0.99 ===\n",
      "train loss:0.012815067002069302\n",
      "train loss:0.004321159500338676\n",
      "train loss:0.00717284334855126\n",
      "train loss:0.016130155717891684\n",
      "train loss:0.01517263826597719\n",
      "train loss:0.004708778584976082\n",
      "train loss:0.012389156062334943\n",
      "train loss:0.01735030265862274\n",
      "train loss:0.013320900470449365\n",
      "train loss:0.036374902157151216\n",
      "train loss:0.008569307190139798\n",
      "train loss:0.024360146706679502\n",
      "train loss:0.050396778366095185\n",
      "train loss:0.005250132356627634\n",
      "train loss:0.006454576737710466\n",
      "train loss:0.012128149771267136\n",
      "train loss:0.032427266112258074\n",
      "train loss:0.015217728121108056\n",
      "train loss:0.010955413155229222\n",
      "train loss:0.016914046921438993\n",
      "train loss:0.006155107363896005\n",
      "train loss:0.018254235856702623\n",
      "train loss:0.001709628114742966\n",
      "train loss:0.00334805240071351\n",
      "train loss:0.03502277992107945\n",
      "train loss:0.02977955185345676\n",
      "train loss:0.033173560969664936\n",
      "train loss:0.005185789555273403\n",
      "train loss:0.02544175009660245\n",
      "train loss:0.046524225717448645\n",
      "train loss:0.025241231318773552\n",
      "train loss:0.0068547882028892814\n",
      "train loss:0.015199757952521204\n",
      "train loss:0.03392751238436678\n",
      "train loss:0.007405913712577574\n",
      "train loss:0.009368539132164393\n",
      "train loss:0.008462514944355994\n",
      "train loss:0.0065650010084289554\n",
      "train loss:0.01858265297070766\n",
      "train loss:0.006839037827452776\n",
      "train loss:0.007214226862005827\n",
      "train loss:0.005917051261252312\n",
      "train loss:0.007841817500268192\n",
      "train loss:0.014893024828135544\n",
      "train loss:0.002880045280657995\n",
      "train loss:0.009411404781436596\n",
      "train loss:0.04139833583451335\n",
      "train loss:0.02319284968146751\n",
      "train loss:0.0387353146893949\n",
      "train loss:0.010187252655992251\n",
      "train loss:0.00560449354282057\n",
      "train loss:0.009506445326867136\n",
      "train loss:0.016798991665670598\n",
      "train loss:0.0027788745576829877\n",
      "train loss:0.005223079659712055\n",
      "train loss:0.014002252480998716\n",
      "train loss:0.018713073579532963\n",
      "train loss:0.010234095894117588\n",
      "train loss:0.002053647080623317\n",
      "train loss:0.017783855966549147\n",
      "train loss:0.011836519387088079\n",
      "train loss:0.002409417188953762\n",
      "train loss:0.02344966499927297\n",
      "train loss:0.020818499599726828\n",
      "train loss:0.01934756164569056\n",
      "train loss:0.023613465755967535\n",
      "train loss:0.008676734886437137\n",
      "train loss:0.004972824348128289\n",
      "train loss:0.027872787723638486\n",
      "train loss:0.01061867483963043\n",
      "train loss:0.007041279087519942\n",
      "train loss:0.007594775179631079\n",
      "train loss:0.02040138184339664\n",
      "train loss:0.01287088166513506\n",
      "train loss:0.010018624995570791\n",
      "train loss:0.005888493710293351\n",
      "train loss:0.01235837967788366\n",
      "train loss:0.033366152276149606\n",
      "train loss:0.032546121433154045\n",
      "train loss:0.02072609934657916\n",
      "train loss:0.0021705464684317437\n",
      "train loss:0.017021199750555573\n",
      "train loss:0.017836364069657714\n",
      "train loss:0.016214372919850416\n",
      "train loss:0.03401085111148975\n",
      "train loss:0.005064379595963876\n",
      "train loss:0.0024097959653421952\n",
      "train loss:0.007532355522902073\n",
      "train loss:0.013384716560184237\n",
      "train loss:0.013094618314341371\n",
      "train loss:0.02633236978191728\n",
      "train loss:0.01709098638877098\n",
      "train loss:0.00480754783788458\n",
      "train loss:0.018418070951987855\n",
      "train loss:0.014961425844841622\n",
      "train loss:0.044917723220028155\n",
      "train loss:0.015456427750149621\n",
      "train loss:0.02582811002031288\n",
      "train loss:0.006197976272633722\n",
      "train loss:0.02690495512051725\n",
      "train loss:0.008927337943181915\n",
      "train loss:0.01153337011105535\n",
      "train loss:0.01954635319019049\n",
      "train loss:0.034537338808219874\n",
      "train loss:0.002732454736160542\n",
      "train loss:0.022470894285088142\n",
      "train loss:0.009445162820206337\n",
      "train loss:0.012576660269428688\n",
      "train loss:0.0031076045709541884\n",
      "train loss:0.015074566986848656\n",
      "train loss:0.019057183287877505\n",
      "train loss:0.004783718373778247\n",
      "train loss:0.08600622840873676\n",
      "train loss:0.004902856005464862\n",
      "train loss:0.00310206934744125\n",
      "train loss:0.09146170256449399\n",
      "train loss:0.0025791427870386348\n",
      "train loss:0.01513389538917011\n",
      "train loss:0.00668182827767921\n",
      "train loss:0.004814294244243269\n",
      "train loss:0.015506992703084517\n",
      "train loss:0.004226830725008857\n",
      "train loss:0.05230969396725632\n",
      "train loss:0.0316033498291272\n",
      "train loss:0.0060275232098874944\n",
      "train loss:0.004271986258490663\n",
      "train loss:0.04012865997171298\n",
      "train loss:0.008655569795803241\n",
      "train loss:0.011197428769959453\n",
      "train loss:0.011192402575600578\n",
      "train loss:0.004100536782074826\n",
      "train loss:0.002558260908021309\n",
      "train loss:0.0587263327988998\n",
      "train loss:0.004957114395494527\n",
      "train loss:0.015458351048083976\n",
      "train loss:0.0063835159850924505\n",
      "train loss:0.004549452967465949\n",
      "train loss:0.056511842281600826\n",
      "train loss:0.023472958934115096\n",
      "train loss:0.03215988203758733\n",
      "train loss:0.0065289355509301795\n",
      "train loss:0.004013718238131358\n",
      "train loss:0.005548247120378226\n",
      "train loss:0.02449804434643751\n",
      "train loss:0.009782948267671461\n",
      "train loss:0.017062866192545684\n",
      "train loss:0.035138386225623326\n",
      "train loss:0.04858398218367782\n",
      "train loss:0.011089720620617553\n",
      "train loss:0.008338938317600287\n",
      "train loss:0.02061746858160275\n",
      "train loss:0.011424241152109445\n",
      "train loss:0.02884979240866051\n",
      "train loss:0.02939305692145609\n",
      "train loss:0.017627725205100423\n",
      "train loss:0.033997135866662545\n",
      "train loss:0.012299810165300356\n",
      "train loss:0.04056371160023382\n",
      "train loss:0.054696418282034254\n",
      "train loss:0.006236357708494277\n",
      "train loss:0.03221748465004297\n",
      "train loss:0.0108897279636017\n",
      "train loss:0.008937719253365934\n",
      "train loss:0.0024826985023356663\n",
      "train loss:0.04456810133642516\n",
      "train loss:0.020814551776158475\n",
      "train loss:0.020880356638268746\n",
      "train loss:0.08287225174394186\n",
      "train loss:0.010064745596158775\n",
      "train loss:0.012523844862291219\n",
      "train loss:0.01038220733557825\n",
      "train loss:0.006330252724180355\n",
      "train loss:0.01892866646986369\n",
      "train loss:0.00865793807909512\n",
      "train loss:0.01135809853136646\n",
      "train loss:0.00801697600188954\n",
      "train loss:0.013119636227172788\n",
      "train loss:0.007388854391553864\n",
      "train loss:0.005072043096245858\n",
      "train loss:0.026153541141678113\n",
      "train loss:0.008204886460752615\n",
      "train loss:0.0102508520254164\n",
      "train loss:0.007791151071947853\n",
      "train loss:0.005272963351493612\n",
      "train loss:0.0023547007384275807\n",
      "train loss:0.00453246535786746\n",
      "train loss:0.0023791659505448025\n",
      "train loss:0.01675582741181536\n",
      "train loss:0.02502683009997156\n",
      "train loss:0.00346689513023392\n",
      "train loss:0.0073077543508537155\n",
      "train loss:0.03399859542056539\n",
      "train loss:0.0214305806689234\n",
      "train loss:0.010110764016188495\n",
      "train loss:0.063384649103544\n",
      "train loss:0.0014190142924139784\n",
      "train loss:0.01211661342333566\n",
      "train loss:0.006307323225128701\n",
      "train loss:0.014002891476899305\n",
      "train loss:0.0358207442508303\n",
      "train loss:0.017926186798569853\n",
      "train loss:0.03500541432577932\n",
      "train loss:0.005437808281661125\n",
      "train loss:0.020103992635451897\n",
      "train loss:0.02698882348738791\n",
      "train loss:0.00846112207242281\n",
      "train loss:0.02352265784430019\n",
      "train loss:0.010061163267930696\n",
      "train loss:0.030211865334931764\n",
      "train loss:0.036963065095214714\n",
      "train loss:0.012454452775238592\n",
      "train loss:0.016193465154042228\n",
      "train loss:0.02570439121984861\n",
      "train loss:0.07291227119975029\n",
      "train loss:0.002316303746565465\n",
      "train loss:0.0068925983974664415\n",
      "train loss:0.016660265659205465\n",
      "train loss:0.01858220534528017\n",
      "train loss:0.04202387329860738\n",
      "train loss:0.009154697467481267\n",
      "train loss:0.1554975913454654\n",
      "train loss:0.028333494662503657\n",
      "train loss:0.008696406389803792\n",
      "train loss:0.018194131145392176\n",
      "train loss:0.009131454670179511\n",
      "train loss:0.023294685521748543\n",
      "train loss:0.023778200647652178\n",
      "train loss:0.011110480382406957\n",
      "train loss:0.010551359554990541\n",
      "train loss:0.010168232086457476\n",
      "train loss:0.014979140462294894\n",
      "train loss:0.005413590107301532\n",
      "train loss:0.0024396605932199976\n",
      "train loss:0.017670925078667875\n",
      "train loss:0.014746523515230512\n",
      "train loss:0.005478838493733704\n",
      "train loss:0.026929902613704582\n",
      "train loss:0.009749798742477216\n",
      "train loss:0.005376816116295548\n",
      "train loss:0.024836338103070996\n",
      "train loss:0.011095201667368102\n",
      "train loss:0.05951244005203549\n",
      "train loss:0.003482513226082096\n",
      "train loss:0.01589099365422544\n",
      "train loss:0.031702103465523594\n",
      "train loss:0.006876739176003852\n",
      "train loss:0.0027158776046857865\n",
      "train loss:0.010611291782354582\n",
      "train loss:0.021855860022059925\n",
      "train loss:0.013073217128835897\n",
      "train loss:0.0063292410415312274\n",
      "train loss:0.009166918583229875\n",
      "train loss:0.0032949338384573113\n",
      "train loss:0.0045384987572641144\n",
      "train loss:0.005461900967058714\n",
      "train loss:0.008314063911327295\n",
      "train loss:0.020578812609769938\n",
      "train loss:0.029943141301581263\n",
      "train loss:0.056536731300583946\n",
      "train loss:0.022516267362149903\n",
      "train loss:0.005965705270969064\n",
      "train loss:0.017447340788183583\n",
      "train loss:0.02205332178570331\n",
      "train loss:0.007459839507053955\n",
      "train loss:0.01147751561633933\n",
      "train loss:0.007619647595007969\n",
      "train loss:0.026573169556868007\n",
      "train loss:0.009802824709983013\n",
      "train loss:0.04828984645250671\n",
      "train loss:0.05945277727010825\n",
      "train loss:0.002440717760647715\n",
      "train loss:0.003167585703457837\n",
      "train loss:0.004917345191872861\n",
      "train loss:0.018618623841348915\n",
      "train loss:0.02591536976961766\n",
      "train loss:0.013345951524446214\n",
      "train loss:0.03154265040209767\n",
      "train loss:0.04640450474900169\n",
      "train loss:0.018722328851657498\n",
      "train loss:0.0009243042186260622\n",
      "train loss:0.06864681012466649\n",
      "train loss:0.0067959638208931515\n",
      "train loss:0.011834795310444655\n",
      "train loss:0.044517715916795896\n",
      "train loss:0.017077514355530236\n",
      "train loss:0.0045318717789408595\n",
      "train loss:0.03524215683622707\n",
      "train loss:0.025865014686014\n",
      "train loss:0.005450218552152853\n",
      "train loss:0.02072165905915173\n",
      "train loss:0.02888174469875553\n",
      "train loss:0.020584903498801644\n",
      "train loss:0.00705661496954422\n",
      "train loss:0.010527105525643114\n",
      "train loss:0.002920362658445719\n",
      "train loss:0.022400839907080427\n",
      "train loss:0.006621459144947989\n",
      "train loss:0.02261265654254661\n",
      "train loss:0.0151448579116121\n",
      "train loss:0.005934026164347719\n",
      "train loss:0.00567316278890173\n",
      "train loss:0.007613697207273058\n",
      "train loss:0.004612872375214355\n",
      "train loss:0.017801993255098462\n",
      "train loss:0.01260202789075756\n",
      "train loss:0.041610689417912995\n",
      "train loss:0.013916115034608689\n",
      "train loss:0.04518544364884898\n",
      "train loss:0.057914742228413946\n",
      "train loss:0.008511318263044621\n",
      "train loss:0.005963481484983614\n",
      "train loss:0.017603960601364505\n",
      "train loss:0.017331351332148782\n",
      "train loss:0.017096125988827607\n",
      "train loss:0.02942856602823716\n",
      "train loss:0.001613923486091097\n",
      "train loss:0.015107620881545918\n",
      "train loss:0.009201101920961501\n",
      "train loss:0.0282323176096414\n",
      "train loss:0.04872978875596905\n",
      "train loss:0.0077715661519444645\n",
      "train loss:0.0037915237139317876\n",
      "train loss:0.005308746389503992\n",
      "train loss:0.009319567043258547\n",
      "train loss:0.0027611275487899197\n",
      "train loss:0.009495721584609578\n",
      "train loss:0.03947068704013554\n",
      "train loss:0.0243595546668873\n",
      "train loss:0.0422107488721293\n",
      "train loss:0.015849791859603383\n",
      "train loss:0.05867457715582614\n",
      "train loss:0.01642522363080721\n",
      "train loss:0.004327912673605979\n",
      "train loss:0.08720670303945542\n",
      "train loss:0.006024194277389015\n",
      "train loss:0.0027065690464607526\n",
      "train loss:0.03062039807490085\n",
      "train loss:0.005183249854172503\n",
      "train loss:0.008573136112005749\n",
      "train loss:0.09072568954679719\n",
      "train loss:0.011814104101484611\n",
      "train loss:0.02997550754882545\n",
      "train loss:0.0060308634314701895\n",
      "train loss:0.005850777388846269\n",
      "train loss:0.022622430124604048\n",
      "train loss:0.05068322002427769\n",
      "train loss:0.025153749724650402\n",
      "train loss:0.008412916041230272\n",
      "train loss:0.012691954276307881\n",
      "train loss:0.016536015090282182\n",
      "train loss:0.03157279584427414\n",
      "train loss:0.021914241666697868\n",
      "train loss:0.01731459681552943\n",
      "train loss:0.011536836401071811\n",
      "train loss:0.01285816656487848\n",
      "train loss:0.011052237029853902\n",
      "train loss:0.010576256943777933\n",
      "train loss:0.006745291936970293\n",
      "train loss:0.00953070062443806\n",
      "train loss:0.00297869239267371\n",
      "train loss:0.012955403457664655\n",
      "train loss:0.08756931246495575\n",
      "train loss:0.010925357595453059\n",
      "train loss:0.06139464516367434\n",
      "train loss:0.0037257675406688682\n",
      "train loss:0.004688974538820496\n",
      "train loss:0.0030492108624950364\n",
      "train loss:0.009317622211692017\n",
      "train loss:0.051489616475036915\n",
      "train loss:0.0033522346388287026\n",
      "train loss:0.010964739569254612\n",
      "train loss:0.0032865997268526487\n",
      "train loss:0.031823160433733184\n",
      "train loss:0.0038219795855080818\n",
      "train loss:0.025274855172038504\n",
      "train loss:0.010513721565826441\n",
      "train loss:0.004621852260942949\n",
      "train loss:0.02545180629268595\n",
      "train loss:0.00916437084144969\n",
      "train loss:0.019826342630377768\n",
      "train loss:0.018675072122906426\n",
      "train loss:0.02321345783027516\n",
      "train loss:0.0033282763661682396\n",
      "train loss:0.03975147278290649\n",
      "train loss:0.016224951042916783\n",
      "train loss:0.028305875265958052\n",
      "train loss:0.0453499739858809\n",
      "train loss:0.012546463270307591\n",
      "train loss:0.027340862352469145\n",
      "train loss:0.023995812466342463\n",
      "train loss:0.013738959363786845\n",
      "train loss:0.04149749755497023\n",
      "train loss:0.00497615112079551\n",
      "train loss:0.01879817712238678\n",
      "train loss:0.02731546666020833\n",
      "train loss:0.022786954603309515\n",
      "train loss:0.01839931197318423\n",
      "train loss:0.03296489256680774\n",
      "train loss:0.010601675510408463\n",
      "train loss:0.015805156920890365\n",
      "train loss:0.007753704451874781\n",
      "train loss:0.007054076908925099\n",
      "train loss:0.047755849077103056\n",
      "train loss:0.006259057858490859\n",
      "train loss:0.013845571296158654\n",
      "train loss:0.007356429204223502\n",
      "train loss:0.007664689359669392\n",
      "train loss:0.007692735942112014\n",
      "train loss:0.004454814561233169\n",
      "train loss:0.00737048541831852\n",
      "train loss:0.035390698380987816\n",
      "train loss:0.0015121297431363522\n",
      "train loss:0.03183620983800224\n",
      "train loss:0.013564641851949655\n",
      "train loss:0.016958737287564384\n",
      "train loss:0.017740790681115354\n",
      "train loss:0.03421924849366684\n",
      "train loss:0.005439891564315148\n",
      "train loss:0.0015133152207763604\n",
      "train loss:0.018688219860073317\n",
      "train loss:0.003330374028782142\n",
      "train loss:0.014047328158217473\n",
      "train loss:0.04116565468279634\n",
      "train loss:0.013831730837795944\n",
      "train loss:0.01745363892162446\n",
      "train loss:0.008098297046564397\n",
      "train loss:0.013760338972799973\n",
      "train loss:0.006064422913116822\n",
      "train loss:0.00433820357268847\n",
      "train loss:0.02087870788630089\n",
      "train loss:0.008584974882246944\n",
      "train loss:0.062071648285532806\n",
      "train loss:0.004350086861898336\n",
      "train loss:0.0400386289719594\n",
      "train loss:0.01055251057261294\n",
      "train loss:0.04472834498454939\n",
      "train loss:0.03402504281312098\n",
      "train loss:0.0023643159549093166\n",
      "train loss:0.005974474170782008\n",
      "train loss:0.014837713707251437\n",
      "train loss:0.016403928202381266\n",
      "train loss:0.013799830644273288\n",
      "train loss:0.018352023943451725\n",
      "train loss:0.003730653909704765\n",
      "train loss:0.009688966203904172\n",
      "train loss:0.03593475666000533\n",
      "train loss:0.024593294642005593\n",
      "train loss:0.028500675324048378\n",
      "train loss:0.027389779598562182\n",
      "train loss:0.03986414702544939\n",
      "train loss:0.011537628069709484\n",
      "train loss:0.015171700021351991\n",
      "train loss:0.0032073888964642143\n",
      "train loss:0.005065944618422078\n",
      "train loss:0.012593760614676732\n",
      "train loss:0.007412064247515529\n",
      "train loss:0.011817347246319712\n",
      "train loss:0.02125114798708445\n",
      "train loss:0.027600591546025587\n",
      "train loss:0.04041728822712762\n",
      "train loss:0.008285528386036132\n",
      "train loss:0.009568538079036609\n",
      "train loss:0.01475314616792187\n",
      "train loss:0.037297712162299795\n",
      "train loss:0.007382208499714696\n",
      "train loss:0.011758137872889436\n",
      "train loss:0.008050400755175631\n",
      "train loss:0.03297038641137409\n",
      "train loss:0.004248112995355997\n",
      "train loss:0.019298264404616666\n",
      "train loss:0.006125597275757578\n",
      "train loss:0.012051787040135629\n",
      "train loss:0.034143806037448626\n",
      "train loss:0.0203715697172076\n",
      "train loss:0.0061457011691389615\n",
      "train loss:0.01129109227833492\n",
      "train loss:0.06949460456240136\n",
      "train loss:0.0126109523833127\n",
      "train loss:0.012512844113204554\n",
      "train loss:0.016645555278468453\n",
      "train loss:0.04361511653295218\n",
      "train loss:0.02029486229912558\n",
      "train loss:0.0035347612530585363\n",
      "train loss:0.02642854845202548\n",
      "train loss:0.012380688816895406\n",
      "train loss:0.006504705849134792\n",
      "train loss:0.019100859317868944\n",
      "train loss:0.027602001600758513\n",
      "train loss:0.013844149895344786\n",
      "train loss:0.00871240423659363\n",
      "train loss:0.006881855113751981\n",
      "train loss:0.008694883804520463\n",
      "train loss:0.001115276699429006\n",
      "train loss:0.01530619623044856\n",
      "train loss:0.02775405548838789\n",
      "train loss:0.014849267215259818\n",
      "train loss:0.00410659774915713\n",
      "train loss:0.00375985999200403\n",
      "train loss:0.003031916115173539\n",
      "train loss:0.005614976583267897\n",
      "train loss:0.05151624994724565\n",
      "train loss:0.01997188141143377\n",
      "train loss:0.015009179086299633\n",
      "train loss:0.003800247610811343\n",
      "train loss:0.011283789402180465\n",
      "train loss:0.002353867585627016\n",
      "train loss:0.018230359669694704\n",
      "train loss:0.015265008926239016\n",
      "train loss:0.036693179982674684\n",
      "train loss:0.007896519120243733\n",
      "train loss:0.006114774591313547\n",
      "train loss:0.007368011106921687\n",
      "train loss:0.026169466978305977\n",
      "train loss:0.010876352090294252\n",
      "train loss:0.006792303095467811\n",
      "train loss:0.003432282928710312\n",
      "train loss:0.009304139860961623\n",
      "train loss:0.027404698802803548\n",
      "train loss:0.00910507076363797\n",
      "train loss:0.010189654120683471\n",
      "train loss:0.020004948391871537\n",
      "train loss:0.05787812643240162\n",
      "train loss:0.00921393390861424\n",
      "train loss:0.009691612401608563\n",
      "train loss:0.00506599679378151\n",
      "train loss:0.04949786670831528\n",
      "train loss:0.007980485888837196\n",
      "train loss:0.028360354508278274\n",
      "train loss:0.029894843445371314\n",
      "train loss:0.015028165444869589\n",
      "train loss:0.012618760717414945\n",
      "train loss:0.0076099410712071845\n",
      "train loss:0.014563516555821143\n",
      "train loss:0.01135449691751136\n",
      "train loss:0.01706859194391042\n",
      "train loss:0.04302309814907497\n",
      "train loss:0.023709851994152674\n",
      "train loss:0.01424257084680502\n",
      "train loss:0.013159358848706055\n",
      "train loss:0.011628269898174542\n",
      "train loss:0.009826403834933144\n",
      "train loss:0.011796635502149823\n",
      "train loss:0.007211153377952924\n",
      "train loss:0.015924504317905687\n",
      "train loss:0.019152257798394978\n",
      "train loss:0.008000499292412519\n",
      "train loss:0.006918319734526006\n",
      "train loss:0.0024882078111639738\n",
      "train loss:0.0031611479452405195\n",
      "train loss:0.023778813817764487\n",
      "train loss:0.021463066351656415\n",
      "train loss:0.03746503426970946\n",
      "train loss:0.007834853203054487\n",
      "train loss:0.012074437999180836\n",
      "train loss:0.011402609401774417\n",
      "train loss:0.008436378826876215\n",
      "train loss:0.005406430348916358\n",
      "train loss:0.004073310503694347\n",
      "train loss:0.005874166999433501\n",
      "train loss:0.005806884524314486\n",
      "train loss:0.0069089245364463425\n",
      "train loss:0.006478770532182715\n",
      "train loss:0.00386893952484976\n",
      "train loss:0.0071419897339473635\n",
      "train loss:0.0028742781729068283\n",
      "train loss:0.02858446033141799\n",
      "train loss:0.012413301397164319\n",
      "train loss:0.004942241483750553\n",
      "train loss:0.0061654123412398084\n",
      "train loss:0.010010139134844711\n",
      "train loss:0.03043303063928319\n",
      "train loss:0.01457592497330616\n",
      "train loss:0.025915037176372512\n",
      "train loss:0.01516174177015601\n",
      "train loss:0.02980691175906024\n",
      "train loss:0.008031263882020759\n",
      "train loss:0.016895047182773404\n",
      "train loss:0.030602417018547583\n",
      "train loss:0.00796627523379051\n",
      "train loss:0.0166984201039255\n",
      "train loss:0.020340772247124658\n",
      "train loss:0.0019836349345220055\n",
      "train loss:0.010782775923691448\n",
      "train loss:0.01801181998587301\n",
      "train loss:0.021010624029314515\n",
      "train loss:0.019640145846448413\n",
      "train loss:0.046680289179760664\n",
      "train loss:0.0021690194254370635\n",
      "train loss:0.026359694334767217\n",
      "train loss:0.009710400071298557\n",
      "train loss:0.004261170782646911\n",
      "train loss:0.013060443504669766\n",
      "train loss:0.0033556105417231123\n",
      "train loss:0.0014105181288479047\n",
      "train loss:0.02035212394226143\n",
      "train loss:0.014485233455095663\n",
      "train loss:0.017664674343444802\n",
      "train loss:0.018422010744559784\n",
      "train loss:0.018687611603951205\n",
      "train loss:0.04450950702974273\n",
      "=== epoch:8, train acc:0.993, test acc:0.986 ===\n",
      "train loss:0.004769531418130808\n",
      "train loss:0.004274129438554834\n",
      "train loss:0.004182056620875409\n",
      "train loss:0.0026661632203948352\n",
      "train loss:0.013786837036007173\n",
      "train loss:0.015533284029253146\n",
      "train loss:0.008198848639336065\n",
      "train loss:0.020404639540546134\n",
      "train loss:0.011987339993902581\n",
      "train loss:0.0018010976780326135\n",
      "train loss:0.007307200333323671\n",
      "train loss:0.01965874785338022\n",
      "train loss:0.009371896247157608\n",
      "train loss:0.004758260868424625\n",
      "train loss:0.0018780557194912888\n",
      "train loss:0.027505399084885897\n",
      "train loss:0.005889866426414826\n",
      "train loss:0.003307628948718801\n",
      "train loss:0.0038693798984587597\n",
      "train loss:0.007302113763328632\n",
      "train loss:0.012510685783447485\n",
      "train loss:0.006586286110996269\n",
      "train loss:0.0040669928102294774\n",
      "train loss:0.010143416327692788\n",
      "train loss:0.009284629345602022\n",
      "train loss:0.037113922117489165\n",
      "train loss:0.01831880614327179\n",
      "train loss:0.008202820439943604\n",
      "train loss:0.0028441917566630476\n",
      "train loss:0.0054106311247833815\n",
      "train loss:0.01510041216431044\n",
      "train loss:0.012553804060773461\n",
      "train loss:0.008690827867048435\n",
      "train loss:0.04064570099888708\n",
      "train loss:0.003617820723265671\n",
      "train loss:0.005498972674560441\n",
      "train loss:0.01378156891238038\n",
      "train loss:0.004211180218269688\n",
      "train loss:0.006126755746070443\n",
      "train loss:0.008195549205772413\n",
      "train loss:0.018517099899892843\n",
      "train loss:0.00039368517346136735\n",
      "train loss:0.003833350661065334\n",
      "train loss:0.002876710339970549\n",
      "train loss:0.020547833704044626\n",
      "train loss:0.0034630139520191645\n",
      "train loss:0.009545573319301521\n",
      "train loss:0.006998359082066503\n",
      "train loss:0.02992935212052505\n",
      "train loss:0.004118493593827441\n",
      "train loss:0.0031732241952867435\n",
      "train loss:0.007729177723951074\n",
      "train loss:0.059989807659483585\n",
      "train loss:0.008833640090916015\n",
      "train loss:0.005095436140545904\n",
      "train loss:0.009077535847551289\n",
      "train loss:0.003990379653033584\n",
      "train loss:0.0026308626307082273\n",
      "train loss:0.00821670901194833\n",
      "train loss:0.017324057959028433\n",
      "train loss:0.008019266068081687\n",
      "train loss:0.00512916362437845\n",
      "train loss:0.03286219090096881\n",
      "train loss:0.0726204594775202\n",
      "train loss:0.019273070567872797\n",
      "train loss:0.0029788636258796576\n",
      "train loss:0.06211759474100713\n",
      "train loss:0.006181522417550342\n",
      "train loss:0.018408939744905418\n",
      "train loss:0.007238247285396859\n",
      "train loss:0.0068496767163502455\n",
      "train loss:0.0054937493235816415\n",
      "train loss:0.01132725925345569\n",
      "train loss:0.016481917748849065\n",
      "train loss:0.0011939094292998111\n",
      "train loss:0.013496628702059657\n",
      "train loss:0.004640699773228042\n",
      "train loss:0.012018274247907284\n",
      "train loss:0.015208147242273753\n",
      "train loss:0.006352781501260856\n",
      "train loss:0.01854952107619778\n",
      "train loss:0.004401143903064437\n",
      "train loss:0.013809693316526367\n",
      "train loss:0.007823167378098881\n",
      "train loss:0.016936009433206053\n",
      "train loss:0.04084199029551319\n",
      "train loss:0.026689618135652363\n",
      "train loss:0.004006616934859799\n",
      "train loss:0.0020697832209057034\n",
      "train loss:0.012931277345205418\n",
      "train loss:0.03681477013505843\n",
      "train loss:0.012363737412089753\n",
      "train loss:0.01899022689111741\n",
      "train loss:0.01874896031862852\n",
      "train loss:0.007205055731658931\n",
      "train loss:0.011434258026499696\n",
      "train loss:0.011355294678722332\n",
      "train loss:0.020789627552170023\n",
      "train loss:0.008222982842744435\n",
      "train loss:0.012329169697992344\n",
      "train loss:0.01022876510058504\n",
      "train loss:0.02642203527698538\n",
      "train loss:0.018229061447462475\n",
      "train loss:0.006103707882487037\n",
      "train loss:0.0157128910502941\n",
      "train loss:0.0013152233064599717\n",
      "train loss:0.028003055036630097\n",
      "train loss:0.0016839253050880399\n",
      "train loss:0.010878721695191045\n",
      "train loss:0.04136299721254073\n",
      "train loss:0.019164463053227908\n",
      "train loss:0.0027382112327921627\n",
      "train loss:0.008965269791496304\n",
      "train loss:0.013212311896119083\n",
      "train loss:0.0011740280091513077\n",
      "train loss:0.029904549722210367\n",
      "train loss:0.008186503836398597\n",
      "train loss:0.003295355931034162\n",
      "train loss:0.02243906138618112\n",
      "train loss:0.014192161223624135\n",
      "train loss:0.018131942101999518\n",
      "train loss:0.018198083428088953\n",
      "train loss:0.012675263805912343\n",
      "train loss:0.007558104266410963\n",
      "train loss:0.004922261224242936\n",
      "train loss:0.011588651587001193\n",
      "train loss:0.010835231231049146\n",
      "train loss:0.038551176177393606\n",
      "train loss:0.043644168624822385\n",
      "train loss:0.004667042764939119\n",
      "train loss:0.022474965897746734\n",
      "train loss:0.02975175102495572\n",
      "train loss:0.006450115899722222\n",
      "train loss:0.03357601740883872\n",
      "train loss:0.00939623892115398\n",
      "train loss:0.013205906980149028\n",
      "train loss:0.00703780729946194\n",
      "train loss:0.03296139635515313\n",
      "train loss:0.06390964807959287\n",
      "train loss:0.004101021277664432\n",
      "train loss:0.022885188709513057\n",
      "train loss:0.005774992816952634\n",
      "train loss:0.0041523458549338\n",
      "train loss:0.026477080946271356\n",
      "train loss:0.009079050466330433\n",
      "train loss:0.007105717597781842\n",
      "train loss:0.026695294954550305\n",
      "train loss:0.0069373573179881635\n",
      "train loss:0.002873934708680535\n",
      "train loss:0.05436735458024197\n",
      "train loss:0.0012786371714636209\n",
      "train loss:0.07981922728245783\n",
      "train loss:0.0026193534811486006\n",
      "train loss:0.0038888944915674573\n",
      "train loss:0.013605918682140637\n",
      "train loss:0.006092452374040789\n",
      "train loss:0.023330912653687374\n",
      "train loss:0.006874022416042394\n",
      "train loss:0.011710074596036579\n",
      "train loss:0.017215375664986897\n",
      "train loss:0.014660317761442663\n",
      "train loss:0.013494631689077118\n",
      "train loss:0.007178350981205439\n",
      "train loss:0.006277815205595717\n",
      "train loss:0.002021096851147082\n",
      "train loss:0.008302558065034151\n",
      "train loss:0.01313637982927305\n",
      "train loss:0.027378150732096325\n",
      "train loss:0.04612864152588426\n",
      "train loss:0.03107590872315486\n",
      "train loss:0.014140897392405559\n",
      "train loss:0.011583674279871649\n",
      "train loss:0.002500087368651986\n",
      "train loss:0.010347654172964443\n",
      "train loss:0.020356828308381515\n",
      "train loss:0.005352731992459104\n",
      "train loss:0.014414043183771713\n",
      "train loss:0.0011998244699864275\n",
      "train loss:0.012247676822523429\n",
      "train loss:0.009686399173812166\n",
      "train loss:0.009333446736741252\n",
      "train loss:0.008738556997458333\n",
      "train loss:0.004162265986108358\n",
      "train loss:0.007462572614622841\n",
      "train loss:0.00338139346363686\n",
      "train loss:0.007920278184706996\n",
      "train loss:0.0022517891991694324\n",
      "train loss:0.0020923992673105973\n",
      "train loss:0.008703658803376256\n",
      "train loss:0.011252952501512908\n",
      "train loss:0.003091627131523407\n",
      "train loss:0.004432412380151573\n",
      "train loss:0.040327408842150206\n",
      "train loss:0.0033942035671116135\n",
      "train loss:0.006755572560215067\n",
      "train loss:0.006426250312761752\n",
      "train loss:0.03648053848873906\n",
      "train loss:0.009000703731394435\n",
      "train loss:0.008569019576352139\n",
      "train loss:0.008196459937159718\n",
      "train loss:0.006784959733945357\n",
      "train loss:0.017574240387259164\n",
      "train loss:0.006787599749827534\n",
      "train loss:0.012425774069964734\n",
      "train loss:0.016969738749074405\n",
      "train loss:0.0020818774411127078\n",
      "train loss:0.01673780414146379\n",
      "train loss:0.0720010499397863\n",
      "train loss:0.00408495702228682\n",
      "train loss:0.020641805499516594\n",
      "train loss:0.0038328110536700495\n",
      "train loss:0.012552397987932734\n",
      "train loss:0.0029579301737245613\n",
      "train loss:0.016196845268069776\n",
      "train loss:0.004815569926311334\n",
      "train loss:0.0028039497005234917\n",
      "train loss:0.00233573529868822\n",
      "train loss:0.01875980889940454\n",
      "train loss:0.011255363195634908\n",
      "train loss:0.014995445882109309\n",
      "train loss:0.007335804878691812\n",
      "train loss:0.0043492839386460895\n",
      "train loss:0.004792902329901694\n",
      "train loss:0.027986848992963647\n",
      "train loss:0.038612880711163415\n",
      "train loss:0.03081243593781193\n",
      "train loss:0.010318759946259769\n",
      "train loss:0.02274685107380536\n",
      "train loss:0.008958618132647022\n",
      "train loss:0.054268594293351395\n",
      "train loss:0.01057067965431502\n",
      "train loss:0.012768989265858864\n",
      "train loss:0.015892164169956598\n",
      "train loss:0.010841030103371663\n",
      "train loss:0.017328118498784753\n",
      "train loss:0.04305403614856632\n",
      "train loss:0.011867282280991962\n",
      "train loss:0.035408693887491995\n",
      "train loss:0.012178333005710473\n",
      "train loss:0.003762339646082463\n",
      "train loss:0.005269875444572647\n",
      "train loss:0.030184204374414096\n",
      "train loss:0.0461525616767155\n",
      "train loss:0.004094883254616637\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import sys, os\n",
    "sys.path.append('C:\\\\Users\\\\stevelee\\\\Documents\\\\30-Days-Challenges\\\\deep_learning_scratch_master\\\\deep-learning-from-scratch-master')\n",
    "# coding: utf-8\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from ch07.simple_convnet import SimpleConvNet\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
